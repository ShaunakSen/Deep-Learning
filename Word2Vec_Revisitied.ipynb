{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Word2Vec Revisitied.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMaXgHcts0jgdFAkCLRkJI8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShaunakSen/Deep-Learning/blob/master/Word2Vec_Revisitied.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ywNoDN2D4Zu",
        "colab_type": "text"
      },
      "source": [
        "## The Illustrated Word2vec\n",
        "\n",
        "> Notes on the excellent article by [Jay Alammar](http://jalammar.github.io/illustrated-word2vec/)\n",
        "\n",
        "---\n",
        "\n",
        "![](http://jalammar.github.io/images/word2vec/word2vec.png)\n",
        "\n",
        "### Basic Intuition\n",
        "\n",
        "On a scale of 0 to 100, how introverted/extraverted are you (where 0 is the most introverted, and 100 is the most extraverted)? Have you ever taken a personality test like MBTI – or even better, the Big Five Personality Traits test? If you haven’t, these are tests that ask you a list of questions, then score you on a number of axes, introversion/extraversion being one of them.\n",
        "\n",
        "Imagine I’ve scored 38/100 as my introversion/extraversion score. we can plot that in this way:\n",
        "\n",
        "![](http://jalammar.github.io/images/word2vec/introversion-extraversion-100.png)\n",
        "\n",
        "Let’s switch the range to be from -1 to 1:\n",
        "\n",
        "How well do you feel you know a person knowing only this one piece of information about them? Not much. People are complex. So let’s add another dimension – the score of one other trait from the test.\n",
        "\n",
        "![](http://jalammar.github.io/images/word2vec/two-traits-vector.png)\n",
        "\n",
        "We can represent the two dimensions as a point on the graph, or better yet, as a vector from the origin to that point. We have incredible tools to deal with vectors that will come in handy very shortly.\n",
        "\n",
        "\n",
        "I’ve hidden which traits we’re plotting just so you get used to not knowing what each dimension represents – but still getting a lot of value from the vector representation of a person’s personality.\n",
        "\n",
        "We can now say that this vector partially represents my personality. The usefulness of such representation comes when you want to compare two other people to me. Say I get hit by a bus and I need to be replaced by someone with a similar personality. In the following figure, which of the two people is more similar to me?\n",
        "\n",
        "![](http://jalammar.github.io/images/word2vec/personality-two-persons.png)\n",
        "\n",
        "When dealing with vectors, a common way to calculate a similarity score is cosine_similarity:\n",
        "\n",
        "![](http://jalammar.github.io/images/word2vec/cosine-similarity.png)\n",
        "\n",
        "Person #1 is more similar to me in personality. Vectors pointing at the same direction (length plays a role as well) have a higher cosine similarity score.\n",
        "\n",
        "Yet again, two dimensions aren’t enough to capture enough information about how different people are. Decades of psychology research have led to five major traits (and plenty of sub-traits). So let’s use all five dimensions in our comparison:\n",
        "\n",
        "The problem with five dimensions is that we lose the ability to draw neat little arrows in two dimensions. This is a common challenge in machine learning where we often have to think in higher-dimensional space. The good thing is, though, that cosine_similarity still works. It works with any number of dimensions:\n",
        "\n",
        "![](http://jalammar.github.io/images/word2vec/embeddings-cosine-personality.png)\n",
        "\n",
        "At the end of this section, I want us to come out with two central ideas:\n",
        "\n",
        "1. We can represent people (and things) as vectors of numbers (which is great for machines!).\n",
        "2. We can easily calculate how similar vectors are to each other.\n",
        "\n",
        "![](http://jalammar.github.io/images/word2vec/section-1-takeaway-vectors-cosine.png)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tQi5KsDCmqp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}