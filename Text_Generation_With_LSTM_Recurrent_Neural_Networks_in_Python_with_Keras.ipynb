{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text Generation With LSTM Recurrent Neural Networks in Python with Keras.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShaunakSen/Deep-Learning/blob/master/Text_Generation_With_LSTM_Recurrent_Neural_Networks_in_Python_with_Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "PLy246YtKcOd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Text Generation With LSTM Recurrent Neural Networks in Python with Keras\n",
        "\n",
        "[tutorial link](https://machinelearningmastery.com/text-generation-lstm-recurrent-neural-networks-python-keras/)\n",
        "\n",
        "Recurrent neural networks can also be used as generative models.\n",
        "\n",
        "This means that in addition to being used for predictive models (making predictions) they can learn the sequences of a problem and then generate entirely new plausible sequences for the problem domain.\n",
        "\n",
        "Generative models like this are useful not only to study how well a model has learned a problem, but to learn more about the problem domain itself.\n",
        "\n",
        "In this post you will discover how to create a generative model for text, character-by-character using LSTM recurrent neural networks in Python with Keras.\n",
        "\n",
        "\n",
        "### Problem Description: Project Gutenberg\n",
        "\n",
        "\n",
        "We are going to learn the dependencies between characters and the conditional probabilities of characters in sequences so that we can in turn generate wholly new and original sequences of characters.\n",
        "\n",
        "These experiments are not limited to text, you can also experiment with other ASCII data, such as computer source code, marked up documents in LaTeX, HTML or Markdown and more.\n",
        "\n",
        "### Develop a Small LSTM Recurrent Neural Network\n",
        "\n",
        "In this section we will develop a simple LSTM network to learn sequences of characters from Alice in Wonderland. In the next section we will use this model to generate new sequences of characters.\n",
        "\n",
        "Letâ€™s start off by importing the classes and functions we intend to use to train our model.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "7TEbOZS6KaNK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ibhcZPP_VcI2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Next, we need to load the ASCII text for the book into memory and convert all of the characters to lowercase to reduce the vocabulary that the network must learn.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "UIWTluYtVVcR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# load ascii text and covert to lowercase\n",
        "\n",
        "filename = 'alice_data'\n",
        "\n",
        "raw_text = open(file=filename).read()\n",
        "raw_text = raw_text.lower()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s1GH3mu7WEGO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now that the book is loaded, we must prepare the data for modeling by the neural network. We cannot model the characters directly, instead we must convert the characters to integers.\n",
        "\n",
        "We can do this easily by first creating a set of all of the distinct characters in the book, then creating a map of each character to a unique integer."
      ]
    },
    {
      "metadata": {
        "id": "I_KyE1JjWFNN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "5da6d7d9-02e0-46dc-9bda-2b9ca9a7ed5f"
      },
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(raw_text)))\n",
        "\n",
        "\n",
        "chars_to_int = dict((c,i) for i,c in enumerate(chars))\n",
        "\n",
        "print (chars_to_int)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'\\n': 0, ' ': 1, '!': 2, '\"': 3, \"'\": 4, '(': 5, ')': 6, '*': 7, ',': 8, '-': 9, '.': 10, '0': 11, '3': 12, ':': 13, ';': 14, '?': 15, '[': 16, ']': 17, '_': 18, 'a': 19, 'b': 20, 'c': 21, 'd': 22, 'e': 23, 'f': 24, 'g': 25, 'h': 26, 'i': 27, 'j': 28, 'k': 29, 'l': 30, 'm': 31, 'n': 32, 'o': 33, 'p': 34, 'q': 35, 'r': 36, 's': 37, 't': 38, 'u': 39, 'v': 40, 'w': 41, 'x': 42, 'y': 43, 'z': 44}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "osjRlxDfYkpz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "dataset that will reduce the vocabulary and may improve the modeling process.\n",
        "\n",
        "Now that the book has been loaded and the mapping prepared, we can summarize the dataset."
      ]
    },
    {
      "metadata": {
        "id": "TYh_TAXUYdt7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "2430559c-0dd6-423c-fe87-37ce8a3f270a"
      },
      "cell_type": "code",
      "source": [
        "n_chars = len(raw_text)\n",
        "n_vocab = len(chars)\n",
        "print (\"Total Characters: \", n_chars)\n",
        "print (\"Total Vocab: \", n_vocab)\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Characters:  144408\n",
            "Total Vocab:  45\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "41vy61xKZC_y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Each training pattern of the network is comprised of 100 time steps of one character (X) followed by one character output (y). When creating these sequences, we slide this window along the whole book one character at a time, allowing each character a chance to be learned from the 100 characters that preceded it (except the first 100 characters of course).\n",
        "\n",
        "For example, if the sequence length is 5 (for simplicity) then the first two training patterns would be as follows:\n",
        "\n",
        "```\n",
        "CHAPT -> E\n",
        "HAPTE -> R\n",
        "```\n",
        "\n",
        "As we split up the book into these sequences, we convert the characters to integers using our lookup table we prepared earlier.\n",
        "\n",
        "\n",
        "Basic idea of the data we want:\n"
      ]
    },
    {
      "metadata": {
        "id": "vPVO9NZ9fjnP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "b0a4cc79-9865-4610-aa33-75e461f971fb"
      },
      "cell_type": "code",
      "source": [
        "seq_length = 10\n",
        "\n",
        "\n",
        "for i in range(0, 5):\n",
        "\tseq_in = raw_text[i:i + seq_length]\n",
        "\tseq_out = raw_text[i + seq_length]\n",
        "\tprint (seq_in, seq_out)\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "alice's ad v\n",
            "lice's adv e\n",
            "ice's adve n\n",
            "ce's adven t\n",
            "e's advent u\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vVutswtJtZrc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "So the `X` data should be like `[\"alice's ad\", \"lice's adv\", ...]` and `Y` should be like `[\"v\", \"e\", ...]`. But the chars should not be present, the integere representations of the chars should be present in X and Y\n",
        "\n",
        "\n",
        "Extracting a small part of the datastet for experiment"
      ]
    },
    {
      "metadata": {
        "id": "czkD73s0m5PJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "outputId": "3a6cb60e-7b34-47cf-9193-725e0488b49f"
      },
      "cell_type": "code",
      "source": [
        "raw_text_sub = raw_text[:100]\n",
        "\n",
        "print(raw_text_sub)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "alice's adventures in wonderland\n",
            "\n",
            "lewis carroll\n",
            "\n",
            "the millennium fulcrum edition 3.0\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "chapter i. d\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JVnI9s1AmmED",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "011c9fca-f4fe-4797-e1ba-39a4bfdb796e"
      },
      "cell_type": "code",
      "source": [
        "text_to_process = raw_text\n",
        "seq_length = 100\n",
        "\n",
        "dataX = []\n",
        "\n",
        "dataY = []\n",
        "\n",
        "n_chars = len(text_to_process)\n",
        "\n",
        "for i in range (0, n_chars-seq_length):\n",
        "  \n",
        "  seq_in = text_to_process[i:i+seq_length]\n",
        "  \n",
        "  seq_out = text_to_process[i+seq_length]\n",
        "  \n",
        "  # print (seq_in, seq_out) \n",
        "  \n",
        "  dataX.append([chars_to_int[char] for char in seq_in])\n",
        "  \n",
        "  dataY.append(chars_to_int[seq_out])\n",
        "  \n",
        "n_patterns = len(dataX)\n",
        "print (\"Total Patterns: \", n_patterns)\n",
        "  "
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Patterns:  144308\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8R9ryDt7s6S9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# test to see if result matches with tutorial's data \n",
        "# print (dataX == dataX_new and dataY == dataY_new)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zPQ1tThWtI9l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "9588c718-7694-4ce5-bd56-a6383095ee9f"
      },
      "cell_type": "code",
      "source": [
        "print (len(dataX), len(dataY))\n",
        "\n",
        "print (len(dataX[0]))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "144308 144308\n",
            "100\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}