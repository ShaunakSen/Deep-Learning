{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ch 01 & 02 - Deep Learning With Python Chollet .ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNwqqSSOOyq3EHyKrrUO8kJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShaunakSen/Deep-Learning/blob/master/Ch_01_%26_02_Deep_Learning_With_Python_Chollet_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZE2W28EpY-ni",
        "colab_type": "text"
      },
      "source": [
        "> Notes based on the book [Deep Learning with Python by François Chollet](https://www.manning.com/books/deep-learning-with-python)\n",
        "\n",
        "## Ch 01 What is Deep Learning?\n",
        "\n",
        "A machine-learning model transforms its input data into meaningful outputs, a process that is “learned” from exposure to known examples of inputs and outputs. Therefore, the central problem in machine learning and deep learning is to meaningfully\n",
        "transform data: in other words, to learn useful representations of the input data at\n",
        "hand—representations that get us closer to the expected output. Before we go any\n",
        "further: what’s a representation? At its core, it’s a different way to look at data—to represent or encode data. For instance, a color image can be encoded in the RGB format\n",
        "(red-green-blue) or in the HSV format (hue-saturation-value): these are two different\n",
        "representations of the same data. Some tasks that may be difficult with one representation can become easy with another. For example, the task “select all red pixels in the\n",
        "image” is simpler in the RG format, whereas “make the image less saturated” is simpler\n",
        "in the HSV format. Machine-learning models are all about finding appropriate representations for their input data—transformations of the data that make it more amenable to the task at hand, such as a classification task.\n",
        "\n",
        "### Machine Learning\n",
        "\n",
        "Say we have a 2D plane of black and white points and we find a boundary to separate these points that works very well.\n",
        "\n",
        "In this case, we defined the coordinate change by hand. But if instead we tried systematically searching for different possible coordinate changes, and used as feedback the percentage of points being correctly classified, then we would be doing machine learning. Learning, in the context of machine learning, describes an automatic search process for better representations\n",
        "\n",
        "All machine-learning algorithms consist of automatically finding such transformations that turn data into more-useful representations for a given task. These operations can be coordinate changes, as you just saw, or linear projections (which may destroy information), translations, nonlinear operations (such as “select all points such that x > 0”), and so on. Machine-learning algorithms aren’t usually creative in finding these transformations; they’re merely searching through a predefined set of\n",
        "operations, called a hypothesis space.\n",
        " \n",
        "So that’s what machine learning is, technically: searching for useful representations of some input data, within a predefined space of possibilities, using guidance from a feedback signal. This simple idea allows for solving a remarkably broad range of intellectual tasks, from speech recognition to autonomous car driving.\n",
        "\n",
        "Now that you understand what we mean by learning, let’s take a look at what makes deep learning special. \n",
        "\n",
        "### The “deep” in deep learning\n",
        "\n",
        "Deep learning is a specific subfield of machine learning: a new take on learning representations from data that puts an emphasis on learning successive layers of increasingly\n",
        "meaningful representations. The deep in deep learning isn’t a reference to any kind ofdeeper understanding achieved by the approach; rather, it stands for this idea of successive layers of representations. How many layers contribute to a model of the data iscalled the depth of the model. Other appropriate names for the field could have beenlayered representations learning and hierarchical representations learning. Modern deeplearning often involves tens or even hundreds of successive layers of representations—\n",
        "and they’re all learned automatically from exposure to training data. Meanwhile,\n",
        "other approaches to machine learning tend to focus on learning only one or two layers of representations of the data; hence, they’re sometimes called shallow learning\n",
        "\n",
        " In deep learning, these layered representations are (almost always) learned via\n",
        "models called neural networks, structured in literal layers stacked on top of each other.\n",
        "The term neural network is a reference to neurobiology, but although some of the central concepts in deep learning were developed in part by drawing inspiration from our understanding of the brain, deep-learning models are not models of the brain.\n",
        "There’s no evidence that the brain implements anything like the learning mechanisms used in modern deep-learning models. You may come across pop-science articles proclaiming that deep learning works like the brain or was modeled after the brain, but that isn’t the case. It would be confusing and counterproductive for newcomers to the field to think of deep learning as being in any way related to neurobiology; you don’t need that shroud of “just like our minds” mystique and mystery, and you may as well forget anything you may have read about hypothetical links between deep learning and biology. **For our purposes, deep learning is a mathematical framework for learning representations from data**\n",
        "\n",
        "<img src='./img/fig1.6.png'>\n",
        "\n",
        "As you can see in figure 1.6, the network transforms the digit image into representations that are increasingly different from the original image and increasingly informative about the final result. You can think of a deep network as a multistage information-distillation operation, where information goes through successive filters and comes out increasingly purified (that is, useful with regard to some task).\n",
        "\n",
        "So that’s what deep learning is, technically: a multistage way to learn data representations. It’s a simple idea—but, as it turns out, very simple mechanisms, sufficiently scaled, can end up looking like magic. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LvmN9eufbXp",
        "colab_type": "text"
      },
      "source": [
        "### Understanding how deep learning works, in three figures\n",
        "\n",
        "At this point, you know that machine learning is about mapping inputs (such as\n",
        "images) to targets (such as the label “cat”), which is done by observing many examples of input and targets.You also know that deep neural networks do this input-to-target mapping via a deep sequence of simple data transformations (layers) and that these data transformations are learned by exposure to examples. Now let’s look at how this learning happens, concretely.\n",
        "\n",
        " The specification of what a layer does to its input data is stored in the layer’s weights, which in essence are a bunch of numbers. In this context, learning means finding a set of values for the weights of all layers in a network, such that the network will correctly map example inputs to their associated targets. But here’s the thing: a deep neural network can contain tens of millions of parameters. Finding the correct value for all of them may seem like a daunting task, especially given that modifying the value of one parameter will affect the behavior of all the others!\n",
        "\n",
        "\n",
        " To control the output of\n",
        "a neural network, you need to be able to measure how far this output is from what you expected. This is the job of the loss function of the network, also called the objective function. The loss function takes the predictions of the network and the true target (what you wanted the network to output) and computes a distance score, capturing\n",
        "how well the network has done on this specific example\n",
        "\n",
        "The fundamental trick in deep learning is to use this score as a feedback signal to adjust the value of the weights a little, in a direction that will lower the loss score for the current example (see figure 1.9). This adjustment is the job of the optimizer, which implements what’s called the Backpropagation algorithm: the central algorithm in deep learning. The next chapter explains in more detail how backpropagation works\n",
        "\n",
        "<img src='./img/fig1.9.png'>\n",
        "\n",
        "\n",
        "Initially, the weights of the network are assigned random values, so the network\n",
        "merely implements a series of random transformations. Naturally, its output is far from what it should ideally be, and the loss score is accordingly very high. But with every example the network processes, the weights are adjusted a little in the correct direction, and the loss score decreases. This is the training loop, which, repeated a sufficient number of times (typically tens of iterations over thousands of examples), yields weight values that minimize the loss function. A network with a minimal loss is one for which the outputs are as close as they can be to the targets: a trained network. Once again, it’s a simple mechanism that, once scaled, ends up looking like magic. \n",
        "\n",
        "### What makes deep learning different\n",
        "\n",
        "The primary reason deep learning took off so quickly is that it offered better performance on many problems. But that’s not the only reason. Deep learning also makes problem-solving much easier, because it completely automates what used to be the most crucial step in a machine-learning workflow: feature engineering.\n",
        "\n",
        "Previous machine-learning techniques—shallow learning—only involved transforming the input data into one or two successive representation spaces, usually via simple transformations such as high-dimensional non-linear projections (SVMs) or\n",
        "decision trees. But the refined representations required by complex problems generally can’t be attained by such techniques. As such, humans had to go to great lengths to make the initial input data more amenable to processing by these methods: they had to manually engineer good layers of representations for their data. This is called feature engineering. Deep learning, on the other hand, completely automates this step:\n",
        "with deep learning, you learn all features in one pass rather than having to engineer them yourself. This has greatly simplified machine-learning workflows, often replacing sophisticated multistage pipelines with a single, simple, end-to-end deep-learning model.\n",
        "\n",
        "You may ask, if the crux of the issue is to have multiple successive layers of representations, could shallow methods be applied repeatedly to emulate the effects of deep learning? In practice, there are fast-diminishing returns to successive applications of shallow-learning methods, *because the optimal first representation layer in a three layer model isn’t the optimal first layer in a one-layer or two-layer model.* What is transformative about deep learning is that it allows a model to learn all layers of representation **jointly, at the same time, rather than in succession (greedily, as it’s called). With joint\n",
        "feature learning, whenever the model adjusts one of its internal features, all other features that depend on it automatically adapt to the change, without requiring human intervention.** Everything is supervised by a single feedback signal: every change in the model serves the end goal. This is much more powerful than greedily stacking shallow models, because it allows for **complex, abstract representations to be learned by breaking them down into long series of intermediate spaces (layers); each space is only a simple transformation away from the previous one.**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lu6NMqFui_SH",
        "colab_type": "text"
      },
      "source": [
        "## Before we begin: the mathematical building blocks of neural networks\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuQODsp1Y0ta",
        "colab_type": "code",
        "outputId": "69018aac-3fb5-49ae-9a1f-0e7c499b76d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "from keras.datasets import mnist\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "print (train_images.shape, train_labels.shape, test_images.shape, test_labels.shape) # each img is 28x28 greyscale"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "(60000, 28, 28) (60000,) (10000, 28, 28) (10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8ku3zHOk9zP",
        "colab_type": "text"
      },
      "source": [
        "The workflow will be as follows: First, we’ll feed the neural network the training data, train_images and train_labels. The network will then learn to associate images and labels. Finally, we’ll ask the network to produce predictions for test_images, and we’ll verify whether these predictions match the labels from test_labels.\n",
        "\n",
        " Let’s build the network—again, remember that you aren’t expected to understand\n",
        "everything about this example yet."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6uNcxsnkTeL",
        "colab_type": "code",
        "outputId": "96d75cd9-e5fb-4f37-89d1-3d4fe2d8ee1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "network = models.Sequential()\n",
        "network.add(layers.Dense(units=512, activation='relu', input_shape=(28*28, )))\n",
        "network.add(layers.Dense(units=10, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zN92TXE_l7vA",
        "colab_type": "text"
      },
      "source": [
        "The core building block of neural networks is the layer, a data-processing module that you can think of as a filter for data. Some data goes in, and it comes out in a more useful form. Specifically, layers extract representations out of the data fed into them—hopefully, representations that are more meaningful for the problem at hand. Most of deep learning consists of chaining together simple layers that will implement a form of progressive data distillation. A deep-learning model is like a sieve for data processing, made of a succession of increasingly refined data filters—the layers.\n",
        "\n",
        "Here, our network consists of a sequence of two Dense layers, which are densely\n",
        "connected (also called fully connected) neural layers. The second (and last) layer is a 10-way softmax layer, which means it will return an array of 10 probability scores (summing to 1). Each score will be the probability that the current digit image belongs to one of our 10 digit classes\n",
        "\n",
        "To make the network ready for training, we need to pick three more things, as part of the compilation step:\n",
        "\n",
        "1. A loss function—How the network will be able to measure its performance on\n",
        "the training data, and thus how it will be able to steer itself in the right direction.\n",
        "\n",
        "2. An optimizer—The mechanism through which the network will update itself\n",
        "based on the data it sees and its loss function\n",
        "\n",
        "3. Metrics to monitor during training and testing—Here, we’ll only care about accuracy (the fraction of the images that were correctly classified).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUyu95CQl4Ks",
        "colab_type": "code",
        "outputId": "9ac4cb24-ede3-49bf-d8a2-ae46f20faec6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "# the compilation step\n",
        "network.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UlFM6hJvnqz3",
        "colab_type": "text"
      },
      "source": [
        "Before training, we’ll preprocess the data by reshaping it into the shape the network expects and scaling it so that all values are in the `[0, 1]` interval. Previously, our training images, for instance, were stored in an array of shape `(60000, 28, 28)` of type uint8 with values in the `[0, 255]` interval. We transform it into a float32 array of shape `(60000, 28 * 28)` with values between 0 and 1.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vosj5EOhnqAr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_images = train_images.reshape((60000, 28*28))\n",
        "train_images = train_images.astype('float32')/255\n",
        "\n",
        "test_images = test_images.reshape((10000, 28*28))\n",
        "test_images = test_images.astype('float32')/255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOX3x1W5pJky",
        "colab_type": "code",
        "outputId": "99da9236-e4fa-4ca8-c76c-3a7aadc777e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "source": [
        "# We also need to categorically encode the labels\n",
        "\n",
        "print (train_labels[:5])\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "train_labels = to_categorical(y=train_labels)\n",
        "test_labels = to_categorical(y=test_labels)\n",
        "\n",
        "print (train_labels[:5])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[5 0 4 1 9]\n",
            "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmpc2bMZrdWQ",
        "colab_type": "text"
      },
      "source": [
        "We’re now ready to train the network, which in Keras is done via a call to the network’s fit method—we fit the model to its training data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zV9dS_t9re5e",
        "colab_type": "code",
        "outputId": "d2b1ca21-a387-4760-ea97-f2bb7c5ce20b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        }
      },
      "source": [
        "network.fit(x=train_images, y=train_labels, batch_size=128, epochs=5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Epoch 1/5\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "60000/60000 [==============================] - 11s 187us/step - loss: 0.2548 - acc: 0.9261\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 0.1028 - acc: 0.9694\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0680 - acc: 0.9792\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 0.0490 - acc: 0.9854\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 1s 23us/step - loss: 0.0377 - acc: 0.9886\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f17b1c4d978>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptFr1_B0rw1O",
        "colab_type": "text"
      },
      "source": [
        "Two quantities are displayed during training: the loss of the network over the training data, and the accuracy of the network over the training data.\n",
        "\n",
        " We quickly reach an accuracy of 0.989 (98.9%) on the training data. Now let’s\n",
        "check that the model performs well on the test set, too:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUJdMh-PrpHA",
        "colab_type": "code",
        "outputId": "6e43a0e3-9d2a-4318-82af-3594227fecfa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "test_loss, test_acc = network.evaluate(x=test_images, y=test_labels)\n",
        "\n",
        "print (test_loss, test_acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 0s 43us/step\n",
            "0.06641416108431294 0.9803\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vowBP0HHsM-T",
        "colab_type": "text"
      },
      "source": [
        "The test-set accuracy turns out to be 97.8%—that’s quite a bit lower than the training set accuracy. This gap between training accuracy and test accuracy is an example of overfitting: the fact that machine-learning models tend to perform worse on new data than on their training data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oo7pyAeEMca-",
        "colab_type": "text"
      },
      "source": [
        "### Data representations for neural networks\n",
        "\n",
        "In the previous example, we started from data stored in multidimensional Numpy\n",
        "arrays, also called tensors. In general, all current machine-learning systems use tensors as their basic data structure. Tensors are fundamental to the field—so fundamental that Google’s TensorFlow was named after them. \n",
        "\n",
        "At its core, a tensor is a container for data—almost always numerical data. So, it’s a container for numbers. You may be already familiar with matrices, which are 2D tensors: tensors are a generalization of matrices to an arbitrary number of dimensions (note that in the context of tensors, a dimension is often called an axis).\n",
        "\n",
        "A tensor that contains only one number is called a scalar (or scalar tensor, or 0-dimensional tensor, or 0D tensor). In Numpy, a float32 or float64 number is a scalar tensor (or scalar array). You can display the number of axes of a Numpy tensor via the ndim attribute; a scalar tensor has 0 axes (ndim == 0). The number of axes of a tensor is also called its rank\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Co_iuXe7sIBQ",
        "colab_type": "code",
        "outputId": "3ec7dcdc-4487-4e45-ba60-b642b9a19009",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "x=np.array(12)\n",
        "\n",
        "print (x.ndim)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plqjgRAHNTi_",
        "colab_type": "code",
        "outputId": "ac2e460d-fa7d-459f-bb43-78be78243b64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x=np.array([1,2,3,4,5])\n",
        "print (x.ndim)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kC2ozro6NCxn",
        "colab_type": "text"
      },
      "source": [
        "An array of numbers is called a vector, or 1D tensor. A 1D tensor is said to have exactly one axis. Following is a Numpy vector:\n",
        "\n",
        "This vector has five entries and so is called a 5-dimensional vector. \n",
        "> Don’t confuse a 5D vector with a 5D tensor! A 5D vector has only one axis and has five dimensions along its axis, whereas a 5D tensor has five axes (and may have any number of dimensions along each axis). \n",
        "\n",
        "> Dimensionality can denote either the number of entries along a specific axis (as in the case of our 5D vector) or the number of axes in a tensor (such as a\n",
        "5D tensor), which can be confusing at times. In the latter case, it’s technically more correct to talk about a tensor of rank 5 (the rank of a tensor being the number of axes), but the ambiguous notation 5D tensor is common regardless. \n",
        "\n",
        "An array of vectors is a matrix, or 2D tensor. A matrix has two axes (often referred to rows and columns). You can visually interpret a matrix as a rectangular grid of numbers.\n",
        "\n",
        "This is a Numpy matrix:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NA1GnqiOVp2",
        "colab_type": "code",
        "outputId": "cdaf24a6-bd94-4863-c47b-6f512fc93acf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        " x = np.array([[5, 78, 2, 34, 0],\n",
        "              [6, 79, 3, 35, 1],\n",
        "              [7, 80, 4, 36, 2]])\n",
        " \n",
        "print (x.ndim)\n",
        "\n",
        "print (x[0, :])\n",
        "\n",
        "print (x[:, 0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n",
            "[ 5 78  2 34  0]\n",
            "[5 6 7]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1RufoAnMO-w4",
        "colab_type": "text"
      },
      "source": [
        "#### 3D tensors and higher-dimensional tensors\n",
        "\n",
        "If you pack such matrices in a new array, you obtain a 3D tensor, which you can visually interpret as a cube of numbers. Following is a Numpy 3D tensor:\n",
        "\n",
        "\n",
        "By packing 3D tensors in an array, you can create a 4D tensor, and so on. In deep learning, you’ll generally manipulate tensors that are 0D to 4D, although you may go up to 5D if you process video data. \n",
        "\n",
        "> In general, think that by packing (n-1)D tensors in an array we can create n D tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWAh4TiJPgIL",
        "colab_type": "code",
        "outputId": "7ecc3096-4c25-4102-a025-ca2a294b926e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "x = np.array([\n",
        "              [                       # 1st matrix\n",
        "               [5, 78, 2, 34, 0],\n",
        "               [6, 79, 3, 35, 1],\n",
        "               [7, 80, 4, 36, 2]\n",
        "              ],\n",
        "              [                       # 2nd matrix\n",
        "                [5, 78, 2, 34, 0],\n",
        "                [6, 79, 3, 35, 1],\n",
        "                [7, 80, 4, 36, 2]\n",
        "              ],\n",
        "              [                       # 3rd matrix\n",
        "               [5, 78, 2, 34, 0],\n",
        "               [6, 79, 3, 35, 1],\n",
        "               [7, 80, 4, 36, 2]\n",
        "              ]\n",
        "            ])\n",
        "\n",
        "print (x.ndim)\n",
        "\n",
        "print (x[0])\n",
        "\n",
        "print (x.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3\n",
            "[[ 5 78  2 34  0]\n",
            " [ 6 79  3 35  1]\n",
            " [ 7 80  4 36  2]]\n",
            "(3, 3, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlVLQYbYQtjt",
        "colab_type": "text"
      },
      "source": [
        "A tensor is defined by three key attributes:\n",
        "\n",
        "1. Number of axes (rank)—For instance, a 3D tensor has three axes, and a matrix has two axes. This is also called the tensor’s ndim in Python libraries such as Numpy\n",
        "\n",
        "2. Shape—This is a tuple of integers that describes how many dimensions the tensor has along each axis. For instance, the previous matrix example has shape\n",
        "(3, 5), and the 3D tensor example has shape (3, 3, 5). A vector has a shape\n",
        "with a single element, such as (5,), whereas a scalar has an empty shape, ().\n",
        "\n",
        "3. Data type (usually called dtype in Python libraries)—This is the type of the data contained in the tensor; for instance, a tensor’s type could be float32, uint8, float64, and so on. On rare occasions, you may see a char tensor. Note that string tensors don’t exist in Numpy (or in most other libraries), **because tensors live in preallocated, contiguous memory segments: and strings, being variable length, would preclude the use of this implementation.**\n",
        "\n",
        "To make this more concrete, let’s look back at the data we processed in the MNIST example. We load the data again as we do not want to look at the pre processed data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjnGq8GER_Hq",
        "colab_type": "code",
        "outputId": "5872ce21-d274-4afc-ef57-8ff6671601d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "from keras.datasets import mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "print (train_images.ndim)\n",
        "\n",
        "print (train_images.shape)\n",
        "\n",
        "print (train_images.dtype)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3\n",
            "(60000, 28, 28)\n",
            "uint8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3IMUjW9goB3",
        "colab_type": "text"
      },
      "source": [
        "So what we have here is a 3D tensor of 8-bit integers. More precisely, it’s an array of 60,000 matrices of 28 × 8 integers. Each such matrix is a grayscale image, with coefficients between 0 and 255. Let’s display the fourth digit in this 3D tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rco3HK2SgfHW",
        "colab_type": "code",
        "outputId": "cada763f-6147-4e85-836f-11d10f8bd76e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "digit = train_images[4]\n",
        "print (digit.shape)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(X=digit, cmap=plt.cm.binary)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NEbWQvLhpac",
        "colab_type": "text"
      },
      "source": [
        "#### Manipulating tensors in Numpy\n",
        "\n",
        "In the previous example, we selected a specific digit alongside the first axis using the syntax `train_images[i]`. Selecting specific elements in a tensor is called tensor slicing.\n",
        "\n",
        "Let’s look at the tensor-slicing operations you can do on Numpy arrays.\n",
        "The following example selects digits #10 to #100 (#100 isn’t included) and puts\n",
        "them in an array of shape (90, 28, 28):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrAVjnnbhUcm",
        "colab_type": "code",
        "outputId": "eae8ec76-fb5c-4043-e3ff-3a0e49a3991f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "my_slice = train_images[10:100]\n",
        "\n",
        "print (my_slice.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(90, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wyzHSaO9kDP9",
        "colab_type": "text"
      },
      "source": [
        "It’s equivalent to this more detailed notation, which specifies a start index and stop index for the slice along each tensor axis. Note that : is equivalent to selecting the entire axis:\n",
        "\n",
        "```python\n",
        ">>> my_slice = train_images[10:100, :, :]\n",
        ">>> my_slice.shape\n",
        "(90, 28, 28)\n",
        ">>> my_slice = train_images[10:100, 0:28, 0:28]\n",
        ">>> my_slice.shape\n",
        "(90, 28, 28)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ReOW9MGYi-NT",
        "colab_type": "code",
        "outputId": "46f008a9-15bc-4fa8-b406-22c7a453319e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        }
      },
      "source": [
        "plt.imshow(train_images[2]);"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAANSklEQVR4nO3db4wc9X3H8c/Hx9mOnaD4TH29GAco\nwQ9opZrqMFX4UypSRFAqgxJZsZTElVAvD2IpSHkApa1ClQclURMatRHSBdw4VQpKlCD8gKQYCxWh\nRI4P4mIb00KoXewYn1MnsgnGf799cEN0wO3seWd2Z33f90ta3e58d3a+GvnjmZ3f7v4cEQIw981r\nugEAvUHYgSQIO5AEYQeSIOxAEhf0cmPzvSAWanEvNwmk8qZ+o5NxwjPVKoXd9i2Svi5pQNKDEXFf\n2fMXarGu8U1VNgmgxLbY2rLW8Wm87QFJ35D0UUlXSlpn+8pOXw9Ad1V5z75a0ssR8UpEnJT0iKQ1\n9bQFoG5Vwr5c0qvTHu8vlr2N7THbE7YnTulEhc0BqKLrV+MjYjwiRiNidFALur05AC1UCfsBSSum\nPb64WAagD1UJ+3ZJV9i+zPZ8SZ+UtLmetgDUreOht4g4bXuDpH/X1NDbxojYXVtnAGpVaZw9Ih6X\n9HhNvQDoIj4uCyRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQd\nSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKV\nZnEF+tlvPnFNy9qXv/JA6bpfWvuZ0npM7OqopyZVCrvtvZKOSToj6XREjNbRFID61XFk/9OI+GUN\nrwOgi3jPDiRRNewh6Qnbz9oem+kJtsdsT9ieOKUTFTcHoFNVT+Ovi4gDtpdJ2mL7xYh4evoTImJc\n0rgkXeihqLg9AB2qdGSPiAPF30lJj0paXUdTAOrXcdhtL7b9vrfuS7pZ0vk3HgEkUeU0fljSo7bf\nep1/i4gf1dJVFxxfU37ScXzpQGl9aONP6mwHPTA52vpY9qW9f97DTvpDx2GPiFck/WGNvQDoIobe\ngCQIO5AEYQeSIOxAEoQdSCLNV1x/cUP5/2uLLv91+QtsrLEZ1GNe+XBpfPB4y9pNy14sXXerP9xR\nS/2MIzuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJJFmnP3vPva90vqX99zco05Ql4HLLymtv/gnrT8c\nseqnnypd9wPbd3bUUz/jyA4kQdiBJAg7kARhB5Ig7EAShB1IgrADSaQZZx/06aZbQM0uePCNjtc9\n/vMLa+zk/MCRHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSmDPj7GevW1Vav37hMz3qBL1y6eL/63jd\nFU+eqbGT80PbI7vtjbYnbe+atmzI9hbbLxV/l3S3TQBVzeY0/luSbnnHsrslbY2IKyRtLR4D6GNt\nwx4RT0s68o7FayRtKu5vknRbzX0BqFmn79mHI+Jgcf81ScOtnmh7TNKYJC3Uog43B6CqylfjIyIk\nRUl9PCJGI2J0UAuqbg5AhzoN+yHbI5JU/J2sryUA3dBp2DdLWl/cXy/psXraAdAtbd+z235Y0o2S\nLrK9X9IXJd0n6bu275C0T9LabjY5G/s+9p7S+rIBrhecby649IOl9U8Mbe74td/zP78qrc/FUfi2\nYY+IdS1KN9XcC4Au4uOyQBKEHUiCsANJEHYgCcIOJDFnvuJ6wYeOVVr/zRffX1MnqMur/7i4tH7t\ngrOl9YeOXty6+OujnbR0XuPIDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJzJlx9qqWTZSP2WJmAxct\nLa0f+vjKlrWhtftL1/2PlQ+12frC0uoD32j904jLDv24zWvPPRzZgSQIO5AEYQeSIOxAEoQdSIKw\nA0kQdiAJxtkLx4fK/98r/2Z1NWevv6q0HgMurb/6kdYz7Zz8wKnSdefNL//R5Ceu/6fS+mB5a3rt\nTOve/vaV20vXPXK2/LMPi+aV9z68rfVvHLScwmgO48gOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0nM\nmXH2E28OltbPthlZ/Zd77i+tb96w6px7mq27lj5YWp+n8sHs43GyZe0XZ8rHov/58I2l9Y88eWdp\n/f0/m19aH3niUMua95V/n/3wnvJpuIcHyj9DENt3ltazaXtkt73R9qTtXdOW3Wv7gO0dxe3W7rYJ\noKrZnMZ/S9ItMyy/PyJWFbfH620LQN3ahj0inpZ0pAe9AOiiKhfoNth+vjjNX9LqSbbHbE/Ynjil\nExU2B6CKTsP+gKTLJa2SdFDSV1s9MSLGI2I0IkYH1fpLEQC6q6OwR8ShiDgTEWclfVPS6nrbAlC3\njsJue2Taw9sl7Wr1XAD9oe04u+2HJd0o6SLb+yV9UdKNtldp6mvBeyV9tos9zsqHPvWz0vrv//2G\n0vqKqw/U2c45eWqy9W+rS9LhH5bMMy5p6e7W483zf7S9zdbLx6pXaqLN+uXKRvkP3PXh0nWvXvCT\n0vojry/voKO82oY9ItbNsLjdr/cD6DN8XBZIgrADSRB2IAnCDiRB2IEk5sxXXNu57K/Kh3H62Yj+\nt+kWumLRDYcrrf83T328tL5SP630+nMNR3YgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSCLNODvmnkse\nyzjxcuc4sgNJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig\n7EASfJ8dfWvA5ceiX60cLK3/7g/r7Ob81/bIbnuF7adsv2B7t+3PF8uHbG+x/VLxd0n32wXQqdmc\nxp+W9IWIuFLSH0v6nO0rJd0taWtEXCFpa/EYQJ9qG/aIOBgRzxX3j0naI2m5pDWSNhVP2yTptm41\nCaC6c3rPbvtSSVdJ2iZpOCIOFqXXJA23WGdM0pgkLdSiTvsEUNGsr8bbfq+k70u6MyKOTq9FREia\n8df/ImI8IkYjYnRQCyo1C6Bzswq77UFNBf07EfGDYvEh2yNFfUTSZHdaBFCH2VyNt6SHJO2JiK9N\nK22WtL64v17SY/W3h8zOxNnSm+ap/Ia3mc179mslfVrSTts7imX3SLpP0ndt3yFpn6S13WkRQB3a\nhj0inpHkFuWb6m0HQLdwsgMkQdiBJAg7kARhB5Ig7EASfMUV5603rn6j6RbOKxzZgSQIO5AEYQeS\nIOxAEoQdSIKwA0kQdiAJxtnRt9r9lDTODXsTSIKwA0kQdiAJwg4kQdiBJAg7kARhB5JgnB2NOfHk\n75TWz6w626NOcuDIDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJOCLKn2CvkPRtScOSQtJ4RHzd9r2S\n/lLS4eKp90TE42WvdaGH4hoz8SvQLdtiq47GkRlnXZ7Nh2pOS/pCRDxn+32SnrW9pajdHxH/UFej\nALpnNvOzH5R0sLh/zPYeScu73RiAep3Te3bbl0q6StK2YtEG28/b3mh7SYt1xmxP2J44pROVmgXQ\nuVmH3fZ7JX1f0p0RcVTSA5Iul7RKU0f+r860XkSMR8RoRIwOakENLQPoxKzCbntQU0H/TkT8QJIi\n4lBEnImIs5K+KWl199oEUFXbsNu2pIck7YmIr01bPjLtabdL2lV/ewDqMpur8ddK+rSknbZ3FMvu\nkbTO9ipNDcftlfTZrnQIoBazuRr/jKSZxu1Kx9QB9Bc+QQckQdiBJAg7kARhB5Ig7EAShB1IgrAD\nSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUii7U9J17ox+7CkfdMWXSTplz1r4Nz0a2/92pdEb52q\ns7dLImLGubB7GvZ3bdyeiIjRxhoo0a+99WtfEr11qle9cRoPJEHYgSSaDvt4w9sv06+99WtfEr11\nqie9NfqeHUDvNH1kB9AjhB1IopGw277F9n/Zftn23U300IrtvbZ32t5he6LhXjbanrS9a9qyIdtb\nbL9U/J1xjr2GervX9oFi3+2wfWtDva2w/ZTtF2zvtv35Ynmj+66kr57st56/Z7c9IOm/Jf2ZpP2S\ntktaFxEv9LSRFmzvlTQaEY1/AMP2DZJel/TtiPiDYtlXJB2JiPuK/yiXRMRdfdLbvZJeb3oa72K2\nopHp04xLuk3SX6jBfVfS11r1YL81cWRfLenliHglIk5KekTSmgb66HsR8bSkI+9YvEbSpuL+Jk39\nY+m5Fr31hYg4GBHPFfePSXprmvFG911JXz3RRNiXS3p12uP96q/53kPSE7aftT3WdDMzGI6Ig8X9\n1yQNN9nMDNpO491L75hmvG/2XSfTn1fFBbp3uy4i/kjSRyV9rjhd7Usx9R6sn8ZOZzWNd6/MMM34\nbzW57zqd/ryqJsJ+QNKKaY8vLpb1hYg4UPydlPSo+m8q6kNvzaBb/J1suJ/f6qdpvGeaZlx9sO+a\nnP68ibBvl3SF7ctsz5f0SUmbG+jjXWwvLi6cyPZiSTer/6ai3ixpfXF/vaTHGuzlbfplGu9W04yr\n4X3X+PTnEdHzm6RbNXVF/ueS/rqJHlr09XuS/rO47W66N0kPa+q07pSmrm3cIWmppK2SXpL0pKSh\nPurtXyXtlPS8poI10lBv12nqFP15STuK261N77uSvnqy3/i4LJAEF+iAJAg7kARhB5Ig7EAShB1I\ngrADSRB2IIn/Bziw80r6zfkYAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LS8KMnWdk1z-",
        "colab_type": "text"
      },
      "source": [
        "For instance, in order to select 14 × 14 pixels in the bottom-right corner of all images, you do this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WbqMqiAlG1l",
        "colab_type": "code",
        "outputId": "ed287c18-0005-4876-9365-947398518070",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "plt.imshow(train_images[2, 14:, 14:])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f16f68307f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMrXC2JAl5SD",
        "colab_type": "text"
      },
      "source": [
        "The 2 is for the 2nd image, the first 14: selects the 14-28 pixels from the top (i.e 14 pixels from bottom) the second 14: selects the 14-28 pixels from left to right i.e the 14 rightmost pixels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1euSjTibnESQ",
        "colab_type": "text"
      },
      "source": [
        "#### The notion of data batches\n",
        "\n",
        "In general, the first axis (axis 0, because indexing starts at 0) in all data tensors you’ll come across in deep learning will be the samples axis (sometimes called the samples dimension). In the MNIST example, samples are images of digits\n",
        "\n",
        "In addition, deep-learning models don’t process an entire dataset at once; rather, they break the data into small batches. Concretely, here’s one batch of our MNIST digits, with batch size of 128:\n",
        "\n",
        "```\n",
        "batch = train_images[:128]\n",
        "And here’s the next batch:\n",
        "batch = train_images[128:256]\n",
        "And the nth batch:\n",
        "batch = train_images[128 * n:128 * (n + 1)]\n",
        "```\n",
        "\n",
        "When considering such a batch tensor, the first axis (axis 0) is called the batch axis or batch dimension. This is a term you’ll frequently encounter when using Keras and other deep-learning libraries.\n",
        "\n",
        "#### Real-world examples of data tensors\n",
        "\n",
        "Let’s make data tensors more concrete with a few examples similar to what you’ll\n",
        "encounter later. The data you’ll manipulate will almost always fall into one of the following categories:\n",
        "\n",
        "1. Vector data—2D tensors of shape (samples, features)\n",
        "2. Timeseries data or sequence data—3D tensors of shape (samples, timesteps,\n",
        "features)\n",
        "3. Images—4D tensors of shape (samples, height, width, channels) or (samples,\n",
        "channels, height, width)\n",
        "4. Video—5D tensors of shape (samples, frames, height, width, channels) or\n",
        "(samples, frames, channels, height, width)\n",
        "\n",
        "##### Vector data\n",
        "\n",
        "This is the most common case. In such a dataset, each single data point can be encoded as a vector, and thus a batch of data will be encoded as a 2D tensor (that is, an array of vectors), where the first axis is the samples axis and the second axis is the features axis\n",
        "\n",
        "Let’s take a look at two examples:\n",
        "\n",
        "- An actuarial dataset of people, where we consider each person’s age, ZIP code,\n",
        "and income. Each person can be characterized as a vector of 3 values, and thus\n",
        "an entire dataset of 100,000 people can be stored in a 2D tensor of shape\n",
        "(100000, 3).\n",
        "\n",
        "- A dataset of text documents, where we represent each document by the counts\n",
        "of how many times each word appears in it (out of a dictionary of 20,000 common words). Each document can be encoded as a vector of 20,000 values (one\n",
        "count per word in the dictionary), and thus an entire dataset of 500 documents\n",
        "can be stored in a tensor of shape (500, 20000).\n",
        "\n",
        "##### Timeseries data or sequence data\n",
        "\n",
        "Whenever time matters in your data (or the notion of sequence order), it makes sense to store it in a 3D tensor with an explicit time axis. Each sample can be encoded as a sequence of vectors (a 2D tensor), and thus a batch of data will be encoded as a 3D tensor (see figure 2.3).\n",
        "\n",
        "<img src='./img/fig2.3.png'>\n",
        "\n",
        "\n",
        "The time axis is always the second axis (axis of index 1), by convention. Let’s look at a few examples:\n",
        "\n",
        "- A dataset of stock prices. Every minute, we store the current price of the stock, the highest price in the past minute, and the lowest price in the past minute. Thus every minute is encoded as a 3D vector, an entire day of trading is encoded as a 2D tensor of shape (390, 3) (there are 390 minutes in a trading\n",
        "day), and 250 days’ worth of data can be stored in a 3D tensor of shape (250, 390, 3). Here, each sample would be one day’s worth of data.\n",
        "\n",
        "- A dataset of tweets, where we encode each tweet as a sequence of 280 characters out of an alphabet of 128 unique characters. In this setting, each character can be encoded as a binary vector of size 128 (an all-zeros vector except for a 1 entry at the index corresponding to the character). Then each tweet can be encoded as a 2D tensor of shape (280, 128), and a dataset of 1 million tweets can be stored in a tensor of shape (1000000, 280, 128).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXFWDLX8keVy",
        "colab_type": "text"
      },
      "source": [
        "##### Image data\n",
        "\n",
        "Images typically have three dimensions: height, width, and color depth. Although\n",
        "grayscale images (like our MNIST digits) have only a single color channel and could thus be stored in 2D tensors, by convention image tensors are always 3D, with a onedimensional color channel for grayscale images. A batch of 128 grayscale images of size 256 × 256 could thus be stored in a tensor of shape (128, 256, 256, 1), and a batch of 128 color images could be stored in a tensor of shape (128, 256, 256, 3) (see figure 2.4).\n",
        "\n",
        "<img src='./img/fig2.4.png'>\n",
        "\n",
        "\n",
        "##### Video data\n",
        "\n",
        "Video data is one of the few types of real-world data for which you’ll need 5D tensors. A video can be understood as a sequence of frames, each frame being a color image. Because each frame can be stored in a 3D tensor (height, width, color_depth), a sequence of frames can be stored in a 4D tensor (frames, height, width, color_depth), and thus a batch of different videos can be stored in a 5D tensor of shape (samples, frames, height, width, color_depth).\n",
        "\n",
        "> For instance, a 60-second, 144 × 256 YouTube video clip sampled at 4 frames per second would have 240 frames. A batch of four such video clips would be stored in a tensor of shape (4, 240, 144, 256, 3). That’s a total of 106,168,320 values! If the dtype of the tensor was float32, then each value would be stored in 32 bits, so the tensor would represent 405 MB. Heavy! Videos you encounter in real life are much lighter, because they aren’t stored in float32, and they’re typically compressed by a large factor (such as in the MPEG format)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSDib5V3lQuR",
        "colab_type": "text"
      },
      "source": [
        "### The gears of neural networks: tensor operations\n",
        "\n",
        "Much as any computer program can be ultimately reduced to a small set of binary\n",
        "operations on binary inputs (AND, OR, NOR, and so on), all transformations learned by deep neural networks can be reduced to a handful of tensor operations applied to tensors of numeric data. For instance, it’s possible to add tensors, multiply tensors, and so on.\n",
        "\n",
        "\n",
        "In our initial example, we were building our network by stacking Dense layers on\n",
        "top of each other. A Keras layer instance looks like this:\n",
        "\n",
        "`keras.layers.Dense(512, activation='relu')`\n",
        "\n",
        "This layer can be interpreted as a function, which takes as input a 2D tensor andreturns another 2D tensor—a new representation for the input tensor. Specifically, thefunction is as follows (where W is a 2D tensor and b is a vector, both attributes of the layer):\n",
        "\n",
        "`output = relu(dot(W, input) + b)`\n",
        "\n",
        "\n",
        "Let’s unpack this. We have three tensor operations here: a dot product (dot) between the input tensor and a tensor named W; an addition (+) between the resulting 2D tensor and a vector b; and, finally, a relu operation. relu(x) is max(x, 0)\n",
        "\n",
        "#### Element-wise operations\n",
        "\n",
        "The relu operation and addition are element-wise operations: operations that are\n",
        "applied independently to each entry in the tensors being considered. This means\n",
        "these operations are highly amenable to massively parallel implementations (vectorized implementations, a term that comes from the vector processor supercomputer architecture from the 1970–1990 period). If you want to write a naive Python implementation of an element-wise operation, you use a for loop, as in this naive implementation of an element-wise relu operation:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--PXGAhnlPmm",
        "colab_type": "code",
        "outputId": "8d61538e-e7af-4dc3-8612-dbe3ba99d275",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def naive_relu(x):\n",
        "    assert len(x.shape) == 2 # x should be a 2D np tensor\n",
        "    x1 = x.copy()\n",
        "\n",
        "    for i in range(x.shape[0]):\n",
        "        for j in range(x.shape[1]):\n",
        "            x1[i,j] = max(x[i,j], 0)\n",
        "    return x1\n",
        "\n",
        "def naive_add(x, y):\n",
        "    assert len(x.shape) == 2\n",
        "    assert x.shape == y.shape\n",
        "\n",
        "    x1 = x.copy()\n",
        "\n",
        "    for i in range(x.shape[0]):\n",
        "        for j in range(x.shape[1]):\n",
        "            x1[i, j] = x[i, j] + y[i, j]\n",
        "    return x1\n",
        "\n",
        "a = np.array([\n",
        "              [1,-2,3],\n",
        "              [-3, 8, -1]\n",
        "              ])\n",
        "\n",
        "print (a.shape, naive_relu(a))\n",
        "\n",
        "b = np.array([\n",
        "              [1,4,2],\n",
        "              [0, 5, 7]\n",
        "              ])\n",
        "\n",
        "print (naive_add(a, b))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2, 3) [[1 0 3]\n",
            " [0 8 0]]\n",
            "[[ 2  2  5]\n",
            " [-3 13  6]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GN6OIe6D4jFi",
        "colab_type": "text"
      },
      "source": [
        "In practice, when dealing with Numpy arrays, these operations are available as well optimized built-in Numpy functions, which themselves delegate the heavy lifting to a Basic Linear Algebra Subprograms (BLAS) implementation if you have one installed\n",
        "(which you should). BLAS are low-level, highly parallel, efficient tensor-manipulation routines that are typically implemented in Fortran or C.\n",
        "\n",
        "#### Broadcasting\n",
        "\n",
        "Our earlier naive implementation of naive_add only supports the addition of 2D tensors with identical shapes. But in the Dense layer introduced earlier, we added a 2D tensor with a vector. What happens with addition when the shapes of the two tensors being added differ?\n",
        "When possible, and if there’s no ambiguity, the smaller tensor will be broadcasted to match the shape of the larger tensor. Broadcasting consists of two steps:\n",
        "\n",
        "1. Axes (called broadcast axes) are added to the smaller tensor to match the ndim of the larger tensor.\n",
        "\n",
        "2. The smaller tensor is repeated alongside these new axes to match the full shape of the larger tensor.\n",
        "\n",
        "Let’s look at a concrete example. Consider X with shape (32, 10) and y with shape (10,). This means that X has 32 rows, 10 cols and y has 10 cols. First, we add an empty first axis to y, whose shape becomes (1, 10) - 1 row, 10 cols. Then, we repeat y 32 times alongside this new axis, so that we end up with a tensor Y with shape (32, 10). Each row has the same 10 col values st `Y[i, :] == y for i in range(0, 32)`. At this point, we can proceed to add X and Y, because they have the same shape.\n",
        "\n",
        "In terms of implementation, no new 2D tensor is created, because that would be\n",
        "terribly inefficient. The repetition operation is entirely virtual: it happens at the algorithmic level rather than at the memory level. But thinking of the vector being repeated 10 times alongside a new axis is a helpful mental model. Here’s what a naive implementation would look like:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXcFKryj4T01",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def naive_add_matrix_and_vector(x, y):\n",
        "    assert len(x.shape) == 2\n",
        "    assert len(y.shape) == 1\n",
        "\n",
        "    x1 = x.copy()\n",
        "    for i in range(x.shape[0]): # 0-31\n",
        "        for j in range(x.shape[1]): # 0-9\n",
        "            x1[i,j] = x[i, j] + y[j]\n",
        "    return x1\n",
        "\n",
        "a = np.random.random_integers(low=0, high=9, size=(3, 10))\n",
        "b = np.random.random_integers(low=0, high=9, size=(10,))\n",
        "\n",
        "print (a)\n",
        "print (b)\n",
        "\n",
        "naive_add_matrix_and_vector(a, b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1ky_iswHCAe",
        "colab_type": "text"
      },
      "source": [
        "With broadcasting, you can generally apply two-tensor element-wise operations if one tensor has shape `(a, b, … n, n + 1, … m)` and the other has shape `(n, n + 1, … m)`. The broadcasting will then automatically happen for axes a through n - 1. The following example applies the element-wise maximum operation to two tensors of different shapes via broadcasting:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNqLuZIpHNX5",
        "colab_type": "code",
        "outputId": "130b7eec-28fe-4d18-c510-37ba38ef8b1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "x = np.random.randint(0, 9, size=(3,2,1))\n",
        "y = np.random.randint(0, 9, size=(2,1))\n",
        "\n",
        "print ('x')\n",
        "print (x)\n",
        "print ('y')\n",
        "print (y)\n",
        "print ('max')\n",
        "print (np.maximum(x,y))\n",
        "print ('add')\n",
        "print (x+y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x\n",
            "[[[3]\n",
            "  [7]]\n",
            "\n",
            " [[6]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [1]]]\n",
            "y\n",
            "[[4]\n",
            " [0]]\n",
            "max\n",
            "[[[4]\n",
            "  [7]]\n",
            "\n",
            " [[6]\n",
            "  [0]]\n",
            "\n",
            " [[4]\n",
            "  [1]]]\n",
            "add\n",
            "[[[ 7]\n",
            "  [ 7]]\n",
            "\n",
            " [[10]\n",
            "  [ 0]]\n",
            "\n",
            " [[ 4]\n",
            "  [ 1]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FFqlD7gI7YI",
        "colab_type": "text"
      },
      "source": [
        "The op of both the max and add operations will be size of the larger array x (3,2,1)\n",
        "\n",
        "#### Tensor dot\n",
        "\n",
        "The dot operation, also called a tensor product (not to be confused with an elementwise product) is the most common, most useful tensor operation. Contrary to element-wise operations, it combines entries in the input tensors.\n",
        "\n",
        "The dot operation, also called a tensor product (not to be confused with an elementwise product) is the most common, most useful tensor operation. Contrary to element-wise operations, it combines entries in the input tensors.\n",
        "\n",
        "Mathematically, what does the dot operation do? Let’s start with the dot product of two vectors x and y. It’s computed as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wm96xHKRJeoG",
        "colab_type": "code",
        "outputId": "69347cd6-2089-4ca9-c7e6-8794079955ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def naive_vector_dot(x, y):\n",
        "    assert len(x.shape) == 1 \n",
        "    assert len(y.shape) == 1 \n",
        "    assert x.shape[0] == y.shape[0]\n",
        "\n",
        "    z = 0\n",
        "    for i in range(x.shape[0]):\n",
        "        z += x[i]*y[i]\n",
        "    return z\n",
        "\n",
        "x, y = np.array([1,2,3]), np.array([2,3,4])\n",
        "\n",
        "naive_vector_dot(x,y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2sxfkXbKvcl",
        "colab_type": "text"
      },
      "source": [
        "You’ll have noticed that the dot product between two vectors is a scalar and that only vectors with the same number of elements are compatible for a dot product. You can also take the dot product between a matrix x and a vector y, which returns a vector where the coefficients are the dot products between y and the rows of x.\n",
        "\n",
        "Of course, a dot product generalizes to tensors with an arbitrary number of axes.\n",
        "The most common applications may be the dot product between two matrices. You can take the dot product of two matrices x and y `(dot(x, y))` if and only if `x.shape[1] == y.shape[0]`. The result is a matrix with shape `(x.shape[0], y.shape[1])`, where the coefficients are the vector products between the rows of x and the columns of y.\n",
        "\n",
        "#### Tensor reshaping\n",
        "\n",
        "A third type of tensor operation that’s essential to understand is tensor reshaping. Although it wasn’t used in the Dense layers in our first neural network example, we used it when we preprocessed the digits data before feeding it into our network:\n",
        "train_images = train_images.reshape((60000, 28 * 28))\n",
        "Reshaping a tensor means rearranging its rows and columns to match a target shape. Naturally, the reshaped tensor has the same total number of coefficients as the initial tensor. Reshaping is best understood via simple examples:\n",
        "\n",
        "``` python\n",
        "\n",
        ">>> x = np.array([[0., 1.], [2., 3.], [4., 5.]])\n",
        "\n",
        ">>> print(x.shape) \n",
        "(3, 2)\n",
        "\n",
        ">>> x = x.reshape((6, 1))\n",
        ">>> x\n",
        "\n",
        "array([[ 0.], [ 1.], [ 2.], [ 3.], [ 4.], [ 5.]])\n",
        "\n",
        ">>> x = x.reshape((2, 3))\n",
        ">>> x\n",
        "array([[ 0., 1., 2.], \n",
        "        [ 3., 4., 5.]])\n",
        "```\n",
        "\n",
        "#### A geometric interpretation of deep learning\n",
        "\n",
        "You just learned that neural networks consist entirely of chains of tensor operations and that all of these tensor operations are just geometric transformations of the input data. It follows that you can interpret a neural network as a very complex geometric transformation in a high-dimensional space, implemented via a long series of simple steps. \n",
        "\n",
        "\n",
        "In 3D, the following mental image may prove useful. Imagine two sheets of colored paper: one red and one blue. Put one on top of the other. Now crumple them together into a small ball. That crumpled paper ball is your input data, and each sheet of paper is a class of data in a classification problem. What a neural network (or any other machine-learning model) is meant to do is figure out a transformation of the paper ball that would uncrumple it, so as to make the two classes cleanly separable again. With deep learning, this would be implemented as a series of simple transformations of the 3D space, such as those you could apply on the paper ball with your fingers, one movement at a time.\n",
        "\n",
        "Uncrumpling paper balls is what machine learning is about: finding neat representations for complex, highly folded data manifolds. At this point, you should have a pretty good intuition as to why deep learning excels at this: it takes the approach of incrementally decomposing a complicated geometric transformation into a long chain of elementary ones, which is pretty much the strategy a human would follow to uncrumple a paper ball. Each layer in a deep network applies a transformation that disentangles the data a little—and a deep stack of layers makes tractable an extremely complicated disentanglement process."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6KFXgcSiPue",
        "colab_type": "text"
      },
      "source": [
        "### The engine of neural networks: gradient-based optimization\n",
        "\n",
        "As you saw in the previous section, each neural layer from our first network example transforms its input data as follows: `output = relu(dot(W, input) + b)` In this expression, W and b are tensors that are attributes of the layer. They’re called the weights or trainable parameters of the layer (the kernel and bias attributes, respectively). These weights contain the information learned by the network from exposure to training data. \n",
        "\n",
        "Initially, these weight matrices are filled with small random values (a step called random initialization). Of course, there’s no reason to expect that `relu(dot(W, input) + b)`, when W and b are random, will yield any useful representations. The resulting representations are meaningless—but they’re a starting point. What comes next is to gradually adjust these weights, based on a feedback signal. This gradual adjustment, also called training, is basically the learning that machine learning is all about. This happens within what’s called a training loop, which works as follows. Repeat these steps in a loop, as long as necessary: \n",
        "\n",
        "1. Draw a batch of training samples x and corresponding targets y. \n",
        "2. Run the network on x (a step called the forward pass) to obtain predictions y_pred. \n",
        "3. Compute the loss of the network on the batch, a measure of the mismatch between y_pred and y.\n",
        "4. Update all weights of the network in a way that slightly reduces the loss on this batch.\n",
        "\n",
        "You’ll eventually end up with a network that has a very low loss on its training data: a low mismatch between predictions y_pred and expected targets y. The network has “learned” to map its inputs to correct targets. From afar, it may look like magic, but when you reduce it to elementary steps, it turns out to be simple.\n",
        "\n",
        "Step 1 sounds easy enough—just I/O code. Steps 2 and 3 are merely the application of a handful of tensor operations, so you could implement these steps purely from what you learned in the previous section. The difficult part is step 4: updating the network’s weights. Given an individual weight coefficient in the network, how can you compute whether the coefficient should be increased or decreased, and by how much?\n",
        "\n",
        "One naive solution would be to freeze all weights in the network except the one scalar coefficient being considered, and try different values for this coefficient. Let’s say the initial value of the coefficient is 0.3. After the forward pass on a batch of data, the loss of the network on the batch is 0.5. If you change the coefficient’s value to 0.35 and rerun the forward pass, the loss increases to 0.6. But if you lower the coefficient to 0.25, the loss falls to 0.4. In this case, it seems that updating the coefficient by -0.05 would contribute to minimizing the loss. This would have to be repeated for all coefficients in the network.\n",
        "\n",
        "But such an approach would be horribly inefficient, because you’d need to compute two forward passes (which are expensive) for every individual coefficient (of which there are many, usually thousands and sometimes up to millions). A much better approach is to take advantage of the fact that all operations used in the network are differentiable, and compute the gradient of the loss with regard to the network’s coefficients. You can then move the coefficients in the opposite direction from the gradient, thus decreasing the loss.\n",
        "\n",
        "#### Derivative of a tensor operation: the gradient\n",
        "\n",
        "A gradient is the derivative of a tensor operation. It’s the generalization of the concept of derivatives to functions of multidimensional inputs: that is, to functions that take tensors as inputs.\n",
        "\n",
        "Consider an input vector x, a matrix W, a target y, and a loss function loss. You can use W to compute a target candidate y_pred, and compute the loss, or mismatch, between the target candidate y_pred and the target y:\n",
        "\n",
        "```\n",
        "y_pred = dot(W, x) \n",
        "loss_value = loss(y_pred, y)\n",
        "```\n",
        "If the data inputs x and y are frozen, then this can be interpreted as a function mapping values of W to loss values:\n",
        "\n",
        "`loss_value = f(W)`\n",
        "\n",
        "Say the current value of W is W0. The derivative of f at W0 is a tensor: `gradient(f)(W0)`, with same shape as W0, where each coeff `gradient(f) (W0)[i, j]` indicates the direction and magnitude of the change in loss_value you observe when modifying `W0[i, j]`. That tensor `gradient(f)(W0)` is the gradient of the function `f(W) = loss_value` in W0.\n",
        "\n",
        "You saw earlier that the derivative of a function f(x) of a single coefficient can be interpreted as the slope of the curve of f. Likewise, gradient(f)(W0) can be interpreted as the tensor describing the curvature of f(W) around W0.\n",
        "\n",
        "\n",
        "For this reason, in much the same way that, for a function f(x), you can reduce the value of f(x) by moving x a little in the opposite direction from the derivative, with a function f(W) of a tensor, you can reduce f(W) by moving W in the opposite direction from the gradient: for example, W1 = W0 - step * gradient(f)(W0) (where step is a small scaling factor)\n",
        "\n",
        "That means going against the curvature, which intuitively should put you lower on the curve. **Note that the scaling factor step is needed because gradient(f)(W0) only approximates the curvature when you’re close to W0, so you don’t want to get too far from W0.**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwzlAdkAesat",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zrmgpy3iesXf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpsLZfsjesU8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2W8juWFesRz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yaagu_Y4esOT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itZZRrZJesHy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6hqHF4ZLKN4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpxPjuDbJHRE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJbs53wqJHno",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jL2ktqmJH7p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbeC5Vm7JIN1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsBcvKOtJIWd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFlTuuIpJIT7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ser-YX1ZHXWc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}