{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of 3_2_sgd_momentum_adam.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShaunakSen/Deep-Learning/blob/master/Copy_of_3_2_sgd_momentum_adam.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "76f331e42b18f90c2798827fd09f7916",
          "grade": false,
          "grade_id": "cell-64f625d2f2a95421",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "Lds6P7gkDOJ0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Part 2: Stochastic Gradient Descent, Momentum, and Adam"
      ]
    },
    {
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "7f0ff2c2c93f9726d6df73febe04ee97",
          "grade": false,
          "grade_id": "cell-4298e9d3fced7f34",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "5lIB5xINDOJ3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### For this part of the lab, using the same data and setup as in Part 1, compare how stochastic gradient descent (SGD), SGD with momentum, and ADAM will perform. You are free to write all of the code on your own, or if you prefer, you can fill in the missing sections in the code below."
      ]
    },
    {
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "d1c4e30f2dcd1eaf1c6aa91f689bf6d7",
          "grade": false,
          "grade_id": "cell-d5a58ae230138c8a",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "1WrKKVdfDOJ7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Start by reusing some of the functions you have coded for Part 1 to compute the hypothesis, the gradient of the cost function, and the cost function. This code will then be used by the next section of the workbook."
      ]
    },
    {
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "14db73c902e1aba6fd752b6e28234498",
          "grade": true,
          "grade_id": "cell-f09153a723d1bb21",
          "locked": false,
          "points": 0,
          "schema_version": 1,
          "solution": true
        },
        "id": "hsivd4EsDOJ9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "outputId": "f8e48e29-59e8-4ae0-dd53-04b4c8316a0c"
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "## generate M data points roughly forming a line (noise added)\n",
        "M = 50\n",
        "theta_true = torch.Tensor([[0.5], [2]])\n",
        "\n",
        "X = 10 * torch.rand(M, 2) - 5\n",
        "X[:, 1] = 1.0\n",
        "\n",
        "y = torch.mm(X, theta_true) + 0.3 * torch.randn(M, 1)\n",
        "\n",
        "plt.scatter(X[:,0].numpy(), y.numpy().reshape(1,M)[0]);\n",
        "plt.xlabel(\"X\");\n",
        "plt.ylabel(\"y\");\n",
        "\n",
        "## hypothesis computes $h_theta$\n",
        "def hypothesis(theta, X):\n",
        "    # YOUR CODE HERE\n",
        "    \n",
        "    return X.mm(theta)\n",
        "  \n",
        "    \n",
        "    # raise NotImplementedError()\n",
        "\n",
        "## grad_cost_func computes the gradient of J for linear regression given J is the MSE \n",
        "def grad_cost_func(theta, X, y): \n",
        "    # YOUR CODE HERE\n",
        "    \n",
        "    M = X.shape[0]\n",
        "    \n",
        "    grad = (1/M) * X.t().mm(hypothesis(theta, X) - y)\n",
        "    \n",
        "    # raise NotImplementedError()\n",
        "    \n",
        "    return grad\n",
        "\n",
        "## cost_func computes the cost function J\n",
        "def cost_func(theta, X, y): \n",
        "    \"\"\"\n",
        "    This func should accept a matrix where each row is a value of theta_0 and theta_1\n",
        "    \n",
        "    It should return a list of losses for such rows\n",
        "    \n",
        "    cost_func(this_theta,X,y)[0] <- only one loss value comes as we are computing loss for only one theta\n",
        "    \n",
        "    J_grid = cost_func(theta_grid.t(), X, y) : 100 loss values for each pair of theta value from theta_grid()\n",
        "    \n",
        "    This will help us plot the fig in RHS (for 100 vals of theta_1 what was the loss)\n",
        "    \n",
        "    \"\"\"\n",
        "\n",
        "    M = X.shape[0]\n",
        "    \n",
        "    # print (theta)\n",
        "    \n",
        "    # print(theta.shape)\n",
        "    \n",
        "    loss_values = []\n",
        "    number_of_thetas = theta.shape[1]\n",
        "    \n",
        "    # for each theta pair compute the loss\n",
        "    \n",
        "    for i in range(number_of_thetas):\n",
        "      theta_value = theta[:,i].reshape(2,1)      \n",
        "     \n",
        "      h_theta = hypothesis(theta_value, X)\n",
        "      \n",
        "      loss = (1/(2*M)) * ((h_theta-y).t().mm(h_theta-y))\n",
        "      loss = loss.item()\n",
        "      loss_values.append(loss)\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    return loss_values"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe0AAAFYCAYAAAB+s6Q9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "34e932803ed631e6d14a1f09103b98c2",
          "grade": false,
          "grade_id": "cell-4f05371072d188fa",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "sFMw-ZPnDOKD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Now we'd like to compare how stochastic gradient descent (SGD), SGD with momentum, and ADAM will run over weight updates. Complete the defined functions below and make sure to add the parameters which may need to be passed into the functions as well. Plot the weight updates over the contour plot using varying colours. Note, for clarity, you may only want to plot some of the updates."
      ]
    },
    {
      "metadata": {
        "id": "DK5IxhB_ebXn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ac3b0380-b879-471d-b6bc-3e9569608b95"
      },
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([50, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "dc258f32732e143ee8c8ad9b25b34096",
          "grade": true,
          "grade_id": "cell-5189819c97d93617",
          "locked": false,
          "points": 10,
          "schema_version": 1,
          "solution": true
        },
        "id": "Z3_XuhZLDOKE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "b1c2b744-b20d-46fa-cdb9-8befb4c2c30c"
      },
      "cell_type": "code",
      "source": [
        "## The weight update computed using the ADAM optimisation algorithm\n",
        "def weightupdate_adam(count, X, y):\n",
        "    # YOUR CODE HERE\n",
        "    raise NotImplementedError()\n",
        "\n",
        "## The weight update computed using SGD + momentum\n",
        "def weightupdate_sgd_momentum(count, X, y):\n",
        "    # YOUR CODE HERE\n",
        "    raise NotImplementedError()\n",
        "\n",
        "## The weight updated computed using SGD\n",
        "def weigthupdate_sgd(count, X, y):\n",
        "    # YOUR CODE HERE\n",
        "    raise NotImplementedError()\n",
        "\n",
        "N = 200\n",
        "beta_1 = 0.9\n",
        "beta_2 = 0.999\n",
        "alpha = 0.01\n",
        "\n",
        "theta_0 = torch.Tensor([[2],[4]]) #initialise\n",
        "\n",
        "# Write the code that will call of the optimisation update functions and compute weight updates for each individual data point over N iterations.\n",
        "\n",
        "# YOUR CODE HERE\n",
        "\n",
        "\n",
        "theta_0_vals = np.linspace(-2,4,100)\n",
        "theta_1_vals = np.linspace(0,4,100)\n",
        "# theta = torch.Tensor(len(theta_0_vals),2)\n",
        "\n",
        "theta_0 = torch.Tensor([[0.0], [2.0]]) #initialise \n",
        "\n",
        "theta = torch.Tensor(2,N,M)\n",
        "\n",
        "last_theta = theta_0\n",
        "\n",
        "for j in range(N):\n",
        "  # for each iteration\n",
        "  for index in range(X.shape[0]):\n",
        "    # for each data pt\n",
        "    x_data = X[index].reshape(1,2)\n",
        "    y_data = y[index].reshape(1,1)\n",
        "    # print(x_data.shape)\n",
        "    grad = grad_cost_func(last_theta, x_data, y_data)\n",
        "    this_theta = last_theta - alpha*grad\n",
        "    last_theta = this_theta\n",
        "    \n",
        "print(last_theta)\n",
        "    \n",
        "  \n",
        "  \n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Compute the value of the cost function, J, over all the thetas in order to plot the contour below.\n",
        "# YOUR CODE HERE\n",
        "raise NotImplementedError()\n",
        "\n",
        "xc,yc = np.meshgrid(theta_0_vals, theta_1_vals)\n",
        "contours = plt.contour(xc, yc, J, 20)\n",
        "\n",
        "# Now plot the output of SGD, momentum and Adam all on the same plot for comparison\n",
        "# YOUR CODE HERE\n",
        "raise NotImplementedError()\n",
        "\n",
        "\"\"\""
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.5562],\n",
            "        [1.9831]])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\n# Compute the value of the cost function, J, over all the thetas in order to plot the contour below.\\n# YOUR CODE HERE\\nraise NotImplementedError()\\n\\nxc,yc = np.meshgrid(theta_0_vals, theta_1_vals)\\ncontours = plt.contour(xc, yc, J, 20)\\n\\n# Now plot the output of SGD, momentum and Adam all on the same plot for comparison\\n# YOUR CODE HERE\\nraise NotImplementedError()\\n\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "metadata": {
        "id": "uDuQi-T1DOKK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}