{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural Network Programming PyTorch.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShaunakSen/Deep-Learning/blob/master/Neural_Network_Programming_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "jHpDbV6XnS6B",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Neural Network Programming - Deep Learning \n",
        "\n",
        "[Playlist link](https://www.youtube.com/watch?v=iTKbyFh-7GM&list=PLZbbT5o_s2xrfNyHZsM6ufI0iZENK9xgG&index=2)\n",
        "\n",
        "### PyTorch - Python deep learning neural network API\n",
        "\n",
        "\n",
        "**A tensor is an n-dimensional array.**\n",
        "\n",
        "With PyTorch tensors, GPU support is built-in. It’s very easy with PyTorch to move tensors to and from a GPU if we have one installed on our system.\n",
        "\n",
        "![](./img/diag1.png)\n",
        "\n",
        "Let’s talk about the prospects for learning PyTorch. For beginners to deep learning and neural networks, the top reason for learning PyTorch is that it is a thin framework that stays out of the way.\n",
        "\n",
        "**PyTorch is thin and stays out of the way!**\n",
        "\n",
        "When we build neural networks with PyTorch, we are super close to programming neural networks from scratch. The experience of programming in PyTorch is as close as it gets to the real thing.\n",
        "\n",
        "A common PyTorch characteristic that often pops up is that it’s great for research. The reason for this research suitability has do do with a technical design consideration. To optimize neural networks, we need to calculate derivatives, and to do this computationally, deep learning frameworks use what are called [computational graphs](http://colah.github.io/posts/2015-08-Backprop/).\n",
        "\n",
        "Computational graphs are used to graph the function operations that occur on tensors inside neural networks.\n",
        "\n",
        "\n",
        "These graphs are then used to compute the derivatives needed to optimize the neural network. PyTorch uses a computational graph that is called a dynamic computational graph. This means that the graph is generated on the fly as the operations are created.\n",
        "\n",
        "This is in contrast to static graphs that are fully determined before the actual operations occur.\n",
        "\n",
        "It just so happens that many of the cutting edge research topics in deep learning are requiring or benefiting greatly from dynamic graphs.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "2-qcCI75nS6C",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9AvkNEKWnS6H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cdb08390-24c6-42d6-bd8b-d54d97154da7"
      },
      "cell_type": "code",
      "source": [
        "t = torch.tensor([1,2,3]) # created on CPU by default\n",
        "\n",
        "# so any operation we do on this tensor will be carried out in the CPU\n",
        "\n",
        "t"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "BZWkCUMcnS6Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "02ab554c-1545-4cf1-cb35-f2cb996152c7"
      },
      "cell_type": "code",
      "source": [
        "# move tensor t onto GPU: Returns a copy of this object in CUDA memory.\n",
        "\n",
        "t = t.cuda()\n",
        "\n",
        "t"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "avZAXpJsoX3_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Why Deep Learning and Neural Networks uses GPUs\n",
        "\n",
        "\n",
        "#### Graphics processing unit (GPU)\n",
        "\n",
        "To understand CUDA, we need to have a working knowledge of graphics processing units (GPUs). A GPU is a processor that is good at handling specialized computations.\n",
        "\n",
        "This is in contrast to a central processing unit (CPU), which is a processor that is good at handling general computations. CPUs are the processors that power most of the typical computations on our electronic devices.\n",
        "\n",
        "A GPU can be much faster at computing than a CPU. However, this is not always the case. The speed of a GPU relative to a CPU depends on the type of computation being performed. The type of computation most suitable for a GPU is a computation that can be done in parallel.\n",
        "\n",
        "The number of tasks that a larger task can be broken into depends on the number of cores contained on a particular piece of hardware. Cores are the units that actually do the computation within a given processor, and CPUs typically have four, eight, or sixteen cores while GPUs have potentially thousands.\n",
        "\n",
        "With this working knowledge, we can conclude that parallel computing is done using GPUs, and we can also conclude that tasks which are best suited to be solved using a GPU are tasks that can be done in parallel. If a computation can be done in parallel, we can accelerate our computation using parallel programming approaches and GPUs.\n",
        "\n",
        "#### Neural networks are embarrassingly parallel\n",
        "\n",
        "Let’s turn our attention now to neural networks and see why GPUs are used so heavily in deep learning. We have just seen that GPUs are well suited for parallel computing, and this fact about GPUs is why deep learning uses them. Neural networks are embarrassingly parallel.\n",
        "\n",
        "In parallel computing, an embarrassingly parallel task is one where little or no effort is needed to separate the overall task into a set of smaller tasks to be computed in parallel.\n",
        "\n",
        "Tasks that embarrassingly parallel are ones where it’s easy to see that the set of smaller tasks are independent with respect to each other.\n",
        "\n",
        "Neural networks are embarrassingly parallel for this reason. Many of the computations that we do with neural networks can be easily broken into smaller computations in such a way that the set of smaller computations do not depend on one another. One such example is a convolution.\n",
        "\n",
        "Let’s look at an example, the convolution operation:\n",
        "\n",
        "![](http://deeplizard.com/images/same_padding_no_strides.gif)\n",
        "\n",
        "This animation showcases the convolution process without numbers. We have an input channel in blue on the bottom. A convolutional filter shaded on the bottom that is sliding across the input channel, and a green output channel:\n",
        "\n",
        "- Blue (bottom) - Input channel\n",
        "- Shaded (on top of blue) - 3 x 3 convolutional filter\n",
        "- Green (top) - Output channel\n",
        "\n",
        "For each position on the blue input channel, the 3 x 3 filter does a computation that maps the shaded part of the blue input channel to the corresponding shaded part of the green output channel.\n",
        "\n",
        "In the animation, these computations are happening sequentially one after the other. However, each computation is independent from the others, meaning that none of the computations depend on the results of any of the other computations.\n",
        "\n",
        "As a result of this, all of these independent computations can happen in parallel on a GPU and the overall output channel can be produced.\n",
        "\n",
        "This allows us to see that the convolution operation can be accelerated by using a parallel programming approach and GPUs.\n",
        "\n",
        "This is where CUDA comes into the picture. Nvidia is a technology company that designs GPUs, and they have created CUDA as a software platform that pairs with their GPU hardware making it easier for developers to build software that accelerates computations using the parallel processing power of Nvidia GPUs.\n",
        "\n",
        "As a result, you might have guessed that an Nvidia GPU is required to use CUDA, and CUDA can be downloaded and installed from Nvidia’s website for free.\n",
        "\n",
        "Developers use CUDA by downloading the CUDA toolkit. With the toolkit comes specialized libraries like cuDNN, the CUDA Deep Neural Network library.\n",
        "\n",
        "One of the benefits of using PyTorch, or any other neural network API is that parallelism comes baked into the API. This means that as neural network programmers, we can focus more on building neural networks and less on performance issues.\n",
        "\n",
        "With PyTorch, CUDA comes baked in from the start. There are no additional downloads required. All we need is to have a supported Nvidia GPU, and we can leverage CUDA using PyTorch. We don’t need to know how to use the CUDA API directly.\n",
        "\n",
        "#### GPU can be slower than CPU\n",
        "\n",
        "We said that we can selectively run our computations on the GPU or the CPU, but why not just run every computation on the GPU?\n",
        "\n",
        "The answer is that a GPU is only faster for particular (specialized) tasks. One issue that we can run into is bottlenecks that slow our performance. For example, moving data from the CPU to the GPU is costly, so in this case, the overall performance might be slower if the computation task is a simple one.\n",
        "\n",
        "Moving relatively small computational tasks to the GPU won’t speed us up very much and may indeed slow us down. Remember, the GPU works well for tasks that can be broken into many smaller tasks, and if a compute task is already small, we won’t have much to gain by moving the task to the GPU.\n",
        "\n",
        "For this reason, it’s often acceptable to simply use a CPU when just starting out, and as we tackle larger more complicated problems, begin using the GPU more heavily.\n",
        "\n",
        "In the beginning, the main tasks that were accelerated using GPUs were computer graphics. Hence the name graphics processing unit, but in recent years, many more varieties parallel tasks have emerged. One such task as we have seen is deep learning.\n",
        "\n",
        "Deep learning along with many other scientific computing tasks that use parallel programming techniques are leading to a new type of programming model called GPGPU or general purpose GPU computing.\n",
        "\n",
        "When we hear Jensen talk about the GPU computing stack, he is referring to the GPU as the hardware on the bottom, CUDA as the software architecture on top of the GPU, and finally libraries like cuDNN on top of CUDA.\n",
        "\n",
        "This GPU computing stack is what supports general purpose computing capabilities on a chip that is otherwise very specialized. We often see stacks like this in computer science as technology is built in layers, just like neural networks.\n",
        "\n",
        "Sitting on top of CUDA and cuDNN is PyTorch, which is the framework were we’ll be working that ultimately supports applications on top.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "01tojF7KUVC_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    }
  ]
}