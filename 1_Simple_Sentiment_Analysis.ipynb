{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1 - Simple Sentiment Analysis.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShaunakSen/Deep-Learning/blob/master/1_Simple_Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "lBKszNgw1Daf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Simple Sentiment Analysis\n",
        "\n",
        "[tutorial link](https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/1%20-%20Simple%20Sentiment%20Analysis.ipynb)\n",
        "\n",
        "\n",
        "In this series we'll be building a machine learning model to detect sentiment (i.e. detect if a sentence is positive or negative) using PyTorch and TorchText. This will be done on movie reviews, using the IMDb dataset.\n",
        "\n",
        "In this first notebook, we'll start very simple to understand the general concepts whilst not really caring about good results. Further notebooks will build on this knowledge and we'll actually get good results.\n",
        "\n",
        "### Introduction\n",
        "\n",
        "We'll be using a recurrent neural network (RNN) as they are commonly used in analysing sequences. An RNN takes in sequence of words, X={x1,...,xT}, one at a time, and produces a hidden state, h, for each word. We use the RNN recurrently by feeding in the current word xt as well as the hidden state from the previous word, ht−1, to produce the next hidden state, ht.\n",
        "\n",
        "ht=RNN(xt,ht−1)\n",
        "Once we have our final hidden state, hT, (from feeding in the last word in the sequence, xT) we feed it through a linear layer, f, (also known as a fully connected layer), to receive our predicted sentiment, ŷ =f(hT).\n",
        "\n",
        "Below shows an example sentence, with the RNN predicting zero, which indicates a negative sentiment. The RNN is shown in orange and the linear layer shown in silver. Note that we use the same RNN for every word, i.e. it has the same parameters. The initial hidden state, h0, is a tensor initialized to all zeros.\n",
        "\n",
        "![](https://nbviewer.jupyter.org/github/bentrevett/pytorch-sentiment-analysis/blob/master/assets/sentiment1.png)\n",
        "\n",
        "Note: some layers and steps have been omitted from the diagram, but these will be explained later.\n",
        "\n",
        "### Preparing Data\n",
        "\n",
        "One of the main concepts of TorchText is the Field. These define how your data should be processed. In our sentiment classification task the data consists of both the raw string of the review and the sentiment, either \"pos\" or \"neg\".\n",
        "\n",
        "The parameters of a Field specify how the data should be processed.\n",
        "\n",
        "We use the TEXT field to define how the review should be processed, and the LABEL field to process the sentiment.\n",
        "\n",
        "Our TEXT field has tokenize='spacy' as an argument. This defines that the \"tokenization\" (the act of splitting the string into discrete \"tokens\") should be done using the spaCy tokenizer. If no tokenize argument is passed, the default is simply splitting the string on spaces.\n",
        "\n",
        "LABEL is defined by a LabelField, a special subset of the Field class specifically used for handling labels. We will explain the dtype argument later.\n",
        "\n",
        "For more on Fields, go here.\n",
        "\n",
        "We also set the random seeds for reproducibility."
      ]
    },
    {
      "metadata": {
        "id": "hyA3jQkr1B2_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchtext import data\n",
        "\n",
        "SEED = 1234\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "TEXT = data.Field(tokenize='spacy')\n",
        "LABEL = data.LabelField(dtype = torch.float)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I_bduG2X3D9g",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Another handy feature of TorchText is that it has support for common datasets used in natural language processing (NLP).\n",
        "\n",
        "The following code automatically downloads the IMDb dataset and splits it into the canonical train/test splits as torchtext.datasets objects. It process the data using the Fields we have previously defined. The IMDb dataset consists of 50,000 movie reviews, each marked as being a positive or negative review."
      ]
    },
    {
      "metadata": {
        "id": "rMzRpLuX2yOX",
        "colab_type": "code",
        "outputId": "894464c7-eddd-4993-e6d5-4b1e1ab4fd08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "from torchtext import datasets\n",
        "\n",
        "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "downloading aclImdb_v1.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:08<00:00, 10.3MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "y6Dn9nxu5R8Z",
        "colab_type": "code",
        "outputId": "9a16669d-3632-4522-a86b-159ca75fd035",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "print(f'Number of training examples: {len(train_data)}')\n",
        "print(f'Number of testing examples: {len(test_data)}')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 25000\n",
            "Number of testing examples: 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oXvL3EVa9jgD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We can also check an example.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "Ap1-78A15a9S",
        "colab_type": "code",
        "outputId": "9bc23eb2-2958-49fc-b1b7-deb786929182",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "print(vars(train_data.examples[0]))\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'text': ['Now', 'let', 'me', 'tell', 'you', 'about', 'this', 'movie', ',', 'this', 'movie', 'is', 'MY', 'FAVORITE', 'MOVIE', '!', '!', '!', 'This', 'movie', 'has', 'excellent', 'combat', 'fighting', '.', 'This', 'movie', 'does', 'sound', 'like', 'a', 'silly', 'story', 'line', 'about', 'how', 'Jet', 'Li', 'plays', 'a', 'super', 'hero', ',', 'like', 'Spider', '-', 'Man', ',', 'or', 'etc', '.', 'But', 'once', 'you', \"'ve\", 'seen', 'this', 'movie', ',', 'you', 'would', 'probably', 'want', 'to', 'see', 'it', 'again', 'and', 'again', '.', 'I', 'rate', 'this', 'movie', '10/10', '.'], 'label': 'pos'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9lz96xNR9slD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The IMDb dataset only has train/test splits, so we need to create a validation set. We can do this with the .split() method.\n",
        "\n",
        "By default this splits 70/30, however by passing a split_ratio argument, we can change the ratio of the split, i.e. a split_ratio of 0.8 would mean 80% of the examples make up the training set and 20% make up the validation set.\n",
        "\n",
        "We also pass our random seed to the random_state argument, ensuring that we get the same train/validation split each time."
      ]
    },
    {
      "metadata": {
        "id": "KWlnIs-m9uVT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "train_data, valid_data = train_data.split(random_state = random.seed(SEED))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TreazdS49_nC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "e6ce580a-4056-4a59-bbee-04cdd6d56758"
      },
      "cell_type": "code",
      "source": [
        "print(f'Number of training examples: {len(train_data)}')\n",
        "print(f'Number of validation examples: {len(valid_data)}')\n",
        "print(f'Number of testing examples: {len(test_data)}')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 17500\n",
            "Number of validation examples: 7500\n",
            "Number of testing examples: 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "768Kz4eW-N2U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "711c9c71-9626-4d25-ae7d-fa661ef445b7"
      },
      "cell_type": "code",
      "source": [
        "print (vars(valid_data.examples[0]))\n",
        "print (vars(test_data.examples[0]))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'text': ['This', 'is', 'a', 'tongue', 'in', 'cheek', 'movie', 'from', 'the', 'very', 'outset', 'with', 'a', 'voice', '-', 'over', 'that', 'pokes', 'fun', 'at', 'everything', 'French', 'and', 'then', 'produces', 'a', 'rather', 'naif', 'but', 'very', 'brave', 'hero', 'in', 'Fanfan', 'La', 'Tulipe', '.', 'Portrayed', 'by', 'the', 'splendid', 'Gerard', 'Philippe', ',', 'the', 'dashing', 'young', 'man', 'believes', 'utterly', 'in', 'the', 'fate', 'curvaceous', 'Lollobrigida', 'foretells', '-', 'notably', 'that', 'he', 'will', 'marry', 'King', 'Louis', 'XV', \"'s\", 'daughter', '!', 'Problem', 'is', ',', 'La', 'Lollo', 'soon', 'find', 'outs', 'she', 'too', 'is', 'in', 'love', 'with', 'Fanfan', '...', '<br', '/><br', '/>Propelled', 'by', 'good', 'sword', 'fights', ',', 'cavalcades', ',', 'and', 'other', 'spirited', 'action', 'sequences', 'the', 'film', 'moves', 'at', 'a', 'brisk', 'pace', 'and', 'with', 'many', 'comic', 'moments', '.', 'The', 'direction', 'is', 'perhaps', 'the', 'weakest', 'aspect', 'but', 'the', 'film', 'is', 'so', 'light', 'and', 'takes', 'itself', 'so', 'un', '-', 'seriously', 'that', 'I', 'could', 'not', 'give', 'those', 'shortcomings', 'a', 'second', 'thought', '.', 'Look', 'out', 'for', 'Noel', 'Roquevert', ',', 'a', 'traditional', 'heavy', 'in', 'French', 'films', ',', 'trying', 'to', 'steal', 'La', 'Lollo', ',', 'making', 'himself', 'a', 'nuisance', ',', 'and', 'feeding', 'the', 'script', 'to', 'the', 'fortune', 'teller', 'that', 'reads', 'La', 'Lollo', \"'s\", 'hand', '!', 'And', 'what', 'a', 'gem', 'Marcel', 'Herrand', 'is', 'as', 'the', 'megalomanous', 'and', 'lust', '-', 'driven', 'King', 'Louis', 'XV', '!', 'That', 'is', 'not', 'all', ':', 'So', 'many', 'beautiful', 'women', 'in', 'one', 'film', 'makes', 'me', 'wish', 'I', 'were', 'in', 'France', 'and', 'on', 'the', 'set', 'back', 'in', '1952', '!', 'The', 'film', 'may', 'have', 'come', 'out', 'that', 'year', 'but', 'its', 'verve', ',', 'cheek', ',', 'superb', 'narration', ',', 'immaculate', 'photography', 'and', 'the', 'memorable', 'Gerard', 'Philippe', 'ensure', 'that', 'it', 'remains', 'modern', 'and', 'a', 'pleasure', 'to', 'watch', '.', 'I', 'would', 'not', 'hesitate', 'to', 'recommend', 'it', 'to', 'my', 'grandchildren', 'let', 'alone', 'to', 'anyone', 'who', 'loves', 'movies', 'in', 'general', 'and', 'swashbucklers', 'in', 'particular', '!', 'Do', 'see', 'it', '!'], 'label': 'pos'}\n",
            "{'text': ['The', 'title', 'is', 'a', 'reference', 'to', 'the', 'destruction', 'of', 'the', 'remnants', 'of', 'a', 'harvest', ',', 'like', 'rice', 'husks', ',', 'by', 'farmers', 'who', 'burn', 'them', 'creating', 'fires', 'on', 'the', 'plains', '.', 'This', 'is', 'a', 'bleak', 'tale', 'of', 'the', 'destruction', 'of', 'the', 'Japanese', 'soldier.<br', '/><br', '/>The', 'story', 'is', 'set', 'in', 'the', 'closing', 'days', 'of', 'the', 'Philippines', 'campaign', 'as', 'a', 'soldier', 'with', 'TB', 'who', 'returns', 'from', 'a', 'hospital', 'because', 'since', 'he', 'can', 'walk', ',', 'they', 'have', 'no', 'room', 'for', 'him', '.', 'His', 'superior', 'officers', 'do', \"n't\", 'want', 'him', 'around', 'since', 'he', \"'s\", 'really', 'too', 'sick', 'to', 'work', 'or', 'fight', '.', 'Abused', 'by', 'his', 'officer', 'he', \"'s\", 'sent', 'back', 'to', 'the', 'hospital', 'with', 'orders', 'to', 'either', 'be', 'admitted', 'or', 'kill', 'himself', '.', 'They', 'still', 'wo', \"n't\", 'take', 'him', 'and', 'he', \"'s\", 'soon', 'left', 'to', 'wander', 'across', 'the', 'war', 'ravaged', 'landscape', 'trying', 'to', 'find', 'help', 'or', 'a', 'place', 'to', 'stay', 'or', 'even', 'just', 'food', '.', 'Its', 'a', 'bleak', 'journey', 'with', 'no', 'hope', 'in', 'sight', 'and', 'only', 'death', 'and', 'man', \"'s\", 'inhumanity', 'to', 'man', 'at', 'every', 'turn.<br', '/><br', '/>Billed', 'as', 'a', 'harrowing', 'journey', 'into', 'the', 'dark', 'heart', 'of', 'man', 'and', 'war', 'this', 'is', 'also', 'a', 'very', 'funny', 'movie', '.', 'This', 'is', \"n't\", 'to', 'say', 'its', 'not', 'horrifying', ',', 'it', 'is', 'at', 'times', ',', 'but', 'its', 'also', 'darkly', 'comic', '.', 'How', 'could', 'it', 'not', 'be', '?', 'Here', 'is', 'a', 'film', 'where', 'madness', 'and', 'insanity', 'run', 'rampant', ',', 'people', 'are', 'constantly', 'trying', 'to', 'hustle', 'tobacco', 'leaves', 'for', 'food', ',', 'trying', 'to', 'get', 'even', 'a', 'slightly', 'better', 'pair', 'of', 'shoes', ',', 'trying', 'to', 'remain', 'a', 'Japanese', 'soldier', 'in', 'the', 'face', 'of', 'absurdity', 'by', 'marching', 'constantly', 'but', 'never', 'getting', 'anywhere', 'and', 'you', 'ca', \"n't\", 'help', 'but', 'laugh', '.', 'To', 'be', 'sure', 'things', 'go', 'darker', 'as', 'it', 'becomes', 'clear', 'that', 'cannibalism', 'maybe', ',', 'literally', 'and', 'figuratively', ',', 'the', 'only', 'way', 'to', 'survive', ',', 'but', 'at', 'the', 'same', 'time', 'there', 'is', 'something', 'uncomfortably', 'funny', 'about', 'the', 'human', 'comedy.<br', '/><br', '/>Hailed', 'as', 'a', 'great', 'anti', '-', 'war', 'film', 'its', 'stark', 'photographic', 'style', 'makes', 'clear', 'the', 'insanity', 'of', 'war', 'even', 'as', 'it', 'dazzles', 'our', 'eye', 'with', 'its', 'beauty', '.', 'Here', 'we', 'see', 'landscapes', 'full', 'of', 'bodies', 'that', 'include', 'the', 'soldier', 'and', 'the', 'civilian', '.', 'set', 'amid', 'fields', 'forests', 'and', 'trees', 'that', 'would', 'otherwise', 'be', ',', 'and', 'to', 'some', 'extent', 'still', 'are', ',', 'quite', 'beautiful', '.', 'Its', 'a', 'jarring', 'sensation.<br', '/><br', '/>What', 'intriguing', 'is', 'that', 'I', 'read', 'that', 'this', 'is', 'based', 'on', 'a', 'novel', 'about', 'the', 'redemptive', 'power', 'of', 'Christianity', '.', 'The', 'director', 'removed', 'all', 'over', 'the', 'religious', 'references', 'to', 'hope', 'and', 'salvation', 'and', 'instead', 'used', 'it', 'as', 'to', 'show', 'that', 'life', 'stinks', ',', 'war', 'stinks', 'worse', 'and', 'that', 'there', 'is', ',', 'ultimately', 'no', 'hope.<br', '/><br', '/>Intellectually', 'I', 'admire', 'the', 'film', ',', 'emotionally', 'I', 'do', \"n't\", '.', 'Part', 'of', 'it', 'is', 'a', 'strident', 'downbeat', 'score', 'which', ',', 'for', 'me', 'over', 'accentuates', 'what', 'we', 'are', 'seeing', 'on', 'the', 'screen', '.', 'Its', 'almost', 'gilding', 'the', 'lily', 'since', 'the', 'imagery', 'is', 'so', 'strong', 'it', 'does', \"n't\", 'really', 'need', 'to', 'have', 'the', 'music', 'force', 'you', 'into', 'feeling', 'one', 'way', 'or', 'another.<br', '/><br', '/>Is', 'it', 'a', 'great', 'film', ',', 'that', 's', 'for', 'you', 'to', 'decide', '.', 'For', 'certain', 'its', 'unlike', 'any', 'other', 'war', 'film', ',', 'bloody', ',', 'horrific', 'and', 'real', 'in', 'ways', 'that', 'big', 'budgeted', 'films', 'claim', 'to', 'be', 'but', 'never', 'are', '.', 'This', 'is', 'not', 'for', 'those', 'adverse', 'to', 'blood', 'and', 'gore', 'since', 'its', 'here', 'in', 'spades.<br', '/><br', '/>Definitely', 'worth', 'a', 'look', '.'], 'label': 'pos'}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}