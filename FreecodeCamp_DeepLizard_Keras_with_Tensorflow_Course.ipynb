{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FreecodeCamp DeepLizard Keras with Tensorflow Course.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMexcsJYV/XAVQRsOYQ7+0h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShaunakSen/Deep-Learning/blob/master/FreecodeCamp_DeepLizard_Keras_with_Tensorflow_Course.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bw0Hy8rvGNJl",
        "colab_type": "text"
      },
      "source": [
        "## FreecodeCamp DeepLizard Keras with Tensorflow Course\n",
        "\n",
        "> Written notes on the tutorial by [DeepLizard](https://youtube.com/deeplizard) and [FreeCodeCamp](https://www.youtube.com/channel/UC8butISFwT-Wl7EV0hUK0BQ): https://www.youtube.com/watch?v=qFJeN9V1ZsI\n",
        "\n",
        "---\n",
        "\n",
        "### Data preparation and processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUfiblDNGKJc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from random import randint\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lvzv7ilG-iL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_samples, train_labels = [], []"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6cz0J7wHKUb",
        "colab_type": "text"
      },
      "source": [
        "For this simple task, we'll be creating our own example data set.\n",
        "\n",
        "#### Data Creation\n",
        "\n",
        "As motivation for this data, let’s suppose that an experimental drug was tested on individuals ranging from age 13 to 100 in a clinical trial. The trial had 2100 participants. Half of the participants were under 65 years old, and the other half was 65 years of age or older.\n",
        "\n",
        "The trial showed that around 95% of patients 65 or older experienced side effects from the drug, and around 95% of patients under 65 experienced no side effects, generally showing that elderly individuals were more likely to experience side effects.\n",
        "\n",
        "Ultimately, we want to build a model to tell us whether or not a patient will experience side effects solely based on the patient's age. The judgement of the model will be based on the training data.\n",
        "\n",
        "Note that with the simplicity of the data along with the conclusions drawn from it, a neural network may be overkill, but understand this is just to first get introduced to working with data for deep learning, and later, we'll be making use of more advanced data sets.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSwRgO9FHB31",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5aa7b06c-7aa3-40bb-8e83-995a4c9996a6"
      },
      "source": [
        "young_population = old_population = int(2100/2)\n",
        "\n",
        "minority = int(0.05*old_population)*2\n",
        "\n",
        "print (minority)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "104\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dZ51nYrIY46",
        "colab_type": "text"
      },
      "source": [
        "So the minority population is around 100 people (50 old and 50 young)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqus8pzdH8Jj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(50):\n",
        "    # The ~5% of younger individuals who did experience side effects\n",
        "    random_younger = randint(13,64)\n",
        "    train_samples.append(random_younger)\n",
        "    train_labels.append(1)\n",
        "\n",
        "    # The ~5% of older individuals who did not experience side effects\n",
        "    random_older = randint(65,100)\n",
        "    train_samples.append(random_older)\n",
        "    train_labels.append(0)\n",
        "\n",
        "    ### we have added 100 of the minority to the data\n",
        "\n",
        "for i in range(1000):\n",
        "    # The ~95% of younger individuals who did not experience side effects\n",
        "    random_younger = randint(13,64)\n",
        "    train_samples.append(random_younger)\n",
        "    train_labels.append(0)\n",
        "\n",
        "    # The ~95% of older individuals who did experience side effects\n",
        "    random_older = randint(65,100)\n",
        "    train_samples.append(random_older)\n",
        "    train_labels.append(1)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mk1YTgtgJBhX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6e778cfb-4a8d-4d8b-d3b7-01e887eb264f"
      },
      "source": [
        "print (len(train_samples), len(train_labels))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2100 2100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shMgm647JNfS",
        "colab_type": "text"
      },
      "source": [
        "This code creates 2100 samples and stores the age of the individuals in the train_samples list and stores whether or not the individuals experienced side effects in the train_labels list.\n",
        "\n",
        "Convert the data to numpy arrays:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqGpKnIRJI3C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "daaa56fc-0512-4cb8-8bcf-ecaa58d84374"
      },
      "source": [
        "train_labels = np.array(train_labels)\n",
        "train_samples = np.array(train_samples)\n",
        "### before shuffling\n",
        "print (train_labels[:10], train_samples[:10])\n",
        "\n",
        "train_labels, train_samples = shuffle(train_labels, train_samples) ### consistent order; so keeps track of the correspondence bw the 2 as we shuffle\n",
        "print (train_labels[:10], train_samples[:10])\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 0 1 0 1 0 1 0 1 0] [36 92 57 93 27 70 21 71 34 71]\n",
            "[1 1 1 0 1 1 1 0 1 1] [78 66 72 14 85 67 77 37 67 79]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMxGZS69LXMz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0abde9d6-c62d-4acb-9b0d-0fade3c36bfb"
      },
      "source": [
        "### test for shuffle\n",
        "t1 = np.array([23,34,12,11,34,65,32])\n",
        "t2 = np.array([1,1,0,0,0,1,1])\n",
        "\n",
        "t1_new,t2_new = shuffle(t1,t2)\n",
        "\n",
        "print(t1_new, t2_new)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[11 34 32 65 12 34 23] [0 1 1 1 0 0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2YIiD3VL19a",
        "colab_type": "text"
      },
      "source": [
        "> Ok, so shuffle does keep track of the correspondence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEcgi0A6LAib",
        "colab_type": "text"
      },
      "source": [
        "In this form, we now have the ability to pass the data to the model because it is now in the required format, however, before doing that, we'll first scale the data down to a range from 0 to 1.\n",
        "\n",
        "We'll use scikit-learn’s MinMaxScaler class to scale all of the data down from a scale ranging from 13 to 100 to be on a scale from 0 to 1.\n",
        "\n",
        "We reshape the data as a technical requirement just since the fit_transform() function doesn’t accept 1D data by default.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cxnq1op4KOXG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "c285530b-fe7b-48aa-b7b1-c6b11d5bff60"
      },
      "source": [
        "scaler = MinMaxScaler(feature_range=(0,1))\n",
        "scaled_train_samples = scaler.fit_transform(X=train_samples.reshape(-1, 1))\n",
        "\n",
        "print (scaled_train_samples[:5])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.74712644]\n",
            " [0.6091954 ]\n",
            " [0.67816092]\n",
            " [0.01149425]\n",
            " [0.82758621]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pe6XEZFHVSof",
        "colab_type": "text"
      },
      "source": [
        "### Create An Artificial Neural Network With TensorFlow's Keras API\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KM64gOw1MG7C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import categorical_crossentropy"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbBYSQoDV0om",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0f5915fa-7021-4110-c453-fb29fd1f89f1"
      },
      "source": [
        "physical_devices = tf.config.experimental.list_physical_devices(\"GPU\")\n",
        "print (physical_devices)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lqs98lqvWZ3-",
        "colab_type": "text"
      },
      "source": [
        "set_memory_growth() attempts to allocate only as much GPU memory as needed at a given time, and continues to allocate more when needed. If this is not enabled, then we may end up running into the error below when we train the model later.\n",
        "\n",
        "`Blas GEMM launch failed`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugrqo_oWWLNt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.config.experimental.set_memory_growth(device=physical_devices[0], enable=True)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHNcVetsWutk",
        "colab_type": "text"
      },
      "source": [
        "#### Build A Sequential Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjPMWOytWnZO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential([\n",
        "    Dense(units=16, input_shape=(1,), activation='relu'),\n",
        "    Dense(units=32, activation='relu'),\n",
        "    Dense(units=2, activation='softmax')\n",
        "])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9YumwZEXOVr",
        "colab_type": "text"
      },
      "source": [
        "As discussed, we’ll be training our network on the data that we generated and processed in the previous episode, and recall, this data is one-dimensional. The input_shape parameter expects a tuple of integers that matches the shape of the input data, so we correspondingly specify (1,) as the input_shape of our one-dimensional data.\n",
        "\n",
        "You can think of the way we specify the input_shape here as acting as an **implicit input layer**. The input layer of a neural network is the underlying raw data itself, therefore we don't create an explicit input layer. **This first Dense layer that we're working with now is actually the first hidden layer**.\n",
        "\n",
        "Lastly, an optional parameter that we’ll set for the Dense layer is the activation function to use after this layer. We’ll use the popular choice of relu. Note, if you don’t explicitly set an activation function, then Keras will use the linear activation function.\n",
        "\n",
        "Our next layer will also be a Dense layer, and this one will have 32 nodes. The choice of how many neurons this node has is also arbitrary, as the idea is to create a simple model, and then test and experiment with it. If we notice that it is insufficient, then at that time, we can troubleshoot the issue and begin experimenting with changing parameters, like number of layers, nodes, etc.\n",
        "\n",
        "Lastly, we specify the output layer. This layer is also a Dense layer, and it will have 2 neurons. This is because we have two possible outputs: either a patient experienced side effects, or the patient did not experience side effects.\n",
        "\n",
        "This time, the activation function we’ll use is softmax, which will give us a probability distribution among the possible outputs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtPgvikqXFsI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "c4d50323-ca79-435b-dcec-bebeffdd8c30"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 16)                32        \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                544       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 2)                 66        \n",
            "=================================================================\n",
            "Total params: 642\n",
            "Trainable params: 642\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8AThedlb5wr",
        "colab_type": "text"
      },
      "source": [
        "#### How do we arrive at 642 trainable params:\n",
        "\n",
        "1. 1 ip. Then 1 hidden layer with 16 nodes. So 16 connections (wts) and 16 (biases): `16x2`\n",
        "\n",
        "2. Next layer has 32 nodes. `16*32` wts + 32 biases: `(16*32)+32`\n",
        "\n",
        "3. Last layer has 2 nodes. So `32*2` wts + 2 biases: `32*2+2`\n",
        "\n",
        "`16*2 + (16*32)+32 + (32*2)+2 = 642`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzWwu1LcdZRj",
        "colab_type": "text"
      },
      "source": [
        "### Train An Artificial Neural Network With Keras\n",
        "\n",
        "---\n",
        "\n",
        "The first thing we need to do to get the model ready for training is call the compile() function on it.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRjy7nPPcbIY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhFxzmbcdhhk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "28355588-a456-4a5d-f54e-f02de4cb78f5"
      },
      "source": [
        "model.fit(x=scaled_train_samples, y=train_labels, batch_size=10, epochs=30, verbose=2, shuffle=True)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "210/210 - 0s - loss: 0.6549 - accuracy: 0.5810\n",
            "Epoch 2/30\n",
            "210/210 - 0s - loss: 0.6068 - accuracy: 0.6795\n",
            "Epoch 3/30\n",
            "210/210 - 0s - loss: 0.5653 - accuracy: 0.7414\n",
            "Epoch 4/30\n",
            "210/210 - 0s - loss: 0.5210 - accuracy: 0.7914\n",
            "Epoch 5/30\n",
            "210/210 - 0s - loss: 0.4807 - accuracy: 0.8333\n",
            "Epoch 6/30\n",
            "210/210 - 0s - loss: 0.4456 - accuracy: 0.8467\n",
            "Epoch 7/30\n",
            "210/210 - 0s - loss: 0.4138 - accuracy: 0.8671\n",
            "Epoch 8/30\n",
            "210/210 - 0s - loss: 0.3850 - accuracy: 0.8819\n",
            "Epoch 9/30\n",
            "210/210 - 0s - loss: 0.3610 - accuracy: 0.8943\n",
            "Epoch 10/30\n",
            "210/210 - 0s - loss: 0.3410 - accuracy: 0.9038\n",
            "Epoch 11/30\n",
            "210/210 - 0s - loss: 0.3252 - accuracy: 0.9100\n",
            "Epoch 12/30\n",
            "210/210 - 0s - loss: 0.3125 - accuracy: 0.9138\n",
            "Epoch 13/30\n",
            "210/210 - 0s - loss: 0.3025 - accuracy: 0.9200\n",
            "Epoch 14/30\n",
            "210/210 - 0s - loss: 0.2944 - accuracy: 0.9238\n",
            "Epoch 15/30\n",
            "210/210 - 0s - loss: 0.2882 - accuracy: 0.9248\n",
            "Epoch 16/30\n",
            "210/210 - 0s - loss: 0.2832 - accuracy: 0.9319\n",
            "Epoch 17/30\n",
            "210/210 - 0s - loss: 0.2788 - accuracy: 0.9314\n",
            "Epoch 18/30\n",
            "210/210 - 0s - loss: 0.2755 - accuracy: 0.9314\n",
            "Epoch 19/30\n",
            "210/210 - 0s - loss: 0.2728 - accuracy: 0.9324\n",
            "Epoch 20/30\n",
            "210/210 - 0s - loss: 0.2704 - accuracy: 0.9357\n",
            "Epoch 21/30\n",
            "210/210 - 0s - loss: 0.2686 - accuracy: 0.9348\n",
            "Epoch 22/30\n",
            "210/210 - 0s - loss: 0.2667 - accuracy: 0.9343\n",
            "Epoch 23/30\n",
            "210/210 - 0s - loss: 0.2654 - accuracy: 0.9371\n",
            "Epoch 24/30\n",
            "210/210 - 0s - loss: 0.2641 - accuracy: 0.9414\n",
            "Epoch 25/30\n",
            "210/210 - 0s - loss: 0.2631 - accuracy: 0.9362\n",
            "Epoch 26/30\n",
            "210/210 - 0s - loss: 0.2617 - accuracy: 0.9410\n",
            "Epoch 27/30\n",
            "210/210 - 0s - loss: 0.2609 - accuracy: 0.9367\n",
            "Epoch 28/30\n",
            "210/210 - 0s - loss: 0.2599 - accuracy: 0.9371\n",
            "Epoch 29/30\n",
            "210/210 - 0s - loss: 0.2592 - accuracy: 0.9386\n",
            "Epoch 30/30\n",
            "210/210 - 0s - loss: 0.2584 - accuracy: 0.9381\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f5d20282358>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZH4b0Tkeonx",
        "colab_type": "text"
      },
      "source": [
        "We set shuffle to True as we do not want the model to learn any implicit order by which it sees the training samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-zoBSfDfjOs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}