{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FreecodeCamp DeepLizard Keras with Tensorflow Course.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMa4Q38iZqoh5XYUCHZX/Sy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShaunakSen/Deep-Learning/blob/master/FreecodeCamp_DeepLizard_Keras_with_Tensorflow_Course.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bw0Hy8rvGNJl",
        "colab_type": "text"
      },
      "source": [
        "## FreecodeCamp DeepLizard Keras with Tensorflow Course\n",
        "\n",
        "> Written notes on the tutorial by [DeepLizard](https://youtube.com/deeplizard) and [FreeCodeCamp](https://www.youtube.com/channel/UC8butISFwT-Wl7EV0hUK0BQ): https://www.youtube.com/watch?v=qFJeN9V1ZsI\n",
        "\n",
        "---\n",
        "\n",
        "### Data preparation and processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUfiblDNGKJc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from random import randint\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lvzv7ilG-iL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_samples, train_labels = [], []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6cz0J7wHKUb",
        "colab_type": "text"
      },
      "source": [
        "For this simple task, we'll be creating our own example data set.\n",
        "\n",
        "#### Data Creation\n",
        "\n",
        "As motivation for this data, let’s suppose that an experimental drug was tested on individuals ranging from age 13 to 100 in a clinical trial. The trial had 2100 participants. Half of the participants were under 65 years old, and the other half was 65 years of age or older.\n",
        "\n",
        "The trial showed that around 95% of patients 65 or older experienced side effects from the drug, and around 95% of patients under 65 experienced no side effects, generally showing that elderly individuals were more likely to experience side effects.\n",
        "\n",
        "Ultimately, we want to build a model to tell us whether or not a patient will experience side effects solely based on the patient's age. The judgement of the model will be based on the training data.\n",
        "\n",
        "Note that with the simplicity of the data along with the conclusions drawn from it, a neural network may be overkill, but understand this is just to first get introduced to working with data for deep learning, and later, we'll be making use of more advanced data sets.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSwRgO9FHB31",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6471dac1-0c1f-45b4-fc70-56e92a734782"
      },
      "source": [
        "young_population = old_population = int(2100/2)\n",
        "\n",
        "minority = int(0.05*old_population)*2\n",
        "\n",
        "print (minority)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "104\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dZ51nYrIY46",
        "colab_type": "text"
      },
      "source": [
        "So the minority population is around 100 people (50 old and 50 young)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqus8pzdH8Jj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(50):\n",
        "    # The ~5% of younger individuals who did experience side effects\n",
        "    random_younger = randint(13,64)\n",
        "    train_samples.append(random_younger)\n",
        "    train_labels.append(1)\n",
        "\n",
        "    # The ~5% of older individuals who did not experience side effects\n",
        "    random_older = randint(65,100)\n",
        "    train_samples.append(random_older)\n",
        "    train_labels.append(0)\n",
        "\n",
        "    ### we have added 100 of the minority to the data\n",
        "\n",
        "for i in range(1000):\n",
        "    # The ~95% of younger individuals who did not experience side effects\n",
        "    random_younger = randint(13,64)\n",
        "    train_samples.append(random_younger)\n",
        "    train_labels.append(0)\n",
        "\n",
        "    # The ~95% of older individuals who did experience side effects\n",
        "    random_older = randint(65,100)\n",
        "    train_samples.append(random_older)\n",
        "    train_labels.append(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mk1YTgtgJBhX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b471ba95-8142-4570-f21b-82689214750b"
      },
      "source": [
        "print (len(train_samples), len(train_labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2100 2100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shMgm647JNfS",
        "colab_type": "text"
      },
      "source": [
        "This code creates 2100 samples and stores the age of the individuals in the train_samples list and stores whether or not the individuals experienced side effects in the train_labels list.\n",
        "\n",
        "Convert the data to numpy arrays:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqGpKnIRJI3C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "50650583-962f-48b9-893d-bcda2fb99926"
      },
      "source": [
        "train_labels = np.array(train_labels)\n",
        "train_samples = np.array(train_samples)\n",
        "### before shuffling\n",
        "print (train_labels[:10], train_samples[:10])\n",
        "\n",
        "train_labels, train_samples = shuffle(train_labels, train_samples) ### consistent order; so keeps track of the correspondence bw the 2 as we shuffle\n",
        "print (train_labels[:10], train_samples[:10])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 0 1 0 1 0 1 0 1 0] [51 99 17 97 59 67 23 69 49 77]\n",
            "[0 0 1 1 1 0 0 0 0 0] [16 29 97 69 98 57 36 38 15 23]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMxGZS69LXMz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e707c6eb-e3e7-4752-e540-9f8a578d772c"
      },
      "source": [
        "### test for shuffle\n",
        "t1 = np.array([23,34,12,11,34,65,32])\n",
        "t2 = np.array([1,1,0,0,0,1,1])\n",
        "\n",
        "t1_new,t2_new = shuffle(t1,t2)\n",
        "\n",
        "print(t1_new, t2_new)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[65 34 23 34 11 12 32] [1 0 1 1 0 0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2YIiD3VL19a",
        "colab_type": "text"
      },
      "source": [
        "> Ok, so shuffle does keep track of the correspondence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEcgi0A6LAib",
        "colab_type": "text"
      },
      "source": [
        "In this form, we now have the ability to pass the data to the model because it is now in the required format, however, before doing that, we'll first scale the data down to a range from 0 to 1.\n",
        "\n",
        "We'll use scikit-learn’s MinMaxScaler class to scale all of the data down from a scale ranging from 13 to 100 to be on a scale from 0 to 1.\n",
        "\n",
        "We reshape the data as a technical requirement just since the fit_transform() function doesn’t accept 1D data by default.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cxnq1op4KOXG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "ed016e03-095c-4b7f-d3c6-eda5547c29ef"
      },
      "source": [
        "scaler = MinMaxScaler(feature_range=(0,1))\n",
        "scaled_train_samples = scaler.fit_transform(X=train_samples.reshape(-1, 1))\n",
        "\n",
        "print (scaled_train_samples[:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.03448276]\n",
            " [0.18390805]\n",
            " [0.96551724]\n",
            " [0.64367816]\n",
            " [0.97701149]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pe6XEZFHVSof",
        "colab_type": "text"
      },
      "source": [
        "### Create An Artificial Neural Network With TensorFlow's Keras API\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KM64gOw1MG7C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import categorical_crossentropy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbBYSQoDV0om",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1c0cfd92-0887-4b54-e9bc-561595e5cbae"
      },
      "source": [
        "physical_devices = tf.config.experimental.list_physical_devices(\"GPU\")\n",
        "print (physical_devices)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lqs98lqvWZ3-",
        "colab_type": "text"
      },
      "source": [
        "set_memory_growth() attempts to allocate only as much GPU memory as needed at a given time, and continues to allocate more when needed. If this is not enabled, then we may end up running into the error below when we train the model later.\n",
        "\n",
        "`Blas GEMM launch failed`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugrqo_oWWLNt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.config.experimental.set_memory_growth(device=physical_devices[0], enable=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHNcVetsWutk",
        "colab_type": "text"
      },
      "source": [
        "#### Build A Sequential Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjPMWOytWnZO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential([\n",
        "    Dense(units=16, input_shape=(1,), activation='relu'),\n",
        "    Dense(units=32, activation='relu'),\n",
        "    Dense(units=2, activation='softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9YumwZEXOVr",
        "colab_type": "text"
      },
      "source": [
        "As discussed, we’ll be training our network on the data that we generated and processed in the previous episode, and recall, this data is one-dimensional. The input_shape parameter expects a tuple of integers that matches the shape of the input data, so we correspondingly specify (1,) as the input_shape of our one-dimensional data.\n",
        "\n",
        "You can think of the way we specify the input_shape here as acting as an **implicit input layer**. The input layer of a neural network is the underlying raw data itself, therefore we don't create an explicit input layer. **This first Dense layer that we're working with now is actually the first hidden layer**.\n",
        "\n",
        "Lastly, an optional parameter that we’ll set for the Dense layer is the activation function to use after this layer. We’ll use the popular choice of relu. Note, if you don’t explicitly set an activation function, then Keras will use the linear activation function.\n",
        "\n",
        "Our next layer will also be a Dense layer, and this one will have 32 nodes. The choice of how many neurons this node has is also arbitrary, as the idea is to create a simple model, and then test and experiment with it. If we notice that it is insufficient, then at that time, we can troubleshoot the issue and begin experimenting with changing parameters, like number of layers, nodes, etc.\n",
        "\n",
        "Lastly, we specify the output layer. This layer is also a Dense layer, and it will have 2 neurons. This is because we have two possible outputs: either a patient experienced side effects, or the patient did not experience side effects.\n",
        "\n",
        "This time, the activation function we’ll use is softmax, which will give us a probability distribution among the possible outputs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtPgvikqXFsI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "14e22835-77b3-4497-d922-4d68e037db77"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 16)                32        \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                544       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 2)                 66        \n",
            "=================================================================\n",
            "Total params: 642\n",
            "Trainable params: 642\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8AThedlb5wr",
        "colab_type": "text"
      },
      "source": [
        "#### How do we arrive at 642 trainable params:\n",
        "\n",
        "1. 1 ip. Then 1 hidden layer with 16 nodes. So 16 connections (wts) and 16 (biases): `16x2`\n",
        "\n",
        "2. Next layer has 32 nodes. `16*32` wts + 32 biases: `(16*32)+32`\n",
        "\n",
        "3. Last layer has 2 nodes. So `32*2` wts + 2 biases: `32*2+2`\n",
        "\n",
        "`16*2 + (16*32)+32 + (32*2)+2 = 642`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzWwu1LcdZRj",
        "colab_type": "text"
      },
      "source": [
        "### Train An Artificial Neural Network With Keras\n",
        "\n",
        "---\n",
        "\n",
        "The first thing we need to do to get the model ready for training is call the compile() function on it.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRjy7nPPcbIY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhFxzmbcdhhk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4948b6af-1f09-41a9-b0e5-867ef9310368"
      },
      "source": [
        "model.fit(x=scaled_train_samples, y=train_labels, batch_size=10, epochs=30, verbose=2, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "210/210 - 0s - loss: 0.6480 - accuracy: 0.5695\n",
            "Epoch 2/30\n",
            "210/210 - 0s - loss: 0.6242 - accuracy: 0.6367\n",
            "Epoch 3/30\n",
            "210/210 - 0s - loss: 0.5986 - accuracy: 0.6981\n",
            "Epoch 4/30\n",
            "210/210 - 0s - loss: 0.5717 - accuracy: 0.7429\n",
            "Epoch 5/30\n",
            "210/210 - 0s - loss: 0.5410 - accuracy: 0.7781\n",
            "Epoch 6/30\n",
            "210/210 - 0s - loss: 0.5055 - accuracy: 0.8224\n",
            "Epoch 7/30\n",
            "210/210 - 0s - loss: 0.4731 - accuracy: 0.8419\n",
            "Epoch 8/30\n",
            "210/210 - 0s - loss: 0.4430 - accuracy: 0.8562\n",
            "Epoch 9/30\n",
            "210/210 - 0s - loss: 0.4153 - accuracy: 0.8724\n",
            "Epoch 10/30\n",
            "210/210 - 0s - loss: 0.3906 - accuracy: 0.8857\n",
            "Epoch 11/30\n",
            "210/210 - 0s - loss: 0.3689 - accuracy: 0.8924\n",
            "Epoch 12/30\n",
            "210/210 - 0s - loss: 0.3504 - accuracy: 0.9019\n",
            "Epoch 13/30\n",
            "210/210 - 0s - loss: 0.3345 - accuracy: 0.9067\n",
            "Epoch 14/30\n",
            "210/210 - 0s - loss: 0.3213 - accuracy: 0.9171\n",
            "Epoch 15/30\n",
            "210/210 - 0s - loss: 0.3103 - accuracy: 0.9181\n",
            "Epoch 16/30\n",
            "210/210 - 0s - loss: 0.3012 - accuracy: 0.9176\n",
            "Epoch 17/30\n",
            "210/210 - 0s - loss: 0.2932 - accuracy: 0.9190\n",
            "Epoch 18/30\n",
            "210/210 - 0s - loss: 0.2870 - accuracy: 0.9348\n",
            "Epoch 19/30\n",
            "210/210 - 0s - loss: 0.2815 - accuracy: 0.9300\n",
            "Epoch 20/30\n",
            "210/210 - 0s - loss: 0.2769 - accuracy: 0.9333\n",
            "Epoch 21/30\n",
            "210/210 - 0s - loss: 0.2730 - accuracy: 0.9348\n",
            "Epoch 22/30\n",
            "210/210 - 0s - loss: 0.2696 - accuracy: 0.9362\n",
            "Epoch 23/30\n",
            "210/210 - 0s - loss: 0.2668 - accuracy: 0.9371\n",
            "Epoch 24/30\n",
            "210/210 - 0s - loss: 0.2643 - accuracy: 0.9381\n",
            "Epoch 25/30\n",
            "210/210 - 0s - loss: 0.2621 - accuracy: 0.9400\n",
            "Epoch 26/30\n",
            "210/210 - 0s - loss: 0.2602 - accuracy: 0.9381\n",
            "Epoch 27/30\n",
            "210/210 - 0s - loss: 0.2584 - accuracy: 0.9400\n",
            "Epoch 28/30\n",
            "210/210 - 0s - loss: 0.2569 - accuracy: 0.9381\n",
            "Epoch 29/30\n",
            "210/210 - 0s - loss: 0.2555 - accuracy: 0.9452\n",
            "Epoch 30/30\n",
            "210/210 - 0s - loss: 0.2545 - accuracy: 0.9390\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f43800807b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZH4b0Tkeonx",
        "colab_type": "text"
      },
      "source": [
        "We set shuffle to True as we do not want the model to learn any implicit order by which it sees the training samples\n",
        "\n",
        "### Build A Validation Set With TensorFlow's Keras API\n",
        "\n",
        "---\n",
        "\n",
        "Recall that we previously built a training set on which we trained our model. With each epoch that our model is trained, the model will continue to learn the features and characteristics of the data in this training set.\n",
        "\n",
        "The hope is that later we can take this model, apply it to new data, and have the model accurately predict on data that it hasn’t seen before based solely on what it learned from the training set.\n",
        "\n",
        "Now, let’s discuss where the addition of a validation set comes into play.\n",
        "\n",
        "Before training begins, we can choose to remove a portion of the training set and place it in a validation set. Then, during training, the model will train only on the training set, and it will validate by evaluating the data in the validation set.\n",
        "\n",
        "Essentially, the model is learning the features of the data in the training set, taking what it's learned from this data, and then predicting on the validation set. During each epoch, we will see not only the loss and accuracy results for the training set, but also for the validation set.\n",
        "\n",
        "This allows us to see how well the model is generalizing on data it wasn’t trained on because, recall, the validation data should not be part of the training data.\n",
        "\n",
        "This also helps us see whether or not the model is overfitting. **Overfitting occurs when the model only learns the specifics of the training data and is unable to generalize well on data that it wasn’t trained on.**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFLE8d8qikgt",
        "colab_type": "text"
      },
      "source": [
        "#### Create a Validation set\n",
        "\n",
        "The first way is to create a data structure to hold a validation set, and place data directly in that structure in the same nature we did for the training set.\n",
        "\n",
        "This data structure should be a tuple `valid_set = (x_val, y_val)` of Numpy arrays or tensors, where `x_val` is a numpy array or tensor containing validation samples, and `y_val` is a numpy array or tensor containing validation labels.\n",
        "\n",
        "When we call model.fit(), we would pass in the validation set in addition to the training set. We pass the validation set by specifying the validation_data parameter.\n",
        "\n",
        "```\n",
        "model.fit(\n",
        "      x=scaled_train_samples\n",
        "    , y=train_labels\n",
        "    , validation_data=valid_set\n",
        "    , batch_size=10\n",
        "    , epochs=30\n",
        "    , verbose=2\n",
        ")\n",
        "```\n",
        "\n",
        "When the model trains, it would continue to train only on the training set, but additionally, it would also be evaluating the validation set.\n",
        "\n",
        "There is another way to create a validation set, and it saves a step!\n",
        "\n",
        "If we don’t already have a specified validation set created, then when we call `model.fit()`, we can set a value for the validation_split parameter. It expects a fractional number between 0 and 1. Suppose that we set this parameter to 0.1.\n",
        "\n",
        "```\n",
        "model.fit(\n",
        "      x=scaled_train_samples\n",
        "    , y=train_labels\n",
        "    , validation_split=0.1\n",
        "    , batch_size=10\n",
        "    , epochs=30\n",
        "    , verbose=2\n",
        ")\n",
        "```\n",
        "\n",
        "With this parameter specified, Keras will split apart a fraction (10% in this example) of the training data to be used as validation data. **The model will set apart this fraction of the training data, will not train on it, and will evaluate the loss and any model metrics on this data at the end of each epoch.**\n",
        "\n",
        "\n",
        "**Note that the fit() function shuffles the data before each epoch by default. When specifying the validation_split parameter, however, the validation data is selected from the last samples in the x and y data before shuffling.**\n",
        "\n",
        "So imagine if in our training data we had all sick patients first and non-sick patients after. Then if we split off the last 10% as validation, its going to take all the non-sick patients! So, here is not a prob as we have already shuffled our training data before iteself, but if that is not so, this would be a problem and setting `shuffle=True` also will not help\n",
        "\n",
        "Therefore, in the case we're using validation_split in this way to create our validation data, we need to be sure that our data has been shuffled ahead of time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ls9UjDCdk2_l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential([\n",
        "    Dense(units=16, input_shape=(1,), activation='relu'),\n",
        "    Dense(units=32, activation='relu'),\n",
        "    Dense(units=2, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-zoBSfDfjOs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3ad7dbc4-573d-4c21-ceb0-efb621a9dcc2"
      },
      "source": [
        "model.fit(x=scaled_train_samples, y=train_labels, batch_size=10, epochs=30, verbose=2, shuffle=True, validation_split=0.1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "189/189 - 1s - loss: 0.6723 - accuracy: 0.5492 - val_loss: 0.6610 - val_accuracy: 0.5905\n",
            "Epoch 2/30\n",
            "189/189 - 0s - loss: 0.6498 - accuracy: 0.6280 - val_loss: 0.6361 - val_accuracy: 0.6714\n",
            "Epoch 3/30\n",
            "189/189 - 0s - loss: 0.6221 - accuracy: 0.7101 - val_loss: 0.6068 - val_accuracy: 0.7429\n",
            "Epoch 4/30\n",
            "189/189 - 0s - loss: 0.5937 - accuracy: 0.7513 - val_loss: 0.5799 - val_accuracy: 0.7714\n",
            "Epoch 5/30\n",
            "189/189 - 0s - loss: 0.5661 - accuracy: 0.7825 - val_loss: 0.5527 - val_accuracy: 0.7857\n",
            "Epoch 6/30\n",
            "189/189 - 0s - loss: 0.5385 - accuracy: 0.8048 - val_loss: 0.5257 - val_accuracy: 0.8143\n",
            "Epoch 7/30\n",
            "189/189 - 0s - loss: 0.5101 - accuracy: 0.8339 - val_loss: 0.4972 - val_accuracy: 0.8190\n",
            "Epoch 8/30\n",
            "189/189 - 0s - loss: 0.4810 - accuracy: 0.8434 - val_loss: 0.4701 - val_accuracy: 0.8476\n",
            "Epoch 9/30\n",
            "189/189 - 0s - loss: 0.4541 - accuracy: 0.8529 - val_loss: 0.4457 - val_accuracy: 0.8810\n",
            "Epoch 10/30\n",
            "189/189 - 0s - loss: 0.4291 - accuracy: 0.8730 - val_loss: 0.4223 - val_accuracy: 0.8810\n",
            "Epoch 11/30\n",
            "189/189 - 0s - loss: 0.4065 - accuracy: 0.8868 - val_loss: 0.4016 - val_accuracy: 0.8810\n",
            "Epoch 12/30\n",
            "189/189 - 0s - loss: 0.3858 - accuracy: 0.8905 - val_loss: 0.3831 - val_accuracy: 0.8810\n",
            "Epoch 13/30\n",
            "189/189 - 0s - loss: 0.3674 - accuracy: 0.9011 - val_loss: 0.3670 - val_accuracy: 0.8952\n",
            "Epoch 14/30\n",
            "189/189 - 0s - loss: 0.3513 - accuracy: 0.9032 - val_loss: 0.3530 - val_accuracy: 0.9048\n",
            "Epoch 15/30\n",
            "189/189 - 0s - loss: 0.3372 - accuracy: 0.9095 - val_loss: 0.3409 - val_accuracy: 0.9048\n",
            "Epoch 16/30\n",
            "189/189 - 0s - loss: 0.3252 - accuracy: 0.9148 - val_loss: 0.3306 - val_accuracy: 0.9095\n",
            "Epoch 17/30\n",
            "189/189 - 0s - loss: 0.3148 - accuracy: 0.9190 - val_loss: 0.3216 - val_accuracy: 0.9095\n",
            "Epoch 18/30\n",
            "189/189 - 0s - loss: 0.3062 - accuracy: 0.9169 - val_loss: 0.3145 - val_accuracy: 0.9095\n",
            "Epoch 19/30\n",
            "189/189 - 0s - loss: 0.2986 - accuracy: 0.9233 - val_loss: 0.3084 - val_accuracy: 0.9333\n",
            "Epoch 20/30\n",
            "189/189 - 0s - loss: 0.2921 - accuracy: 0.9238 - val_loss: 0.3033 - val_accuracy: 0.9333\n",
            "Epoch 21/30\n",
            "189/189 - 0s - loss: 0.2866 - accuracy: 0.9286 - val_loss: 0.2987 - val_accuracy: 0.9333\n",
            "Epoch 22/30\n",
            "189/189 - 0s - loss: 0.2817 - accuracy: 0.9254 - val_loss: 0.2947 - val_accuracy: 0.9333\n",
            "Epoch 23/30\n",
            "189/189 - 0s - loss: 0.2776 - accuracy: 0.9317 - val_loss: 0.2918 - val_accuracy: 0.9381\n",
            "Epoch 24/30\n",
            "189/189 - 0s - loss: 0.2741 - accuracy: 0.9317 - val_loss: 0.2889 - val_accuracy: 0.9381\n",
            "Epoch 25/30\n",
            "189/189 - 0s - loss: 0.2710 - accuracy: 0.9381 - val_loss: 0.2864 - val_accuracy: 0.9381\n",
            "Epoch 26/30\n",
            "189/189 - 0s - loss: 0.2683 - accuracy: 0.9381 - val_loss: 0.2845 - val_accuracy: 0.9381\n",
            "Epoch 27/30\n",
            "189/189 - 0s - loss: 0.2659 - accuracy: 0.9381 - val_loss: 0.2821 - val_accuracy: 0.9381\n",
            "Epoch 28/30\n",
            "189/189 - 0s - loss: 0.2637 - accuracy: 0.9381 - val_loss: 0.2809 - val_accuracy: 0.9381\n",
            "Epoch 29/30\n",
            "189/189 - 0s - loss: 0.2619 - accuracy: 0.9381 - val_loss: 0.2792 - val_accuracy: 0.9381\n",
            "Epoch 30/30\n",
            "189/189 - 0s - loss: 0.2603 - accuracy: 0.9413 - val_loss: 0.2778 - val_accuracy: 0.9381\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f432c0ee7f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdyqz-sAk-9_",
        "colab_type": "text"
      },
      "source": [
        "The accuracy and the val_accuracy is quite similar, so it does not seem that it is oevrfitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqxoWikuJTzW",
        "colab_type": "text"
      },
      "source": [
        "### Make Predictions With An Artificial Neural Network Using Keras\n",
        "\n",
        "At this point, the model we've been working with over the past few episodes has now been trained and validated. Given the results we’ve seen from the validation data, it appears that this model should do well on predicting on a new test set.\n",
        "\n",
        "#### Creating The Test Set\n",
        "\n",
        "We’ll create a test set in the same fashion for which we created the training set. **In general, the test set should always be processed in the same way as the training set**.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2F7NE5FKkouq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_labels =  []\n",
        "test_samples = []\n",
        "\n",
        "for i in range(10):\n",
        "    # The 5% of younger individuals who did experience side effects\n",
        "    random_younger = randint(13,64)\n",
        "    test_samples.append(random_younger)\n",
        "    test_labels.append(1)\n",
        "    \n",
        "    # The 5% of older individuals who did not experience side effects\n",
        "    random_older = randint(65,100)\n",
        "    test_samples.append(random_older)\n",
        "    test_labels.append(0)\n",
        "\n",
        "for i in range(200):\n",
        "    # The 95% of younger individuals who did not experience side effects\n",
        "    random_younger = randint(13,64)\n",
        "    test_samples.append(random_younger)\n",
        "    test_labels.append(0)\n",
        "    \n",
        "    # The 95% of older individuals who did experience side effects\n",
        "    random_older = randint(65,100)\n",
        "    test_samples.append(random_older)\n",
        "    test_labels.append(1)\n",
        "\n",
        "test_labels = np.array(test_labels)\n",
        "test_samples = np.array(test_samples)\n",
        "test_labels, test_samples = shuffle(test_labels, test_samples)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfimQ1BiLvUd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b3346058-6125-489b-fd34-00fb53c7d6cd"
      },
      "source": [
        "print (test_labels.shape, test_samples.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(420,) (420,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lt7FotYGM1Yu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scaled_test_samples = scaler.fit_transform(test_samples.reshape(-1,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E72OewzAM3DG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "725dbd1f-4fe9-435a-fa84-12bd6f81720d"
      },
      "source": [
        "scaled_test_samples[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.77011494],\n",
              "       [0.87356322],\n",
              "       [0.59770115],\n",
              "       [0.20689655],\n",
              "       [0.3908046 ],\n",
              "       [0.28735632],\n",
              "       [0.91954023],\n",
              "       [0.59770115],\n",
              "       [0.12643678],\n",
              "       [0.71264368]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLTTlFQ0M6vH",
        "colab_type": "text"
      },
      "source": [
        "#### Evaluating The Test Set\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Ldi2WiAM4si",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = model.predict(x=scaled_test_samples, batch_size=10, verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIarlHksNoTR",
        "colab_type": "text"
      },
      "source": [
        "To this function, we pass in the test samples x, specify a batch_size, and specify which level of verbosity we want from log messages during prediction generation. The output from the predictions won't be relevant for us, so we're setting verbose=0 for no output.\n",
        "\n",
        "Note that, unlike with training and validation sets, we do not pass the labels of the test set to the model during the inference stage.\n",
        "\n",
        "To see what the model's predictions look like, we can iterate over them and print them out"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgY9EEBeNnmk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "69a89530-5b73-4990-d4d9-e5d907bd2230"
      },
      "source": [
        "predictions[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.09946632, 0.9005337 ],\n",
              "       [0.04490974, 0.9550902 ],\n",
              "       [0.42142275, 0.5785772 ],\n",
              "       [0.96192795, 0.03807205],\n",
              "       [0.87506926, 0.12493078],\n",
              "       [0.9494574 , 0.05054266],\n",
              "       [0.03454174, 0.9654583 ],\n",
              "       [0.42142275, 0.5785772 ],\n",
              "       [0.9621529 , 0.03784714],\n",
              "       [0.17158663, 0.82841337]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9pdQutHN0Vk",
        "colab_type": "text"
      },
      "source": [
        "Each element in the predictions list is itself a list of length 2. The sum of the two values in each list is 1. The reason for this is because the two columns contain probabilities for each possible output: experienced side effects and did not experience side effects. Each element in the predictions list is a probability distribution over all possible outputs.\n",
        "\n",
        "The first column contains the probability for each patient not experiencing side effects, which is represented by a 0. The second column contains the probability for each patient experiencing side effects, which is represented by a 1.\n",
        "\n",
        "We can also look only at the most probable prediction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKxcggZTNrgO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "667f48a2-dd91-4e4b-d1b3-6aa812e72108"
      },
      "source": [
        "rounded_predictions = np.argmax(predictions, axis=-1)\n",
        "\n",
        "print (rounded_predictions[:10])\n",
        "\n",
        "print (rounded_predictions.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 1 1 0 0 0 1 1 0 1]\n",
            "(420,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMlF7hFVOEW2",
        "colab_type": "text"
      },
      "source": [
        "From the printed prediction results, we can observe the underlying predictions from the model, however, we cannot judge how accurate these predictions are just by looking at the predicted output.\n",
        "\n",
        "If we have corresponding labels for the test set, (for which, in this case, we do), then we can compare these true labels to the predicted labels to judge the accuracy of the model's evaluations. We'll see how to visualize this using a tool called a confusion matrix "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkvGRvevjTIE",
        "colab_type": "text"
      },
      "source": [
        "### Create A Confusion Matrix For Neural Network Predictions\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMMpp5sqN4g8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvBw26vWqtLz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cm = confusion_matrix(y_true=test_labels, y_pred=rounded_predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COKiKVfaq_To",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                        normalize=False,\n",
        "                        title='Confusion matrix',\n",
        "                        cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "            horizontalalignment=\"center\",\n",
        "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ayw_8l1-rEH7",
        "colab_type": "text"
      },
      "source": [
        "Next, we define the labels for the confusion matrix. In our case, the labels are titled “no side effects” and “had side effects.”\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eVH9sferCUg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cm_plot_labels = ['no_side_effects','had_side_effects']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NsKpWN6rHdn",
        "colab_type": "text"
      },
      "source": [
        "Lastly, we plot the confusion matrix by using the plot_confusion_matrix() function we just discussed. To this function, we pass in the confusion matrix cm and the labels cm_plot_labels, as well as a title for the confusion matrix.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNE-UCLurF96",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "outputId": "0f3fce63-cdf1-4df8-b8a5-fe9f15dbafa1"
      },
      "source": [
        "plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix, without normalization\n",
            "[[197  13]\n",
            " [ 10 200]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Rl2ND2frXSA",
        "colab_type": "text"
      },
      "source": [
        "Looking at the plot of the confusion matrix, we have the predicted labels on the x-axis and the true labels on the y-axis. The blue cells running from the top left to bottom right contain the number of samples that the model accurately predicted. The white cells contain the number of samples that were incorrectly predicted.\n",
        "\n",
        "There are 420 total samples in the test set. Looking at the confusion matrix, we can see that the model accurately predicted 399 out of 420 total samples. The model incorrectly predicted 21 out of the 420.\n",
        "\n",
        "For the samples the model got correct, we can see that it accurately predicted that the patients would experience no side effects 199 times. It incorrectly predicted that the patient would have no side effects 10 times when the patient did actually experience side effects.\n",
        "\n",
        "On the other side, the model accurately predicted that the patient would experience side effects 200 times that the patient did indeed experience side effects. It incorrectly predicted that the patient would have side effects 11 times when the patient actually did not experience side effects.\n",
        "\n",
        "As you can see, this is a good way we can visually interpret how well the model is doing at its predictions and understand where it may need some work."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7oqZyZDsM2_",
        "colab_type": "text"
      },
      "source": [
        "### Save And Load A Model With TensorFlow's Keras API\n",
        "\n",
        "There are a few different ways to save a Keras model. The multiple mechanisms each save the model differently, so we'll check them all out.\n",
        "\n",
        "#### Saving And Loading The Model In Its Entirety\n",
        "\n",
        "If we want to save a model at its current state after it was trained so that we could make use of it later, we can call the save() function on the model. To save(), we pass in the file path and name of the file we want to save the model to with an h5 extension.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzjJUhCVsVh0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "7cf7f552-7de0-41a3-bb25-f65046ea5479"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_3 (Dense)              (None, 16)                32        \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 32)                544       \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 2)                 66        \n",
            "=================================================================\n",
            "Total params: 642\n",
            "Trainable params: 642\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1Tx__hNrTsG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(filepath='./sample_data/models/medical_trial_model.h5', overwrite=True, include_optimizer=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AE-5UyyswvM",
        "colab_type": "text"
      },
      "source": [
        "Note, this function also allows for saving the model as a Tensorflow SavedModel as well if you'd prefer.\n",
        "\n",
        "This method of saving will save everything about the model – the architecture, the weights, the optimizer, the state of the optimizer, the learning rate, the loss, etc.\n",
        "\n",
        "Now that we have this model saved, we can load the model at a later time.\n",
        "\n",
        "To do so, we first import the load_model() function. Then, we can call the function to load the model by pointing to the saved model on disk."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCJWjHcFshsU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "loaded_model = load_model(filepath='./sample_data/models/medical_trial_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OuEjEhFRs_Ac",
        "colab_type": "text"
      },
      "source": [
        "We can verify that the loaded model has the same architecture and weights as the saved model by calling summary() and get_weights() on the model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdlVTyxws12n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "acc956f0-4ab3-4d80-c397-98f7bf263d62"
      },
      "source": [
        "loaded_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_3 (Dense)              (None, 16)                32        \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 32)                544       \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 2)                 66        \n",
            "=================================================================\n",
            "Total params: 642\n",
            "Trainable params: 642\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKK1gY6EtBVT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "65f9f0a3-a1cd-4eff-d457-cd7899dce906"
      },
      "source": [
        "for wt_ in loaded_model.get_weights():\n",
        "    print (wt_.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 16)\n",
            "(16,)\n",
            "(16, 32)\n",
            "(32,)\n",
            "(32, 2)\n",
            "(2,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "niH4XMN0tS_k",
        "colab_type": "text"
      },
      "source": [
        "#### How did we arrive at 642 trainable params:\n",
        "\n",
        "1. 1 ip. Then 1 hidden layer with 16 nodes. So 16 connections (wts) and 16 (biases): `16x2`\n",
        "\n",
        "2. Next layer has 32 nodes. `16*32` wts + 32 biases: `(16*32)+32`\n",
        "\n",
        "3. Last layer has 2 nodes. So `32*2` wts + 2 biases: `32*2+2`\n",
        "\n",
        "`16*2 + (16*32)+32 + (32*2)+2 = 642`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5SroxgOBtnCj",
        "colab_type": "text"
      },
      "source": [
        "We can also inspect attributes about the model, like the optimizer and loss by calling model.optimizer and model.loss on the loaded model and compare the results to the previously saved model.\n",
        "\n",
        "This is the most encompassing way to save and load a model.\n",
        "\n",
        "#### Saving And Loading Only The Architecture Of The Model\n",
        "\n",
        "There is another way we save only the architecture of the model. **This will not save the model weights, configurations, optimizer, loss or anything else. This only saves the architecture of the model.**\n",
        "\n",
        "We can do this by calling model.to_json(). This will save the architecture of the model as a JSON string. If we print out the string, we can see exactly what this looks like.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWeUcKDttEd5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "334a1878-592d-460a-f79b-9708b820d497"
      },
      "source": [
        "json_string = model.to_json()\n",
        "json_string"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'{\"class_name\": \"Sequential\", \"config\": {\"name\": \"sequential_1\", \"layers\": [{\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_3\", \"trainable\": true, \"batch_input_shape\": [null, 1], \"dtype\": \"float32\", \"units\": 16, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_4\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 32, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_5\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 2, \"activation\": \"softmax\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}], \"build_input_shape\": [null, 1]}, \"keras_version\": \"2.3.0-tf\", \"backend\": \"tensorflow\"}'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yg7gD4WGt3bE",
        "colab_type": "text"
      },
      "source": [
        "Now that we have this saved, we can create a new model from it. First we’ll import the needed model_from_json function, and then we can load the model architecture.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88rMgTqut1VC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "e67f6b88-b25f-4666-d459-763e28b2ccc6"
      },
      "source": [
        "from tensorflow.keras.models import model_from_json\n",
        "model_architecture = model_from_json(json_string)\n",
        "model_architecture.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_3 (Dense)              (None, 16)                32        \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 32)                544       \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 2)                 66        \n",
            "=================================================================\n",
            "Total params: 642\n",
            "Trainable params: 642\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWL4TH8HuHQ7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "45e7a1dd-f69c-4783-e789-cc802c349828"
      },
      "source": [
        "model.get_weights()[0][:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.1749801 ,  0.46704558, -0.16897932, -0.22692353, -0.303186  ,\n",
              "         0.61048204, -0.1776686 , -0.2780507 , -0.08611888, -0.03412133,\n",
              "        -0.5807983 , -0.28748602,  0.28578275,  0.63758403,  0.5423842 ,\n",
              "         0.3377873 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLyczwEot65s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "86cb42ec-e05e-4c10-addb-51e3ae94faa5"
      },
      "source": [
        "model_architecture.get_weights()[0][:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.01539773, -0.2412608 ,  0.4743309 ,  0.28541917,  0.07415468,\n",
              "        -0.31079796, -0.22194752,  0.31857425, -0.21409929, -0.1874021 ,\n",
              "        -0.46452034,  0.00472999,  0.380767  ,  0.0808661 ,  0.09428596,\n",
              "         0.30649614]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZRaZTjDuNeL",
        "colab_type": "text"
      },
      "source": [
        "As we can see the wts are diff as the `model_architecture` weights are untrained and initialized to random"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpviE4dzt97A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e50fe1f7-adca-46d8-fdc9-2ec9f649d886"
      },
      "source": [
        "try:\n",
        "    print (model_architecture.loss, model_architecture.optimizer)\n",
        "except AttributeError:\n",
        "    print (\"No loss/optimizer found\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No loss/optimizer found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rI7pV1tSuVxR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2b58c885-bfda-451f-9950-82600db79101"
      },
      "source": [
        "model.loss"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'sparse_categorical_crossentropy'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zm8xafmMus3r",
        "colab_type": "text"
      },
      "source": [
        "#### Saving And Loading The Weights Of The Model\n",
        "\n",
        "The last saving mechanism we’ll discuss only saves the weights of the model.\n",
        "\n",
        "We can do this by calling model.save_weights() and passing in the path and file name to save the weights to with an h5 extension.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkpL-1NVuZsR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save_weights(filepath='./sample_data/models/medical_trial_model_weights.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdszZZ0pu7hk",
        "colab_type": "text"
      },
      "source": [
        "At a later point, we could then load the saved weights in to a new model, but the new model will need to have the same architecture as the old model before the weights can be saved.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Zd6aF8lu6Ul",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_model_without_wts = Sequential([\n",
        "    Dense(units=16, input_shape=(1,), activation='relu'),\n",
        "    Dense(units=32, activation='relu'),\n",
        "    Dense(units=2, activation='softmax')\n",
        "])\n",
        "\n",
        "new_model_without_wts.load_weights('./sample_data/models/medical_trial_model_weights.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2g8RouevIsL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "7c62851f-bf1d-4751-e713-37d1edc74d49"
      },
      "source": [
        "new_model_without_wts.get_weights()[0][:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.1749801 ,  0.46704558, -0.16897932, -0.22692353, -0.303186  ,\n",
              "         0.61048204, -0.1776686 , -0.2780507 , -0.08611888, -0.03412133,\n",
              "        -0.5807983 , -0.28748602,  0.28578275,  0.63758403,  0.5423842 ,\n",
              "         0.3377873 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bDeyc6LvLhA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "c2723318-e673-49e7-fedb-093613ff4402"
      },
      "source": [
        "model.get_weights()[0][:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.1749801 ,  0.46704558, -0.16897932, -0.22692353, -0.303186  ,\n",
              "         0.61048204, -0.1776686 , -0.2780507 , -0.08611888, -0.03412133,\n",
              "        -0.5807983 , -0.28748602,  0.28578275,  0.63758403,  0.5423842 ,\n",
              "         0.3377873 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDf3O5sRvNrd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "1a0cf867-f96f-4d9b-8516-5a3b15756190"
      },
      "source": [
        "loaded_model.get_weights()[0][:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.1749801 ,  0.46704558, -0.16897932, -0.22692353, -0.303186  ,\n",
              "         0.61048204, -0.1776686 , -0.2780507 , -0.08611888, -0.03412133,\n",
              "        -0.5807983 , -0.28748602,  0.28578275,  0.63758403,  0.5423842 ,\n",
              "         0.3377873 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yV9RNvVvSPk",
        "colab_type": "text"
      },
      "source": [
        "All 3 are equal as expected\n",
        "\n",
        "> We’ve now seen how to save only the weights of a model and deploy those weights to a new model, how to save only the architecture and then deploy that architecture to a model, and how to save everything about a model and deploy it in its entirety at a later time. Each of these saving and loading mechanisms may come in useful in differing scenarios.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZ894UAOvQxo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}