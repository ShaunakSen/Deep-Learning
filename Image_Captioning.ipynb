{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image Captioning.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShaunakSen/Deep-Learning/blob/master/Image_Captioning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0fO308zAjpQ",
        "colab_type": "text"
      },
      "source": [
        "## How to Develop a Deep Learning Photo Caption Generator from Scratch\n",
        "\n",
        "[link](https://machinelearningmastery.com/develop-a-deep-learning-caption-generation-model-in-python/)\n",
        "\n",
        "### Download and extract the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAf2TVTe0UCK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from urllib.request import urlopen\n",
        "from zipfile import ZipFile\n",
        "\n",
        "zipurl = 'https://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_Dataset.zip'\n",
        "    # Download the file from the URL\n",
        "zipresp = urlopen(zipurl)\n",
        "    # Create a new file on the hard drive\n",
        "tempzip = open(\"/tmp/Flickr8k_Dataset.zip\", \"wb\")\n",
        "    # Write the contents of the downloaded file into the new file\n",
        "tempzip.write(zipresp.read())\n",
        "    # Close the newly-created file\n",
        "tempzip.close()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9M6L9MO1GZ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Re-open the newly-created file with ZipFile()\n",
        "zf = ZipFile(\"/tmp/Flickr8k_Dataset.zip\")\n",
        "    # Extract its contents into <extraction_path>\n",
        "    # note that extractall will automatically create the path\n",
        "zf.extractall(path = './Flickr8k_Dataset')\n",
        "    # close the ZipFile instance\n",
        "zf.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiZlE1qV2bQ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Re-open the newly-created file with ZipFile()\n",
        "zf = ZipFile(\"./Flickr8k_text.zip\")\n",
        "    # Extract its contents into <extraction_path>\n",
        "    # note that extractall will automatically create the path\n",
        "zf.extractall(path = './Flickr8k_text')\n",
        "    # close the ZipFile instance\n",
        "zf.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5uxrkRyBN0F",
        "colab_type": "text"
      },
      "source": [
        "The dataset is present in the following locations:\n",
        "\n",
        "1. Flickr8k_Dataset\n",
        "2. Flickr8k_text\n",
        "\n",
        "The dataset has a pre-defined training dataset (6,000 images), development dataset (1,000 images), and test dataset (1,000 images).\n",
        "\n",
        "One measure that can be used to evaluate the skill of the model are BLEU scores.\n",
        "\n",
        "- BLEU-1: 0.401 to 0.578.\n",
        "- BLEU-2: 0.176 to 0.390.\n",
        "- BLEU-3: 0.099 to 0.260.\n",
        "- BLEU-4: 0.059 to 0.170.\n",
        "\n",
        "We describe the BLEU metric more later when we work on evaluating our model.\n",
        "\n",
        "Next, letâ€™s look at how to load the images.\n",
        "\n",
        "### Prepare Photo Data\n",
        "\n",
        "We will use a pre-trained model to interpret the content of the photos.\n",
        "\n",
        "There are many models to choose from. In this case, we will use the Oxford Visual Geometry Group, or VGG, model that won the ImageNet competition in 2014. Learn more about the model here:\n",
        "\n",
        "[](http://www.robots.ox.ac.uk/~vgg/research/very_deep/)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTptHUsU2f7L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}