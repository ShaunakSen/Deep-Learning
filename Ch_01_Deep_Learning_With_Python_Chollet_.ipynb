{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ch 01 - Deep Learning With Python Chollet .ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOpLWxbl7nbuFJOAZpsVW3h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShaunakSen/Deep-Learning/blob/master/Ch_01_Deep_Learning_With_Python_Chollet_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZE2W28EpY-ni",
        "colab_type": "text"
      },
      "source": [
        "> Notes based on the book [Deep Learning with Python by François Chollet](https://www.manning.com/books/deep-learning-with-python)\n",
        "\n",
        "## Ch 01 What is Deep Learning?\n",
        "\n",
        "A machine-learning model transforms its input data into meaningful outputs, a process that is “learned” from exposure to known examples of inputs and outputs. Therefore, the central problem in machine learning and deep learning is to meaningfully\n",
        "transform data: in other words, to learn useful representations of the input data at\n",
        "hand—representations that get us closer to the expected output. Before we go any\n",
        "further: what’s a representation? At its core, it’s a different way to look at data—to represent or encode data. For instance, a color image can be encoded in the RGB format\n",
        "(red-green-blue) or in the HSV format (hue-saturation-value): these are two different\n",
        "representations of the same data. Some tasks that may be difficult with one representation can become easy with another. For example, the task “select all red pixels in the\n",
        "image” is simpler in the RG format, whereas “make the image less saturated” is simpler\n",
        "in the HSV format. Machine-learning models are all about finding appropriate representations for their input data—transformations of the data that make it more amenable to the task at hand, such as a classification task.\n",
        "\n",
        "### Machine Learning\n",
        "\n",
        "Say we have a 2D plane of black and white points and we find a boundary to separate these points that works very well.\n",
        "\n",
        "In this case, we defined the coordinate change by hand. But if instead we tried systematically searching for different possible coordinate changes, and used as feedback the percentage of points being correctly classified, then we would be doing machine learning. Learning, in the context of machine learning, describes an automatic search process for better representations\n",
        "\n",
        "All machine-learning algorithms consist of automatically finding such transformations that turn data into more-useful representations for a given task. These operations can be coordinate changes, as you just saw, or linear projections (which may destroy information), translations, nonlinear operations (such as “select all points such that x > 0”), and so on. Machine-learning algorithms aren’t usually creative in finding these transformations; they’re merely searching through a predefined set of\n",
        "operations, called a hypothesis space.\n",
        " \n",
        "So that’s what machine learning is, technically: searching for useful representations of some input data, within a predefined space of possibilities, using guidance from a feedback signal. This simple idea allows for solving a remarkably broad range of intellectual tasks, from speech recognition to autonomous car driving.\n",
        "\n",
        "Now that you understand what we mean by learning, let’s take a look at what makes deep learning special. \n",
        "\n",
        "### The “deep” in deep learning\n",
        "\n",
        "Deep learning is a specific subfield of machine learning: a new take on learning representations from data that puts an emphasis on learning successive layers of increasingly\n",
        "meaningful representations. The deep in deep learning isn’t a reference to any kind ofdeeper understanding achieved by the approach; rather, it stands for this idea of successive layers of representations. How many layers contribute to a model of the data iscalled the depth of the model. Other appropriate names for the field could have beenlayered representations learning and hierarchical representations learning. Modern deeplearning often involves tens or even hundreds of successive layers of representations—\n",
        "and they’re all learned automatically from exposure to training data. Meanwhile,\n",
        "other approaches to machine learning tend to focus on learning only one or two layers of representations of the data; hence, they’re sometimes called shallow learning\n",
        "\n",
        " In deep learning, these layered representations are (almost always) learned via\n",
        "models called neural networks, structured in literal layers stacked on top of each other.\n",
        "The term neural network is a reference to neurobiology, but although some of the central concepts in deep learning were developed in part by drawing inspiration from our understanding of the brain, deep-learning models are not models of the brain.\n",
        "There’s no evidence that the brain implements anything like the learning mechanisms used in modern deep-learning models. You may come across pop-science articles proclaiming that deep learning works like the brain or was modeled after the brain, but that isn’t the case. It would be confusing and counterproductive for newcomers to the field to think of deep learning as being in any way related to neurobiology; you don’t need that shroud of “just like our minds” mystique and mystery, and you may as well forget anything you may have read about hypothetical links between deep learning and biology. **For our purposes, deep learning is a mathematical framework for learning representations from data**\n",
        "\n",
        "<img src='./img/fig1.6.png'>\n",
        "\n",
        "As you can see in figure 1.6, the network transforms the digit image into representations that are increasingly different from the original image and increasingly informative about the final result. You can think of a deep network as a multistage information-distillation operation, where information goes through successive filters and comes out increasingly purified (that is, useful with regard to some task).\n",
        "\n",
        "So that’s what deep learning is, technically: a multistage way to learn data representations. It’s a simple idea—but, as it turns out, very simple mechanisms, sufficiently scaled, can end up looking like magic. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LvmN9eufbXp",
        "colab_type": "text"
      },
      "source": [
        "### Understanding how deep learning works, in three figures\n",
        "\n",
        "At this point, you know that machine learning is about mapping inputs (such as\n",
        "images) to targets (such as the label “cat”), which is done by observing many examples of input and targets.You also know that deep neural networks do this input-to-target mapping via a deep sequence of simple data transformations (layers) and that these data transformations are learned by exposure to examples. Now let’s look at how this learning happens, concretely.\n",
        "\n",
        " The specification of what a layer does to its input data is stored in the layer’s weights, which in essence are a bunch of numbers. In this context, learning means finding a set of values for the weights of all layers in a network, such that the network will correctly map example inputs to their associated targets. But here’s the thing: a deep neural network can contain tens of millions of parameters. Finding the correct value for all of them may seem like a daunting task, especially given that modifying the value of one parameter will affect the behavior of all the others!\n",
        "\n",
        "\n",
        " To control the output of\n",
        "a neural network, you need to be able to measure how far this output is from what you expected. This is the job of the loss function of the network, also called the objective function. The loss function takes the predictions of the network and the true target (what you wanted the network to output) and computes a distance score, capturing\n",
        "how well the network has done on this specific example\n",
        "\n",
        "The fundamental trick in deep learning is to use this score as a feedback signal to adjust the value of the weights a little, in a direction that will lower the loss score for the current example (see figure 1.9). This adjustment is the job of the optimizer, which implements what’s called the Backpropagation algorithm: the central algorithm in deep learning. The next chapter explains in more detail how backpropagation works\n",
        "\n",
        "<img src='./img/fig1.9.png'>\n",
        "\n",
        "\n",
        "Initially, the weights of the network are assigned random values, so the network\n",
        "merely implements a series of random transformations. Naturally, its output is far from what it should ideally be, and the loss score is accordingly very high. But with every example the network processes, the weights are adjusted a little in the correct direction, and the loss score decreases. This is the training loop, which, repeated a sufficient number of times (typically tens of iterations over thousands of examples), yields weight values that minimize the loss function. A network with a minimal loss is one for which the outputs are as close as they can be to the targets: a trained network. Once again, it’s a simple mechanism that, once scaled, ends up looking like magic. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuQODsp1Y0ta",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}