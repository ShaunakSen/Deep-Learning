{
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# Deep Learning for Computer Vision\n\n> Notes on the course by Michigan Online:  https://www.youtube.com/playlist?list=PL5-TkQAfAZFbzxjBHtzdVCWE0Zbhomg7r\n\n---\n",
   "metadata": {
    "tags": [],
    "cell_id": "00000-429a937a-431e-452d-8120-beadf51d29d4",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "## Image Classifiers\n\nImage classification is often a building block for other tasks in CV like object detection\n\nOne way for OD is to simply classify diff sub-regions of the image\n\nIt can also be leveraged to play games!\n\n![](https://i.imgur.com/hOphz5G.png)\n\n### Some popular datasets\n\n- MNIST\n- FashionMNIST\n- CIFAR10\n- CIFAR100\n- ImageNet - This has 1000 classes, so we generally predict the top 5 accuracy i.e. our model predicts the top 5 likely classes and its correct if any one of them matches the label\n- MIT Places - The above datasets focused on objects, this one focuses on scenes\n\n![](https://i.imgur.com/f6vdmiH.png)\n\nNote here that the y axis is in log scale, so an increase in bar ht is actually orders of magnitude higher\n\n__Omniglot datatset__:\n\n![](https://i.imgur.com/x4Wo47b.png)\n\n### Nearest Neighbor\n\n![](https://i.imgur.com/f86z2ry.png)\n\nWe need a distance metric that takes in 2 images and gives a no corr to similarity/distance bw the 2 images\n\n- L1 distance: abs value in diff of corr pixel values\n    ![](https://i.imgur.com/A6I2Yzs.png)\n\n![](https://i.imgur.com/r612a5j.png)\n\nBy testing here we mean testing 1 image against N training samples\n\nThis is bad as we can have slow training but at test time we want it to be fast\n\n- this can be solved using __[approximate nearest neighbors search](https://engineering.fb.com/2017/03/29/data-infrastructure/faiss-a-library-for-efficient-similarity-search/)__\n\n\n![](https://i.imgur.com/SuO6nth.png)\n\nAs we can see this method is not that great.. Have a look at the 4th example of the frog.. The colsest matched image is that of a cat but its similar as both have a brownish foreground and white background\n\n![](https://i.imgur.com/iWdJRPg.png)\n\nAs we can see that there is a single yellow training pt in the green region and any test pt near this yellow region might be classified yellow instead of green because of this single yellow pt - maybe that is what we want but this makes the method __sensitive to outliers__\n\nAlso the boundary bw the red and blue region is quite jagged and so againsensitive to outliers\n\n![](https://i.imgur.com/CSTMnv5.png)\n\nBut when k>1 there might be ties bw classes - we can break these by something like min distance \n\n![](https://i.imgur.com/BTKSL9I.png)\n\n#### Diff distance metrics\n\nDiff distance metrics influence the decision boundaries\n\n![](https://i.imgur.com/CnsEQuv.png)\n\n> With the right choice of decision metric we can apply KNN to any kind of data, it can be really powerful when used correctly.\n\n\n### Setting hyperparameters\n\n#### Idea 1 : Take entire dataset and chose hyperparams that work best on the overall data\n\n![](https://i.imgur.com/YJyMkT7.png)\n\n#### Idea 2: Split into train-test, use hyperparams that work best on test data\n\nThis seems like a better approach, but __its wrong__. Once we look at the test set and use that knowledge to train the algo, we are introducing data leakage. This pollutes our idea of how that algo will actually perform on unseen data. We have used test set to tune hyperparams, so test set is no longer unseen, so performance of model on test set means nothing anymore!\n\n![](https://i.imgur.com/YpoSMYB.png)\n\n#### Idea 3: Use Split into train-val-test, chose hyperparams on val, eval on test\n\nWe tune hyperparams taking feedback on performance on val set, once hyperparams are fixed, at the very end we eval on test set\n\n\n#### Idea 4: Cross validation\n\n![](https://i.imgur.com/i0iJTab.png)\n\nTrain on each of the 4 folds and eval on the other fold, take avg of the validation errors\n\n#### KNN - Universal approximation\n\nAs the no of training examples reach close to infinity the KNN algorithm can approxoamte any function\n\n![](https://i.imgur.com/l2hgv99.png)\n\n![](https://i.imgur.com/tz6YCUp.png)\n\n\n\n",
   "metadata": {
    "tags": [],
    "cell_id": "00001-6a5ceb84-6071-416e-bfd5-aa8ac6433edd",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "![Picture title](image-20210912-143835.png)",
   "metadata": {
    "tags": [],
    "cell_id": "00002-274747ab-861d-4c0e-a947-6024464b1d38",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00000-64c9c520-d372-4e09-bae2-0ab6d582e830",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "8ad57f32",
    "execution_start": 1631433388268,
    "execution_millis": 5,
    "deepnote_cell_type": "code"
   },
   "source": "# Start writing code here...",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {
    "tags": [],
    "cell_id": "00003-f046461b-47a9-44e5-85d3-ae01f823376f",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=42359498-c03e-4734-b664-807213a846dc' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
   "metadata": {
    "tags": [],
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "orig_nbformat": 2,
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_notebook_id": "67d72b50-689f-4293-9749-18c74f3651bd",
  "deepnote_execution_queue": []
 }
}