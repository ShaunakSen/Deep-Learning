{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of 3_1_gradient_descent.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShaunakSen/Deep-Learning/blob/master/Copy_of_3_1_gradient_descent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "fd2c27ac75b58ab9cfdb05285bcf0292",
          "grade": false,
          "grade_id": "cell-9eeeb7abc468a506",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "UfVVzk9wazqm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Part 1: Gradient Descent"
      ]
    },
    {
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "7515d498d97561d9884b0802387b3be4",
          "grade": false,
          "grade_id": "cell-52980e134e2f9e19",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "DbNxvQhGazqn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In this lab we will implement some of the optimisation methods we learned in the lecture. First, we will start by revisiting gradient descent for linear regression. However, in this implementation we will observe how the model parameters are updated over iterations of the gradient descent algorithm. \n",
        "\n",
        "Let's start by implementing gradient descent on a simple linear regression dataset, like the one you generated in Lab 1, but this time shifted so that it ranges from -5 to 5."
      ]
    },
    {
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "ca9cf8bef763c9249a69f3120f9749b4",
          "grade": true,
          "grade_id": "cell-02c39c20df2f2d24",
          "locked": false,
          "points": 1,
          "schema_version": 1,
          "solution": true
        },
        "id": "4oYv9NjNazqp",
        "colab_type": "code",
        "outputId": "29f9a474-843d-4afe-e95e-271c24226204",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "## generate M data points roughly forming a line (noise added)\n",
        "M = 100\n",
        "theta_true = torch.Tensor([[0.5], [2]])\n",
        "\n",
        "\n",
        "X = 10 * torch.rand(M, 2) - 5\n",
        "X[:, 1] = 1.0\n",
        "\n",
        "print(X.shape)\n",
        "\n",
        "y = torch.mm(X, theta_true) + 0.3 * torch.randn(M, 1)\n",
        "\n",
        "# print(y.shape)\n",
        "\n",
        "# print(X[:,0].numpy())\n",
        "\n",
        "# print(y.numpy().reshape(1,100)[0])\n",
        "\n",
        "plt.scatter(X[:,0].numpy(), y.numpy().reshape(1,100)[0])\n",
        "\n",
        "## visualise the data by plotting it\n",
        "# YOUR CODE HERE\n",
        "# raise NotImplementedError()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([100, 2])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f124ab7a400>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAd8AAAFKCAYAAABcq1WoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "0b22b69e67951075996148ee0cb75f26",
          "grade": false,
          "grade_id": "cell-4c65a1279417a414",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "0Y_HyeZgazqs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "You should now have data points according to y = mx + b where m = theta_true[0,0] and b = theta_true[1,0]. Note, $m = \\theta_1$ and $b = \\theta_0$.\n",
        "\n",
        "Now, let's implement gradient descent using the Mean Squared Error (MSE) cost function. \n",
        "\n",
        "Recall that: \n",
        "\n",
        "$J(\\theta) = \\frac{1}{2 M} \\sum_{i = 1}^M (h_{\\theta} (x^{(i)}) - y^{(i)} )^2$\n",
        "\n",
        "for $i = 1 \\text{  to iters (or until convergence)}$ <br>\n",
        "\n",
        "$\\hspace{1cm} w_i \\leftarrow w_i - \\eta \\frac{\\partial J}{\\partial w_i}$\n",
        "\n",
        "Implement the functions below in order to plot the cost function as well as the weight updates over iterations of gradient descent."
      ]
    },
    {
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "f7f41955a715267d6d73e184b8b43388",
          "grade": true,
          "grade_id": "cell-a52e2455d84ff4da",
          "locked": false,
          "points": 5,
          "schema_version": 1,
          "solution": true
        },
        "id": "d5KKXaH2azqt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "## hypothesis computes $h_theta$\n",
        "def hypothesis(theta, X):\n",
        "    # YOUR CODE HERE\n",
        "    \n",
        "    return X.mm(theta)\n",
        "  \n",
        "    \n",
        "    # raise NotImplementedError()\n",
        "\n",
        "## grad_cost_func computes the gradient of J for linear regression given J is the MSE \n",
        "def grad_cost_func(theta, X, y): \n",
        "    # YOUR CODE HERE\n",
        "    \n",
        "    M = X.shape[1]\n",
        "    \n",
        "    grad = 1/M * X.t().mm(hypothesis(theta, X) - y)\n",
        "    \n",
        "    # raise NotImplementedError()\n",
        "    \n",
        "    return grad\n",
        "\n",
        "## cost_func computes the cost function J\n",
        "def cost_func(theta, X, y): \n",
        "    # YOUR CODE HERE\n",
        "    \n",
        "    # 2x1, 100x2, 100x1\n",
        "    \n",
        "    M = X.shape[1]\n",
        "    \n",
        "    h_theta = hypothesis(theta, X)\n",
        "    \n",
        "    loss = 1/2*M * ((h_theta-y).t().mm(h_theta-y))\n",
        "    \n",
        "    return [loss]\n",
        "    \n",
        "    # raise NotImplementedError()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7J4S6SLBeZnt",
        "colab_type": "code",
        "outputId": "ed88320e-889e-4b14-e9b9-0f74716b8cda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "print(X.shape, theta_true.shape, y.shape)\n",
        "\n",
        "print(X.mm(theta_true).shape)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([100, 2]) torch.Size([2, 1]) torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "81607b0b07d30d5873cfc349f49a5000",
          "grade": false,
          "grade_id": "cell-d0cb37c31097d491",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "KNKJ78XFazqv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now let's plot the updates to see what is happening as we iterate over the algorithm. First, we will plot $J$ as a function of $\\theta_1$ as well as the resulting equation of the line learned over $N=5$ iterations. Once your code is working, modify the value of $\\eta$ to see how it affects convergence.\n",
        "\n",
        "The figure below illustrates what you're aiming to plot. Note, much of the code to generate the figures is given below, you mostly need to complete the 3 functions above and then fill in a few missing lines of code below."
      ]
    },
    {
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "0c8aa3bd5465cf5b8a6d2ad5976e69ff",
          "grade": false,
          "grade_id": "cell-32de56d64c670852",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "wOXjYE7Zazqv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<img src=\"http://comp6248.ecs.soton.ac.uk/labs/lab3/Figure1.png\">"
      ]
    },
    {
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "b50e9a89855e23ac6ffc655323c55876",
          "grade": false,
          "grade_id": "cell-59662fa076965410",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "gdt513Fnazqw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### First generate the figure on the left hand side. This plot shows the data and the linear fit of the data as the model parameters change over the 5 iterations."
      ]
    },
    {
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "ba6c7a291b78ef143956304d0159ea52",
          "grade": true,
          "grade_id": "cell-7663cd58d1e91c37",
          "locked": false,
          "points": 2,
          "schema_version": 1,
          "solution": true
        },
        "id": "rtLNR0Toazqw",
        "colab_type": "code",
        "outputId": "6f7ff6cd-9e7b-4e3f-adcc-d39b9b5166a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "cell_type": "code",
      "source": [
        "## Now we can plot the lines over iterations\n",
        "## To do this, we start by constructing a grid of parameter pairs and their corresponding cost function values. \n",
        "\n",
        "# plot 100 pts\n",
        "x_axis = np.linspace(-1,1,100)\n",
        "\n",
        "\n",
        "theta_grid = torch.Tensor(len(x_axis),2)\n",
        "\n",
        "# theta_grid shape: 100x2\n",
        "\n",
        "# fill 1st col with values from x_axis and 2nd col with 2\n",
        "\n",
        "theta_grid[:,0] = torch.from_numpy(x_axis)\n",
        "theta_grid[:,1] = 2.0\n",
        "\n",
        "J_grid = cost_func(theta_grid.t(), X, y)\n",
        "\n",
        "N = 5\n",
        "eta = 0.003\n",
        "\n",
        "theta_0 = torch.Tensor([[0.0], [2.0]]) #initialise \n",
        "J_t = torch.Tensor(1,N)\n",
        "theta = torch.Tensor(2,1,N)\n",
        "J_t[:,0] = cost_func(theta_0, X, y)[0]\n",
        "theta[:,:,0] = theta_0\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for j in range(1,N):\n",
        "    last_theta = theta[:,:,j-1]\n",
        "    ## Compute the value of this_theta\n",
        "    # YOUR CODE HERE\n",
        "    # raise NotImplementedError()\n",
        "    \n",
        "    grad = grad_cost_func(last_theta, X, y)\n",
        "    \n",
        "    # print (\"Grad:\", grad)\n",
        "    \n",
        "    this_theta = last_theta - eta*grad\n",
        "    \n",
        "    \n",
        "    theta[:,:,j] = this_theta\n",
        "    J_t[:,j] = cost_func(this_theta,X,y)[0]\n",
        "    \n",
        "print(J_t, theta)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "    \n",
        "colors = ['b', 'g', 'm', 'c', 'orange']\n",
        "\n",
        "## Plot the data \n",
        "# YOUR CODE HERE\n",
        "# raise NotImplementedError()\n",
        "\n",
        "plt.xlabel(r'$x$')\n",
        "plt.ylabel(r'$y$')\n",
        "plt.title('Data and fit')\n",
        "\n",
        "\"\"\""
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[229.7044,  40.7348,  14.6561,  11.0476,  10.5414]]) tensor([[[0.0000, 0.6710, 0.4221, 0.5147, 0.4805]],\n",
            "\n",
            "        [[2.0000, 1.9751, 1.9901, 1.9894, 1.9938]]])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n    \\ncolors = ['b', 'g', 'm', 'c', 'orange']\\n\\n## Plot the data \\n# YOUR CODE HERE\\n# raise NotImplementedError()\\n\\nplt.xlabel(r'$x$')\\nplt.ylabel(r'$y$')\\nplt.title('Data and fit')\\n\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "metadata": {
        "id": "v6jQo5gIDKuN",
        "colab_type": "code",
        "outputId": "2ffd6db5-d299-48a4-c81b-0a5b8166ea6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "test = torch.Tensor(2, 1, 5)\n",
        "print(test)\n",
        "\n",
        "print(test[:,0,:])\n",
        "\n",
        "T_data = [[[1., 2.], \n",
        "           [3., 4.]],\n",
        "          [[5., 6.], \n",
        "           [7., 8.]],\n",
        "          [[9., 10.],\n",
        "           [11., 12.]]\n",
        "         ]\n",
        "\n",
        "\n",
        "T = torch.tensor(T_data)\n",
        "print(T.shape)\n",
        "\n",
        "print(T[2])\n",
        "\n",
        "theta = torch.Tensor(2,1,5)\n",
        "\n",
        "print(theta)\n",
        "\n",
        "print(theta[:,:,0])\n",
        "\n",
        "\"\"\"\n",
        "J = torch.Tensor(1,5)\n",
        "\n",
        "print(J)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[5.4926e-36, 0.0000e+00, 0.0000e+00, 0.0000e+00,        nan]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "eaa1ff5b63e1b744b02ea8afa8c533a5",
          "grade": false,
          "grade_id": "cell-e7fd81fa921c6327",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "QzQYC0_1azqy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Next, generate the plots on the right hand side. This figure is a plot of the cost function over the value of $\\theta_1$ as well as the updates of $\\theta_1$ over iterations."
      ]
    },
    {
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "af94209b76d722c3775a2015d1b90dbc",
          "grade": true,
          "grade_id": "cell-c9fa638485b0726e",
          "locked": false,
          "points": 1,
          "schema_version": 1,
          "solution": true
        },
        "id": "v3ZQpCGQazq0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE\n",
        "raise NotImplementedError()\n",
        "\n",
        "# add the plot axes labels and title\n",
        "plt.xlabel(r'$\\theta_1$')\n",
        "plt.ylabel(r'$J(\\theta_1)$')\n",
        "plt.title('Cost function')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "d06192ebc2f3cc31e5c1d42b924f1283",
          "grade": false,
          "grade_id": "cell-e70124241b132a09",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "djMgC7cpazq2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Finally, generate a contour plot of the cost function"
      ]
    },
    {
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "c5a3cbc10e84dcf6671cd5f1ff181839",
          "grade": true,
          "grade_id": "cell-83e4d7737cbda3d1",
          "locked": false,
          "points": 1,
          "schema_version": 1,
          "solution": true
        },
        "id": "W7TSbAYPazq2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## Generate a grid of values for theta_0 and theta_1 and compute the cost function for every combination.\n",
        "\n",
        "theta_0_vals = np.linspace(-1.0,1,100)\n",
        "theta_1_vals = np.linspace(-4.0,4,100)\n",
        "theta = torch.Tensor(len(theta_0_vals),2)\n",
        "\n",
        "# Compute the cost function over every combination of values for theta in a variable called J which will then be plot below\n",
        "# YOUR CODE HERE\n",
        "raise NotImplementedError()\n",
        "\n",
        "xc,yc = np.meshgrid(theta_0_vals, theta_1_vals)\n",
        "contours = plt.contour(xc, yc, J, 20)\n",
        "plt.clabel(contours)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}