{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image Captioning.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShaunakSen/Deep-Learning/blob/master/Image_Captioning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMYJhfFPV1V4",
        "colab_type": "text"
      },
      "source": [
        "## How to Use The Pre-Trained VGG Model to Classify Objects in Photographs\n",
        "\n",
        "[link](https://machinelearningmastery.com/use-pre-trained-vgg-model-classify-objects-photographs/)\n",
        "\n",
        "Convolutional neural networks are now capable of outperforming humans on some computer vision tasks, such as classifying images.\n",
        "\n",
        "That is, given a photograph of an object, answer the question as to which of 1,000 specific objects the photograph shows.\n",
        "\n",
        "A competition-winning model for this task is the VGG model by researchers at Oxford. What is important about this model, besides its capability of classifying objects in photographs, is that the model weights are freely available and can be loaded and used in your own models and applications.\n",
        "\n",
        "### ImageNet\n",
        "\n",
        "ImageNet is a research project to develop a large database of images with annotations, e.g. images and their descriptions.\n",
        "\n",
        "The images and their annotations have been the basis for an image classification challenge called the ImageNet Large Scale Visual Recognition Challenge or ILSVRC since 2010. The result is that research organizations battle it out on pre-defined datasets to see who has the best model for classifying the objects in images.\n",
        "\n",
        "For the classification task, images must be classified into one of 1,000 different categories.\n",
        "\n",
        "For the last few years very deep convolutional neural network models have been used to win these challenges and results on the tasks have exceeded human performance.\n",
        "\n",
        "### The Oxford VGG Models\n",
        "\n",
        "Researchers from the Oxford Visual Geometry Group, or VGG for short, participate in the ILSVRC challenge.\n",
        "\n",
        "In 2014, convolutional neural network models (CNN) developed by the VGG won the image classification tasks.\n",
        "\n",
        "VGG released two different CNN models, specifically a 16-layer model and a 19-layer model.\n",
        "\n",
        "The VGG models are not longer state-of-the-art by only a few percentage points. Nevertheless, they are very powerful models and useful both as image classifiers and as the basis for new models that use image inputs.\n",
        "\n",
        "### Load the VGG Model in Keras\n",
        "\n",
        "The VGG model can be loaded and used in the Keras deep learning library.\n",
        "\n",
        "Keras provides an Applications interface for loading and using pre-trained models.\n",
        "\n",
        "Using this interface, you can create a VGG model using the pre-trained weights provided by the Oxford group and use it as a starting point in your own model, or use it as a model directly for classifying images.\n",
        "\n",
        "In this tutorial, we will focus on the use case of classifying new images using the VGG model.\n",
        "\n",
        "Keras provides both the 16-layer and 19-layer version via the VGG16 and VGG19 classes. Let’s focus on the VGG16 model.\n",
        "\n",
        "The model can be created as follows:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gh9QjvX7Yl84",
        "colab_type": "code",
        "outputId": "ff91f2f3-7afe-41ca-f15b-fde8a3b4cdb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        }
      },
      "source": [
        "from keras.applications.vgg16 import VGG16\n",
        "\n",
        "model = VGG16()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0725 10:29:14.265747 139705347217280 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0725 10:29:14.283389 139705347217280 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0725 10:29:14.287281 139705347217280 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0725 10:29:14.335521 139705347217280 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "W0725 10:29:18.210647 139705347217280 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0725 10:29:18.212412 139705347217280 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vid1krbHZAPs",
        "colab_type": "text"
      },
      "source": [
        "That’s it.\n",
        "\n",
        "The first time you run this example, Keras will download the weight files from the Internet and store them in the ~/.keras/models directory.\n",
        "\n",
        "Note that the weights are about 528 megabytes, so the download may take a few minutes depending on the speed of your Internet connection.\n",
        "\n",
        "The weights are only downloaded once. The next time you run the example, the weights are loaded locally and the model should be ready to use in seconds.\n",
        "\n",
        "We can use the standard Keras tools for inspecting the model structure.\n",
        "\n",
        "For example, you can print a summary of the network layers as follows:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEpUeJMgZLtL",
        "colab_type": "code",
        "outputId": "df060565-27a3-46e2-de30-ea96e109c91d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 976
        }
      },
      "source": [
        "print (model.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 138,357,544\n",
            "Trainable params: 138,357,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2A7AXr6ZAGE",
        "colab_type": "text"
      },
      "source": [
        "You can see that the model is huge.\n",
        "\n",
        "You can also see that, by default, the model expects images as input with the size 224 x 224 pixels with 3 channels (e.g. color).\n",
        "\n",
        "![](https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2017/08/Plot-of-Layers-in-the-VGG-Model.png)\n",
        "\n",
        "The VGG() class takes a few arguments that may only interest you if you are looking to use the model in your own project, e.g. for transfer learning.\n",
        "\n",
        "\n",
        "For example:\n",
        "\n",
        "- include_top (True): Whether or not to include the output layers for the model. You don’t need these if you are fitting the model on your own problem.\n",
        "- weights (‘imagenet‘): What weights to load. You can specify None to not load pre-trained weights if you are interested in training the model yourself from scratch.\n",
        "- input_tensor (None): A new input layer if you intend to fit the model on new data of a different size.\n",
        "- input_shape (None): The size of images that the model is expected to take if you change the input layer.\n",
        "- pooling (None): The type of pooling to use when you are training a new set of output layers.\n",
        "- classes (1000): The number of classes (e.g. size of output vector) for the model.\n",
        "\n",
        "\n",
        "Next, let’s look at using the loaded VGG model to classify ad hoc photographs.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRPSs-Q7Y_43",
        "colab_type": "text"
      },
      "source": [
        "### Develop a Simple Photo Classifier\n",
        "\n",
        "Next, we can load the image as pixel data and prepare it to be presented to the network.\n",
        "\n",
        "Keras provides some tools to help with this step.\n",
        "\n",
        "First, we can use the load_img() function to load the image and resize it to the required size of 224×224 pixels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erII1vG3ashH",
        "colab_type": "code",
        "outputId": "aa44b3e9-8a5b-4c54-e80a-26e4d99c6bad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "# load img from file\n",
        "image = load_img(path='./4994221690_d070e8a355_z.jpg', target_size=(224, 224))\n",
        "\n",
        "# Next, we can convert the pixels to a NumPy array so that we can work with it in Keras.\n",
        "# We can use the img_to_array() function for this.\n",
        "\n",
        "image = img_to_array(img=image)\n",
        "\n",
        "print (image.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(224, 224, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mja5h3WEbief",
        "colab_type": "text"
      },
      "source": [
        "The network expects one or more images as input; that means the input array will need to be 4-dimensional: `[samples, rows, columns, and channels]`.\n",
        "\n",
        "We only have one sample (one image). We can reshape the array by calling reshape() and adding the extra dimension.\n",
        "\n",
        "\n",
        "Next, the image pixels need to be prepared in the same way as the ImageNet training data was prepared. Specifically, from the paper:\n",
        "\n",
        "> The only preprocessing we do is subtracting the mean RGB value, computed on the training set, from each pixel.\n",
        "\n",
        "Keras provides a function called preprocess_input() to prepare new input for the network.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9S-eDe1arTd",
        "colab_type": "code",
        "outputId": "8651e6b5-f50f-4932-c03c-16ae0a464a7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# reshape data for the model\n",
        "image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
        "\n",
        "print (image.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 224, 224, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrFXZKX1crT3",
        "colab_type": "code",
        "outputId": "44bb64ff-416d-4955-92b5-5fd6f134e36e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.applications.vgg16 import preprocess_input\n",
        "\n",
        "# prepare the image for the VGG model\n",
        "image = preprocess_input(image)\n",
        "\n",
        "print (image.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 224, 224, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKlqjwl3dkLJ",
        "colab_type": "text"
      },
      "source": [
        "We are now ready to make a prediction for our loaded and prepared image.\n",
        "\n",
        "We can call the predict() function on the model in order to get a prediction of the probability of the image belonging to each of the 1000 known object types.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eh0y5wJQd0q-",
        "colab_type": "code",
        "outputId": "1ecf9ad0-d19f-4b53-de47-4ba52553e02b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# predict the probability across all output classes\n",
        "yhat = model.predict(image)\n",
        "\n",
        "print (yhat.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 1000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EkV3KaJAeGuL",
        "colab_type": "text"
      },
      "source": [
        "Keras provides a function to interpret the probabilities called decode_predictions().\n",
        "\n",
        "It can return a list of classes and their probabilities in case you would like to present the top 3 objects that may be in the photo.\n",
        "\n",
        "We will just report the first most likely object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIRm3noTeHqA",
        "colab_type": "code",
        "outputId": "3119c54e-4c2c-45ae-b896-bb95cd368579",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "from keras.applications.vgg16 import decode_predictions\n",
        "\n",
        "# convert the probabilities to class labels\n",
        "label = decode_predictions(yhat)\n",
        "\n",
        "print (len(label[0]))\n",
        "\n",
        "# retrieve the most likely result, e.g. highest probability\n",
        "\n",
        "label = label[0][0]\n",
        "\n",
        "print (label)\n",
        "\n",
        "print('%s (%.2f%%)' % (label[1], label[2]*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n",
            "('n03063599', 'coffee_mug', 0.73363245)\n",
            "coffee_mug (73.36%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0fO308zAjpQ",
        "colab_type": "text"
      },
      "source": [
        "## How to Develop a Deep Learning Photo Caption Generator from Scratch\n",
        "\n",
        "[link](https://machinelearningmastery.com/develop-a-deep-learning-caption-generation-model-in-python/)\n",
        "\n",
        "### Download and extract the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAf2TVTe0UCK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from urllib.request import urlopen\n",
        "from zipfile import ZipFile\n",
        "\n",
        "zipurl = 'https://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_Dataset.zip'\n",
        "    # Download the file from the URL\n",
        "zipresp = urlopen(zipurl)\n",
        "    # Create a new file on the hard drive\n",
        "tempzip = open(\"/tmp/Flickr8k_Dataset.zip\", \"wb\")\n",
        "    # Write the contents of the downloaded file into the new file\n",
        "tempzip.write(zipresp.read())\n",
        "    # Close the newly-created file\n",
        "tempzip.close()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EBlcE9wSUxq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "zipurl = 'https://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_text.zip'\n",
        "    # Download the file from the URL\n",
        "zipresp = urlopen(zipurl)\n",
        "    # Create a new file on the hard drive\n",
        "tempzip = open(\"/tmp/Flickr8k_text.zip\", \"wb\")\n",
        "    # Write the contents of the downloaded file into the new file\n",
        "tempzip.write(zipresp.read())\n",
        "    # Close the newly-created file\n",
        "tempzip.close()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9M6L9MO1GZ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Re-open the newly-created file with ZipFile()\n",
        "zf = ZipFile(\"/tmp/Flickr8k_Dataset.zip\")\n",
        "    # Extract its contents into <extraction_path>\n",
        "    # note that extractall will automatically create the path\n",
        "zf.extractall(path = './Flickr8k_Dataset')\n",
        "    # close the ZipFile instance\n",
        "zf.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiZlE1qV2bQ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Re-open the newly-created file with ZipFile()\n",
        "zf = ZipFile(\"/tmp/Flickr8k_text.zip\")\n",
        "    # Extract its contents into <extraction_path>\n",
        "    # note that extractall will automatically create the path\n",
        "zf.extractall(path = './Flickr8k_text')\n",
        "    # close the ZipFile instance\n",
        "zf.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5uxrkRyBN0F",
        "colab_type": "text"
      },
      "source": [
        "The dataset is present in the following locations:\n",
        "\n",
        "1. Flickr8k_Dataset\n",
        "2. Flickr8k_text\n",
        "\n",
        "The dataset has a pre-defined training dataset (6,000 images), development dataset (1,000 images), and test dataset (1,000 images).\n",
        "\n",
        "One measure that can be used to evaluate the skill of the model are BLEU scores.\n",
        "\n",
        "- BLEU-1: 0.401 to 0.578.\n",
        "- BLEU-2: 0.176 to 0.390.\n",
        "- BLEU-3: 0.099 to 0.260.\n",
        "- BLEU-4: 0.059 to 0.170.\n",
        "\n",
        "We describe the BLEU metric more later when we work on evaluating our model.\n",
        "\n",
        "Next, let’s look at how to load the images.\n",
        "\n",
        "### Prepare Photo Data\n",
        "\n",
        "We will use a pre-trained model to interpret the content of the photos.\n",
        "\n",
        "There are many models to choose from. In this case, we will use the Oxford Visual Geometry Group, or VGG, model that won the ImageNet competition in 2014. Learn more about the model here:\n",
        "\n",
        "[](http://www.robots.ox.ac.uk/~vgg/research/very_deep/)\n",
        "\n",
        "Keras provides this pre-trained model directly. Note, the first time you use this model, Keras will download the model weights from the Internet, which are about 500 Megabytes. This may take a few minutes depending on your internet connection.\n",
        "\n",
        "\n",
        "We could use this model as part of a broader image caption model. The problem is, it is a large model and running each photo through the network every time we want to test a new language model configuration (downstream) is redundant.\n",
        "\n",
        "Instead, we can pre-compute the “photo features” using the pre-trained model and save them to file. We can then load these features later and feed them into our model as the interpretation of a given photo in the dataset. It is no different to running the photo through the full VGG model; it is just we will have done it once in advance.\n",
        "\n",
        "This is an optimization that will make training our models faster and consume less memory.\n",
        "\n",
        "We can load the VGG model in Keras using the VGG class. We will remove the last layer from the loaded model, as this is the model used to predict a classification for a photo. We are not interested in classifying images, but we are interested in the internal representation of the photo right before a classification is made. These are the “features” that the model has extracted from the photo.\n",
        "\n",
        "Keras also provides tools for reshaping the loaded photo into the preferred size for the model (e.g. 3 channel 224 x 224 pixel image).\n",
        "\n",
        "Below is a function named extract_features() that, given a directory name, will load each photo, prepare it for VGG, and collect the predicted features from the VGG model. The image features are a 1-dimensional 4,096 element vector.\n",
        "\n",
        "The function returns a dictionary of image identifier to image features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTptHUsU2f7L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from os import listdir\n",
        "from pickle import dump\n",
        "\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.models import Model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-08Ac3pODQK",
        "colab_type": "text"
      },
      "source": [
        "We can call this function to prepare the photo data for testing our models, then save the resulting dictionary to a file named ‘features.pkl‘."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuAJ1orcOVrW",
        "colab_type": "code",
        "outputId": "f357a241-134c-480a-b46e-3d91b5b5ed08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model=VGG16()\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0725 14:24:34.233823 140578825090944 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0725 14:24:34.273075 140578825090944 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0725 14:24:34.279536 140578825090944 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0725 14:24:34.406171 140578825090944 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "553467904/553467096 [==============================] - 7s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0725 14:24:41.759498 140578825090944 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0725 14:24:41.760585 140578825090944 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 138,357,544\n",
            "Trainable params: 138,357,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUnTc8C5Km9Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print (\"No of images:\", len(listdir(path='./Flickr8k_Dataset/Flicker8k_Dataset/')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vligLZzVOD8G",
        "colab_type": "code",
        "outputId": "6b43d18c-ee6d-4b92-aeee-3493e4e3266d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 958
        }
      },
      "source": [
        "def extract_features(directory):\n",
        "  \"\"\"\n",
        "  extract features from each photo in the directory\n",
        "  \"\"\"\n",
        "  \n",
        "  # load the model\n",
        "  model = VGG16()\n",
        "  \n",
        "  # restructure the model\n",
        "  model.layers.pop()\n",
        "  model = Model(inputs=model.inputs, outputs=model.layers[-1].output)\n",
        "  \n",
        "  # summarize\n",
        "  print (model.summary())\n",
        "  \n",
        "  \n",
        "  # extract features from each photo\n",
        "  features = dict()\n",
        "  \n",
        "  # Return a list containing the names of the files in the directory.\n",
        "  for name in listdir(path=directory):\n",
        "    \n",
        "    # load an image from file\n",
        "    filename = directory + '/' + name\n",
        "    image = load_img(path=filename, target_size=(224,224))\n",
        "    \n",
        "    # convert the image pixels to a numpy array\n",
        "    image = img_to_array(img=image)\n",
        "    \n",
        "    # reshape data for the model\n",
        "    # The network expects one or more images as input; \n",
        "    # that means the input array will need to be 4-dimensional: \n",
        "    # [samples, rows, columns, and channels]\n",
        "    image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
        "    \n",
        "    # prepare the image for the VGG model\n",
        "    image = preprocess_input(image)\n",
        "    \n",
        "    # get features\n",
        "    feature = model.predict(x=image, verbose=0)\n",
        "    \n",
        "    # get image id\n",
        "    image_id = name.split('.')[0]\n",
        "    \n",
        "    # store feature in the dict\n",
        "    features[image_id] = feature\n",
        "    \n",
        "    \n",
        "    \n",
        "  return features\n",
        "  \n",
        "directory = './Flickr8k_Dataset/Flicker8k_Dataset/'\n",
        "\n",
        "features = extract_features(directory)\n",
        "print('Extracted Features: %d' % len(features))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "=================================================================\n",
            "Total params: 134,260,544\n",
            "Trainable params: 134,260,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Extracted Features: 8091\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ifmg4UZ3FgKX",
        "colab_type": "text"
      },
      "source": [
        "For each image now we have the features (4096) from the VGG16 model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ahwi8zMFW32",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features['221973402_ecb1cd51f1'].shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqBzjhqfNobD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save to file\n",
        "dump(features, open('features.pkl', 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPe9vLNdP8bx",
        "colab_type": "text"
      },
      "source": [
        "### Prepare Text Data\n",
        "\n",
        "The dataset contains multiple descriptions for each photograph and the text of the descriptions requires some minimal cleaning.\n",
        "\n",
        "\n",
        "First, we will load the file containing all of the descriptions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7WNvEKDPZRW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load the doc into memory\n",
        "def load_doc(filename):\n",
        "  # open the file as read only\n",
        "  file = open(file=filename, mode='r')\n",
        "  # read all text\n",
        "  text = file.read()\n",
        "  # close the file\n",
        "  file.close()\n",
        "  return text\n",
        "\n",
        "filename = './Flickr8k_text/Flickr8k.token.txt'\n",
        "\n",
        "doc = load_doc(filename)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDgNvDEJRA5p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(doc[:200])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBlmk8dCUESI",
        "colab_type": "text"
      },
      "source": [
        "Each photo has a unique identifier. This identifier is used on the photo filename and in the text file of descriptions.\n",
        "\n",
        "Next, we will step through the list of photo descriptions. Below defines a function load_descriptions() that, given the loaded document text, will return a dictionary of photo identifiers to descriptions. Each photo identifier maps to a list of one or more textual descriptions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGCTG6w3Ud8p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "doc.split(\"\\n\")[:10][0].split()[1:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZHnyck-UFRQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# extract descriptions for images\n",
        "def load_descriptions(doc):\n",
        "  mapping=dict()\n",
        "\n",
        "  # process line by line\n",
        "  for line in doc.split(\"\\n\"):\n",
        "    # split line by white space\n",
        "    tokens = line.split()\n",
        "    # check min length\n",
        "    if len(line) < 2:\n",
        "      continue\n",
        "    # take the first token as the image id, the rest as the description\n",
        "    image_id, image_desc = tokens[0], tokens[1:]\n",
        "\n",
        "    # remove filename from image id\n",
        "    image_id = image_id.split('.')[0]\n",
        "\n",
        "    # convert description tokens back to string\n",
        "    image_desc = ' '.join(image_desc)\n",
        "\n",
        "    # create an emty list for a new image_id\n",
        "    if image_id not in mapping:\n",
        "      mapping[image_id] = list()\n",
        "\n",
        "    # append desc for the corr image_id\n",
        "\n",
        "    mapping[image_id].append(image_desc)\n",
        "\n",
        "  return mapping\n",
        "\n",
        "# parse descriptions\n",
        "descriptions = load_descriptions(doc)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xXUZcWoGFom",
        "colab_type": "text"
      },
      "source": [
        "`descriptions` is similar to `features`. Here we have the file names as keys and the captions as an array of values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rv9jMzGGF_MG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "descriptions['221973402_ecb1cd51f1']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYphEf7dpbWg",
        "colab_type": "text"
      },
      "source": [
        "Next, we need to clean the description text. The descriptions are already tokenized and easy to work with.\n",
        "\n",
        "We will clean the text in the following ways in order to reduce the size of the vocabulary of words we will need to work with:\n",
        "\n",
        "- Convert all words to lowercase.\n",
        "- Remove all punctuation.\n",
        "- Remove all words that are one character or less in length (e.g. ‘a’).\n",
        "- Remove all words with numbers in them.\n",
        "\n",
        "Below defines the clean_descriptions() function that, given the dictionary of image identifiers to descriptions, steps through each description and cleans the text.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVfPhvKkZXbX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import string\n",
        "\n",
        "def clean_descriptions(descriptions):\n",
        "  # prepare translation table for removing punctuation\n",
        "  table = str.maketrans('', '', string.punctuation)\n",
        "  \n",
        "  for key, desc_list in descriptions.items():\n",
        "    # for each desc of an image:\n",
        "    for i in range(len(desc_list)):\n",
        "      desc = desc_list[i]\n",
        "\n",
        "      # tokenize\n",
        "      desc = desc.split()\n",
        "\n",
        "      # convert to lowercase\n",
        "      desc = [word.lower() for word in desc]\n",
        "\n",
        "      # remove punctuation from each token\n",
        "      desc = [w.translate(table) for w in desc]\n",
        "\n",
        "      # remove hanging 's' and 'a'\n",
        "      desc = [word for word in desc if len(word)>1]\n",
        "\n",
        "      # remove tokens with numbers in them\n",
        "      desc = [word for word in desc if word.isalpha()]\n",
        "\n",
        "      # replace it in that index position\n",
        "      desc_list[i] = ' '.join(desc)\n",
        "\n",
        "\n",
        "# clean descriptions\n",
        "clean_descriptions(descriptions)\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQhqHfNjGVfP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "descriptions['221973402_ecb1cd51f1']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0O6qqTC23LX",
        "colab_type": "text"
      },
      "source": [
        "Once cleaned, we can summarize the size of the vocabulary.\n",
        "\n",
        "Ideally, we want a vocabulary that is both expressive and as small as possible. A smaller vocabulary will result in a smaller model that will train faster.\n",
        "\n",
        "For reference, we can transform the clean descriptions into a set and print its size to get an idea of the size of our dataset vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqucXTSCpoK8",
        "colab_type": "code",
        "outputId": "99d5c015-39e5-4f81-a2b8-f3b68d38743c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "# convert the loaded descriptions into a vocabulary of words\n",
        "def to_vocabulary(descriptions):\n",
        "\t# build a list of all description strings\n",
        "\tall_desc = set()\n",
        "\tfor key in descriptions.keys():\n",
        "\t\t[all_desc.update(d.split()) for d in descriptions[key]]\n",
        "\treturn all_desc\n",
        "\n",
        "# summarize vocabulary\n",
        "vocabulary = to_vocabulary(descriptions)\n",
        "\n",
        "print(vocabulary)\n",
        "\n",
        "print('Vocabulary Size: %d' % len(vocabulary))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'strewn', 'padel', 'biohazard', 'classical', 'infant', 'examined', 'sponsor', 'electric', 'photographs', 'mickey', 'tattooed', 'bikini', 'rifles', 'fountain', 'discouraged', 'teenagers', 'pee', 'enforcment', 'tiled', 'bathrooms', 'buried', 'squirting', 'riverside', 'defends', 'foliage', 'booth', 'gi', 'watercraft', 'sheperd', 'surfboarder', 'stepstool', 'raging', 'blays', 'plush', 'sillouhette', 'dirt', 'collared', 'tongues', 'swimsuit', 'art', 'rodderick', 'ornament', 'american', 'pale', 'elevation', 'went', 'dashboard', 'salon', 'busying', 'delivering', 'shirts', 'bluetooth', 'people', 'ambulance', 'pit', 'podium', 'wire', 'living', 'grasslands', 'oout', 'opposing', 'alcohol', 'bums', 'nine', 'beret', 'bleached', 'crosswalk', 'halfburied', 'waterskiing', 'punches', 'bullet', 'toast', 'rainbow', 'vertical', 'taps', 'quarter', 'intense', 'interior', 'wellmuscled', 'saharan', 'convenience', 'partying', 'breathing', 'retreiving', 'peanut', 'jewels', 'surrounded', 'wagon', 'rung', 'pier', 'artists', 'here', 'straggle', 'hikes', 'roots', 'lesson', 'pillowfight', 'joking', 'dropping', 'bandanna', 'scottish', 'breaker', 'scarred', 'statues', 'bowled', 'poor', 'digger', 'run', 'lonely', 'upon', 'contestants', 'catch', 'mouthguards', 'sandpit', 'fro', 'brass', 'cigerette', 'encourages', 'purple', 'watched', 'shakes', 'gymnastics', 'marinelifethemed', 'woolen', 'trying', 'greet', 'bass', 'snowboarder', 'skying', 'hulahoops', 'zipping', 'monocolor', 'new', 'individual', 'touchdown', 'jogger', 'samples', 'whiel', 'ibeam', 'acting', 'cups', 'mushrooms', 'sheltie', 'brickwall', 'diaper', 'rollerblading', 'families', 'reentry', 'bigg', 'notebook', 'brimmed', 'allow', 'tuxedo', 'sunbathers', 'gull', 'nubby', 'younger', 'tag', 'braiding', 'noisemaker', 'physiques', 'clowning', 'downtown', 'indigo', 'scuba', 'turnaround', 'unfurled', 'lassie', 'skiny', 'samll', 'zips', 'ask', 'cowboys', 'offf', 'sliding', 'riverrapids', 'hulahoop', 'gift', 'rodeo', 'greyishbrown', 'casino', 'yankee', 'choke', 'trench', 'trace', 'mitten', 'english', 'grond', 'apartment', 'fives', 'sunsetting', 'write', 'waving', 'tomatos', 'nails', 'doll', 'onrushing', 'dandilions', 'treading', 'bulldogs', 'camouflage', 'balcony', 'leaf', 'cotton', 'hotair', 'suitcase', 'housekeeping', 'horizontal', 'parka', 'eatery', 'muxzzled', 'tractor', 'cooks', 'carjack', 'discovery', 'halloween', 'clothesline', 'tin', 'team', 'evening', 'paced', 'guests', 'works', 'website', 'oclock', 'gas', 'crown', 'layup', 'obstacle', 'rose', 'slope', 'condoms', 'belays', 'boys', 'snowshovel', 'stride', 'kakhi', 'concentrates', 'slushies', 'vaulter', 'weas', 'casually', 'she', 'razzling', 'foul', 'large', 'halfcompleted', 'rabbits', 'fixes', 'cap', 'metropolitain', 'reported', 'sip', 'consumer', 'racers', 'fairy', 'heap', 'plan', 'scubba', 'plow', 'drill', 'boardedup', 'furred', 'piled', 'starshaped', 'happy', 'supporting', 'greenish', 'sail', 'sphere', 'fumble', 'dame', 'trike', 'helps', 'batter', 'purses', 'thermos', 'farris', 'slacks', 'interact', 'chew', 'dodge', 'sippy', 'space', 'tops', 'marathon', 'bun', 'served', 'trip', 'astonishment', 'completely', 'bringing', 'sweashirt', 'modeling', 'fall', 'youth', 'polo', 'bicyclers', 'demonstrate', 'sunlit', 'exercising', 'pastel', 'canvas', 'humans', 'wal', 'canada', 'nonworking', 'stonesign', 'ankledeep', 'wall', 'birds', 'protector', 'serveral', 'questioningly', 'travel', 'boards', 'longhorns', 'entangles', 'seaworld', 'tracks', 'skislope', 'brief', 'brilliant', 'appears', 'middleeastern', 'individuals', 'purse', 'making', 'sequined', 'slide', 'poised', 'swingset', 'cubby', 'faced', 'pursues', 'stumps', 'smacking', 'badges', 'portapotty', 'frying', 'thows', 'goalies', 'horsedrawn', 'total', 'giong', 'key', 'customers', 'skyward', 'dogs', 'tickled', 'mature', 'mad', 'selfportrait', 'kitten', 'packed', 'openair', 'reddish', 'enjoying', 'windboarder', 'unfinished', 'beg', 'rabbit', 'crest', 'thirds', 'curving', 'clever', 'stoppie', 'magician', 'exposition', 'racetrack', 'entitled', 'funny', 'outlined', 'equpitment', 'brown', 'layer', 'terriers', 'many', 'dusk', 'reacts', 'paddle', 'giggling', 'bloodied', 'runners', 'gondola', 'rummage', 'spilled', 'row', 'awning', 'sides', 'apportioned', 'foreign', 'colors', 'rapels', 'applauding', 'demolished', 'someone', 'rappeling', 'projected', 'underground', 'blowup', 'orangish', 'parasurfing', 'swan', 'docks', 'fastest', 'falls', 'pick', 'dueling', 'relection', 'flare', 'wodden', 'queens', 'mark', 'tuxes', 'beckons', 'land', 'prey', 'circuit', 'us', 'hut', 'check', 'marking', 'fully', 'bangles', 'merrygoround', 'remember', 'complete', 'countryside', 'palid', 'laundry', 'cottage', 'savanah', 'escalator', 'contraption', 'crosslegged', 'frustrated', 'wipe', 'wrestled', 'cocacola', 'widebrimmed', 'retail', 'arch', 'lack', 'hilltop', 'pan', 'is', 'bodysuit', 'elderly', 'wading', 'marshlike', 'santana', 'crouching', 'present', 'bag', 'waterskies', 'bulging', 'lunges', 'exercisewheel', 'floppy', 'sweatshirt', 'dragsters', 'highchair', 'heather', 'dumbbell', 'towels', 'cavorting', 'motorcrossing', 'urinating', 'loop', 'powder', 'plates', 'plain', 'doughnut', 'flows', 'readies', 'inch', 'kneehigh', 'emotionally', 'stairs', 'intersection', 'vehicles', 'defender', 'big', 'bandage', 'blond', 'directs', 'joint', 'lifevests', 'illustration', 'profile', 'walkway', 'illuminated', 'swimmers', 'poofy', 'cables', 'll', 'goalkeeper', 'magicians', 'buys', 'holding', 'gaze', 'whites', 'humorous', 'racks', 'hose', 'basket', 'collapses', 'serves', 'highfive', 'galloping', 'coordinator', 'fencedin', 'verbal', 'grinning', 'protected', 'trunk', 'avoid', 'brushland', 'blouse', 'dunes', 'accessories', 'gardening', 'tabs', 'microphone', 'wooly', 'reflecting', 'solitary', 'stunts', 'tugofwar', 'tuft', 'sandals', 'convention', 'sparrow', 'shadowdappled', 'velvet', 'assists', 'valleys', 'saucer', 'snowpants', 'misspelled', 'tobaggan', 'distorted', 'chestnut', 'collies', 'brightlycolored', 'cash', 'ot', 'convienance', 'trombone', 'ther', 'message', 'screen', 'balck', 'scent', 'everyday', 'clad', 'length', 'crouched', 'creature', 'pebbly', 'em', 'mottled', 'excitedly', 'underwater', 'pooping', 'tourquoise', 'raked', 'trail', 'foreigners', 'furniture', 'sequoia', 'frisbie', 'business', 'toys', 'schools', 'illustrated', 'cheerleader', 'excavating', 'fires', 'goose', 'harmonica', 'policemen', 'rangers', 'backpack', 'hops', 'windows', 'nech', 'smoking', 'jacketed', 'repel', 'carnival', 'exhaust', 'forearms', 'colt', 'lacrosse', 'bicyclists', 'spiral', 'whisper', 'entertain', 'directly', 'merry', 'saber', 'perpendicular', 'wagging', 'bush', 'production', 'bows', 'bluff', 'hills', 'grownup', 'lafayette', 'ladles', 'bandmates', 'desk', 'aiming', 'plugging', 'most', 'drapped', 'fixing', 'shortly', 'precariously', 'distored', 'fold', 'prop', 'monitor', 'enlarged', 'worked', 'blackshirt', 'railed', 'surfer', 'shirt', 'wilbert', 'batons', 'iceskating', 'amish', 'relaxing', 'mothers', 'handwritten', 'iceburg', 'creative', 'twisting', 'boarded', 'poem', 'outcropping', 'beginning', 'warily', 'stubbled', 'eats', 'surgical', 'gathering', 'mop', 'park', 'noodle', 'bunnies', 'baggy', 'cabin', 'penguins', 'plucking', 'logs', 'yells', 'alike', 'miniskirts', 'tassel', 'wooded', 'scooter', 'sledder', 'bluerobed', 'withdrawing', 'dots', 'skiing', 'clear', 'howling', 'goofing', 'pipes', 'somebody', 'bouquet', 'wheeled', 'glvoes', 'inflated', 'graffited', 'lifts', 'paddling', 'music', 'drug', 'macintosh', 'rifding', 'goats', 'tennis', 'inspecting', 'blackyellow', 'wields', 'graffitied', 'showing', 'element', 'break', 'sleep', 'can', 'aid', 'ethnicity', 'herds', 'sponge', 'passerby', 'gather', 'rhododendron', 'crucified', 'inflating', 'torso', 'wars', 'leader', 'jumphouse', 'somehow', 'raining', 'hindu', 'the', 'injured', 'hamburgers', 'dug', 'africans', 'called', 'slat', 'bagpipe', 'du', 'barn', 'boat', 'matt', 'ignoring', 'hoofs', 'berry', 'neckties', 'darker', 'fadora', 'ependent', 'justice', 'guards', 'gaurdian', 'crooked', 'buzy', 'filmed', 'word', 'canoe', 'watermelons', 'moustaches', 'treat', 'soar', 'recieving', 'puts', 'headscarves', 'expressionless', 'jet', 'tricycle', 'waterproofs', 'form', 'indian', 'ferris', 'jumped', 'skimply', 'whitebearded', 'billboard', 'puppy', 'displays', 'safari', 'gaurd', 'kneel', 'owl', 'chin', 'clifftop', 'quite', 'bracing', 'entertainers', 'bits', 'enclosure', 'midleap', 'motocross', 'cast', 'wards', 'patchy', 'sailboats', 'swings', 'trumped', 'rafters', 'pointed', 'rugby', 'circus', 'group', 'flopping', 'chalked', 'armchair', 'link', 'rearview', 'allterrain', 'smelling', 'unpaved', 'pedestrian', 'competiting', 'soundproof', 'swirl', 'metal', 'seeds', 'then', 'feet', 'un', 'neither', 'landscape', 'towers', 'coal', 'red', 'raincoats', 'swinging', 'nap', 'afican', 'fitls', 'formallydressed', 'smilling', 'chubby', 'christmastime', 'focused', 'hackey', 'speedboat', 'bowed', 'flashlight', 'fancily', 'donates', 'dramatic', 'cry', 'hte', 'bicyclecross', 'crouch', 'flats', 'companion', 'player', 'snowboards', 'comes', 'keepaway', 'tireswing', 'teacher', 'breezeway', 'bulls', 'scraping', 'female', 'onlooker', 'acrobat', 'camper', 'hairy', 'stacks', 'locking', 'riding', 'breaded', 'kilt', 'foothills', 'pups', 'ouside', 'algae', 'lifeguards', 'stockcar', 'gesticulates', 'bee', 'sending', 'composure', 'rushing', 'fatigues', 'skipping', 'ponytailed', 'also', 'devotion', 'proamerica', 'hedge', 'handlebars', 'gliding', 'halmets', 'closer', 'blur', 'chests', 'parkinglot', 'branches', 'submissive', 'performed', 'silky', 'straight', 'rv', 'cathing', 'lagoon', 'handout', 'photographer', 'celebrates', 'arranging', 'onslaught', 'nightclub', 'dozen', 'payer', 'return', 'pacifier', 'bunchh', 'medals', 'physical', 'graffti', 'snack', 'nodding', 'tents', 'passifier', 'entrance', 'retreiver', 'nearly', 'billiards', 'zooming', 'whitefooted', 'smoked', 'bottle', 'search', 'brindlecoated', 'slimy', 'sheets', 'welcomes', 'nuzzling', 'occupied', 'headphones', 'biscut', 'ages', 'rattan', 'wave', 'surface', 'embracing', 'caps', 'cheeked', 'keeling', 'sized', 'limbs', 'bat', 'hear', 'backpacker', 'brides', 'blowing', 'enjoy', 'carried', 'airfilled', 'shed', 'restaurants', 'mug', 'mats', 'rested', 'gloved', 'stop', 'dial', 'scull', 'collapsable', 'forward', 'toothbrush', 'cine', 'splashed', 'flirts', 'jumpsuits', 'shoe', 'grenade', 'bandages', 'fancy', 'playgroud', 'cartwheeling', 'flying', 'painting', 'bottom', 'snare', 'focusing', 'evil', 'catc', 'contents', 'bomber', 'descent', 'clapped', 'handbag', 'clutching', 'flamboyant', 'uncrowded', 'longlegged', 'swimsuites', 'dishtowel', 'second', 'sitts', 'wrap', 'streaked', 'shoreline', 'bounds', 'eyeshadow', 'steal', 'slightly', 'fairway', 'collects', 'song', 'pretends', 'variety', 'sunset', 'unseen', 'coloful', 'seated', 'nursery', 'adolescent', 'casket', 'spacious', 'play', 'sombrero', 'waders', 'attampts', 'pub', 'growls', 'sweatshir', 'coat', 'stand', 'tear', 'sloppy', 'master', 'threw', 'peircings', 'dwelling', 'yet', 'narby', 'snowballs', 'seat', 'serving', 'florescent', 'capris', 'returns', 'bumpy', 'beagle', 'or', 'brownandblack', 'bear', 'shuttered', 'dove', 'rags', 'domes', 'classic', 'riverboat', 'robe', 'photographed', 'payfully', 'fox', 'bounced', 'blossoming', 'policeperson', 'spash', 'bout', 'sidwalk', 'mma', 'kit', 'lakeside', 'hunter', 'agains', 'spotted', 'gnaws', 'streets', 'grabbing', 'teenager', 'uses', 'firedancer', 'waterbed', 'upwards', 'roofed', 'gurnee', 'lime', 'midday', 'orbs', 'pause', 'something', 'mid', 'pair', 'yellow', 'midfield', 'hollywood', 'looptheloop', 'flashes', 'playstation', 'teamates', 'outfit', 'resembles', 'lolly', 'keeping', 'state', 'glassses', 'arches', 'international', 'pods', 'brothers', 'metro', 'landmark', 'facial', 'elbows', 'tiara', 'shute', 'scarf', 'quaint', 'doing', 'heritage', 'petterned', 'wrestilng', 'except', 'leash', 'shaky', 'snows', 'peaceful', 'probably', 'gleaming', 'cane', 'proximity', 'piloting', 'collie', 'tshirts', 'cropped', 'currents', 'skate', 'lookalike', 'longsleeve', 'shocks', 'treefilled', 'handicap', 'pretty', 'roping', 'trim', 'grouchy', 'praying', 'jailbird', 'bagpipes', 'boating', 'toboggan', 'exception', 'fleeing', 'within', 'costumed', 'noodles', 'poodle', 'mat', 'tall', 'rosy', 'power', 'traverse', 'fiesty', 'iced', 'adobe', 'blondehaired', 'rottwieler', 'vista', 'antlers', 'spashes', 'intricate', 'fooling', 'motorists', 'midget', 'snarls', 'skin', 'jubilant', 'nest', 'mountin', 'yong', 'spain', 'aquacolored', 'histerically', 'timeout', 'jumpinjg', 'hamming', 'engraved', 'ducky', 'amazing', 'rates', 'tucking', 'donkey', 'enthusiasts', 'noise', 'peeking', 'burka', 'tails', 'pyramidshaped', 'att', 'exits', 'again', 'bison', 'created', 'bartype', 'pouncing', 'mounds', 'human', 'oklahoma', 'conch', 'kiosk', 'irish', 'ferrett', 'uggs', 'these', 'roman', 'fortess', 'paddles', 'hoops', 'clasp', 'much', 'halves', 'stroll', 'woooden', 'heavy', 'wipeout', 'vests', 'mountain', 'time', 'mixing', 'kneels', 'kawasaki', 'graygreen', 'items', 'find', 'ridden', 'easy', 'escorted', 'thinks', 'gushing', 'inspect', 'currently', 'walks', 'guided', 'butts', 'ankle', 'waterproof', 'amounts', 'babies', 'ls', 'benches', 'sub', 'pearl', 'trophy', 'hosed', 'colorful', 'mushing', 'give', 'prow', 'wings', 'stands', 'hangong', 'extinguish', 'footprints', 'faces', 'chalkboard', 'bowing', 'contestant', 'banging', 'shotongoal', 'sunflowers', 'isolated', 'cat', 'summersault', 'darkhaired', 'runway', 'classmates', 'surfboard', 'flatbed', 'boarder', 'tour', 'arms', 'climber', 'bricks', 'coasting', 'proof', 'arid', 'torwards', 'sleek', 'videos', 'jackets', 'ear', 'flip', 'neck', 'gemmed', 'triangle', 'groomsmen', 'jungle', 'rows', 'free', 'guitars', 'system', 'jumpsuites', 'rifle', 'capri', 'airport', 'barbed', 'shelton', 'party', 'goat', 'rays', 'pillared', 'showered', 'strollers', 'blank', 'venice', 'holiday', 'aprons', 'sell', 'walker', 'actions', 'bobsled', 'duck', 'mime', 'grazing', 'simultaneously', 'daft', 'shivering', 'referee', 'streetlamp', 'spins', 'slingshot', 'perfume', 'grinding', 'neighborhood', 'courthouse', 'heroes', 'lane', 'clipped', 'races', 'composed', 'flexing', 'headless', 'yarn', 'roads', 'crack', 'para', 'small', 'judges', 'diferent', 'practices', 'organic', 'redcarpeted', 'curiously', 'exterior', 'hang', 'zara', 'wrings', 'adoring', 'angel', 'advances', 'waterhole', 'poking', 'fetch', 'sure', 'grayish', 'jumps', 'derssed', 'scowling', 'kiyaking', 'perches', 'rite', 'best', 'rodents', 'horizontallystriped', 'others', 'maneuvering', 'revealed', 'biking', 'awkward', 'hiking', 'aquestrian', 'weeds', 'groom', 'piece', 'sets', 'security', 'mingle', 'locked', 'squeezes', 'mix', 'mess', 'rolledup', 'possibly', 'largley', 'dump', 'brighty', 'aboard', 'garments', 'very', 'avoids', 'winning', 'holes', 'rollerblades', 'speeding', 'las', 'backside', 'canals', 'changing', 'bats', 'patterened', 'range', 'learning', 'lift', 'first', 'burns', 'spectating', 'energetic', 'nibbling', 'wooden', 'knelt', 'coconut', 'lanterns', 'birdcage', 'cars', 'beachgoers', 'props', 'ancient', 'cinderblock', 'attempts', 'civillians', 'breaks', 'dripping', 'shells', 'midsized', 'straddling', 'outise', 'wheels', 'israei', 'starring', 'xmen', 'sweats', 'weather', 'book', 'barrette', 'pinstripe', 'cries', 'trails', 'dimpled', 'playy', 'goofy', 'acrobatics', 'sparking', 'toolbox', 'wmoan', 'boxers', 'national', 'highfives', 'romps', 'cowboy', 'shoot', 'balance', 'gesturing', 'fog', 'dimmly', 'tanning', 'onehanded', 'rectangular', 'bad', 'takeout', 'whose', 'juggling', 'watery', 'granite', 'womand', 'rocks', 'lightcolored', 'motorcyclist', 'pipe', 'mountainclimbing', 'begins', 'mud', 'wicker', 'thinking', 'jumper', 'taxi', 'elf', 'tiretracks', 'midafternoon', 'promting', 'shaking', 'jewish', 'herself', 'official', 'bottoms', 'shaded', 'magnificant', 'bit', 'tattered', 'st', 'interviews', 'launch', 'flooring', 'waterwear', 'blocking', 'scuffle', 'wounded', 'sculpture', 'mound', 'bluetinted', 'hairclips', 'borader', 'pierlike', 'descending', 'workout', 'rolls', 'dirtbikes', 'tandom', 'stream', 'husky', 'refuse', 'knoll', 'chipmunk', 'rope', 'attacking', 'hip', 'chart', 'tumbling', 'salvar', 'wrestle', 'jogged', 'adult', 'tripod', 'woman', 'triangular', 'swans', 'jib', 'wii', 'washed', 'chrome', 'tipping', 'backback', 'taking', 'biscuit', 'highland', 'burnished', 'going', 'pyrotechnics', 'flipping', 'scare', 'gay', 'distance', 'lapel', 'gontaga', 'blurring', 'climbed', 'bunch', 'sox', 'recoiling', 'raceway', 'carpeted', 'golf', 'sheepdog', 'tbe', 'burning', 'cave', 'equpiment', 'seafood', 'performers', 'wrist', 'cards', 'guides', 'closeup', 'into', 'binoculars', 'deciding', 'paddock', 'foyer', 'quintet', 'thousand', 'footbride', 'chops', 'casting', 'stripy', 'pedestal', 'lining', 'walled', 'huskylike', 'climing', 'glares', 'print', 'masses', 'onsie', 'shiner', 'united', 'thought', 'tracksuit', 'cheerfully', 'pig', 'redish', 'summit', 'hoes', 'inside', 'takes', 'daredevil', 'midpitch', 'observe', 'folds', 'paws', 'vibrating', 'yelling', 'corners', 'backhand', 'passenager', 'overwhelmed', 'trolley', 'drives', 'kingsworth', 'arguing', 'prestends', 'clustered', 'zaftig', 'keyboard', 'caterpillar', 'pretend', 'yell', 'buster', 'animals', 'shares', 'steam', 'above', 'kind', 'renaissance', 'closing', 'googles', 'far', 'stay', 'ponchos', 'item', 'corrugated', 'chips', 'intot', 'streetlights', 'smooth', 'practice', 'this', 'lettering', 'heeled', 'redskins', 'words', 'pouring', 'pillowcase', 'shawl', 'squating', 'counters', 'remove', 'deer', 'togerther', 'sloping', 'deeper', 'kiddy', 'handicapped', 'step', 'hydrant', 'furocious', 'cluster', 'conference', 'rafting', 'draw', 'shoes', 'poorlylit', 'grounded', 'certificates', 'staff', 'done', 'navigate', 'evade', 'complimentary', 'chatting', 'awkwardly', 'shorthaired', 'torii', 'structure', 'eastern', 'overlook', 'aliens', 'embroidered', 'tank', 'shielding', 'darkskinned', 'bellysmacker', 'rough', 'musician', 'amongst', 'festival', 'strolls', 'buses', 'skyline', 'waterfront', 'zchtv', 'touched', 'haloween', 'fairies', 'stone', 'fireball', 'stretched', 'checkout', 'fayre', 'upclose', 'strand', 'with', 'lizards', 'conditions', 'onward', 'undershirt', 'bicycling', 'wicket', 'awaiting', 'pilings', 'raised', 'sequins', 'pinstriped', 'suite', 'officers', 'strung', 'presentations', 'feamle', 'lasso', 'gun', 'jomps', 'objective', 'arts', 'monk', 'crows', 'training', 'fantastic', 'their', 'already', 'jogs', 'pitching', 'chainmail', 'foggyday', 'spoon', 'fairly', 'daughters', 'situated', 'transportation', 'bath', 'resembling', 'knuckle', 'broken', 'pointer', 'curtsey', 'flyaway', 'fishing', 'draped', 'reads', 'checker', 'hopping', 'levels', 'murky', 'rink', 'wellkept', 'cavern', 'streamer', 'cereal', 'daring', 'british', 'naturally', 'positions', 'skeletonprinted', 'bum', 'youngsters', 'searching', 'backpackers', 'manager', 'mowed', 'adjusts', 'ones', 'cow', 'path', 'instruments', 'warmly', 'midjump', 'darkheaded', 'canned', 'riwal', 'teaching', 'member', 'philadelphia', 'perspective', 'chats', 'portion', 'underpants', 'bowl', 'massive', 'exercised', 'hurdle', 'princess', 'yellowish', 'headlamp', 'spaced', 'expressing', 'popper', 'sledlike', 'soft', 'movers', 'long', 'naked', 'rash', 'placed', 'ink', 'sang', 'its', 'refreshment', 'apartments', 'celebrities', 'dimly', 'snowploe', 'bouncing', 'folks', 'flighht', 'stiars', 'cart', 'join', 'after', 'telephone', 'suburbs', 'gap', 'reacting', 'eagerly', 'spelunker', 'leaving', 'yawning', 'dives', 'chewing', 'rain', 'plant', 'spaniel', 'cheeseburger', 'hawaiin', 'follow', 'indy', 'shaft', 'hairnet', 'become', 'marketplace', 'riders', 'caring', 'chases', 'piglet', 'oxford', 'jog', 'off', 'atheletes', 'spaniels', 'longbearded', 'seating', 'liberty', 'scaling', 'stuntbicyclist', 'homeless', 'hat', 'advertising', 'hair', 'during', 'electricity', 'mules', 'portopotties', 'gives', 'staffordshire', 'converge', 'pace', 'nt', 'shopping', 'buss', 'up', 'expanse', 'portland', 'approaches', 'pleasant', 'greenhouse', 'aquos', 'slippers', 'patrons', 'karate', 'pad', 'sundress', 'schoolgirl', 'splashing', 'lighter', 'drag', 'rival', 'machine', 'cocked', 'interviewing', 'windsurfer', 'preparation', 'medal', 'underneat', 'haystacks', 'airborne', 'falcon', 'bottled', 'trio', 'supplies', 'glow', 'disguise', 'competeition', 'coastline', 'upraised', 'chemical', 'ox', 'trampled', 'bunk', 'records', 'bagpipers', 'mudwrestle', 'speedos', 'dangles', 'ninjalike', 'juggler', 'sands', 'astride', 'formal', 'crib', 'skidded', 'extinguishes', 'fresh', 'kimonos', 'mills', 'silver', 'headlong', 'certificate', 'wearhing', 'sheperds', 'ratty', 'llama', 'ca', 'picnic', 'chairs', 'turban', 'director', 'chest', 'shews', 'picutre', 'ferry', 'furiously', 'ash', 'hundreds', 'factory', 'malnourished', 'rails', 'dacshund', 'angry', 'staring', 'rugged', 'apart', 'marlins', 'waterspouts', 'tug', 'swipes', 'askance', 'sandbox', 'sweaters', 'sails', 'swear', 'vaste', 'towarn', 'rushes', 'multicultural', 'buttoned', 'assisting', 'site', 'active', 'fanning', 'drum', 'cami', 'drift', 'bare', 'lowcut', 'squeeze', 'docking', 'potrait', 'squirt', 'tire', 'young', 'violin', 'bodyboard', 'displaying', 'performing', 'flume', 'seeingeye', 'europe', 'sunhat', 'area', 'rods', 'culprit', 'quiet', 'tricks', 'stockings', 'tossing', 'emerge', 'engage', 'picket', 'reddressed', 'suspiciously', 'schoolyard', 'bathroom', 'passin', 'circle', 'flames', 'trainer', 'treck', 'directory', 'preteen', 'streetway', 'bearer', 'atrium', 'tightrope', 'dc', 'kayaker', 'duke', 'mill', 'surfboards', 'mast', 'skull', 'harnesses', 'entangled', 'bouncy', 'found', 'browneyed', 'returning', 'pats', 'whilst', 'knocking', 'twisty', 'goodbye', 'faith', 'smal', 'thoroughly', 'gymnast', 'floaties', 'bundled', 'germanshepherd', 'telescope', 'unamused', 'contained', 'persons', 'obscure', 'earth', 'points', 'were', 'pastures', 'beach', 'outcrop', 'shivers', 'barbwire', 'gonzaga', 'masonry', 'blackrimmed', 'suspension', 'tending', 'question', 'positioned', 'operates', 'shelter', 'redbrown', 'final', 'wind', 'partner', 'kissed', 'woodlands', 'campflauge', 'spreading', 'stuntman', 'missed', 'mcdonald', 'mushroom', 'leafless', 'blossoms', 'hooked', 'thinner', 'roofs', 'riverwater', 'places', 'ascending', 'menu', 'crouches', 'videotaped', 'oppose', 'devil', 'kayer', 'browses', 'gettin', 'smu', 'sat', 'diver', 'breeds', 'zebra', 'tuner', 'mountainside', 'intently', 'transit', 'commuters', 'church', 'prance', 'varied', 'firing', 'hairstyle', 'fourwheeler', 'prays', 'propel', 'shoulderhigh', 'corndogs', 'hay', 'submerged', 'topdown', 'nascar', 'plywood', 'hate', 'snowman', 'comic', 'oregon', 'lited', 'intensely', 'skatepark', 'fountains', 'different', 'parasailer', 'pavement', 'darkcolored', 'tychy', 'topless', 'tried', 'pillar', 'fun', 'rellow', 'longspandex', 'energy', 'blow', 'inscribed', 'bandanas', 'stains', 'pond', 'star', 'christ', 'enjoyable', 'street', 'ends', 'carts', 'grip', 'cuddling', 'coiled', 'dreeds', 'beautiful', 'prepairing', 'jockey', 'bandaged', 'int', 'retrieving', 'darkerskinned', 'exploring', 'pastels', 'foliaged', 'curved', 'participate', 'collision', 'railgrind', 'igloo', 'nosedeep', 'menus', 'sad', 'phone', 'quietly', 'use', 'baskets', 'dave', 'hero', 'sportwoman', 'forefront', 'jugs', 'examining', 'treads', 'bookshelves', 'backpacks', 'wristbands', 'maracas', 'berries', 'casual', 'supporter', 'dribbled', 'boe', 'memorabilia', 'girt', 'batshaped', 'peddles', 'bucked', 'hundred', 'tented', 'laps', 'waking', 'whales', 'swordfight', 'shave', 'portojohn', 'bikes', 'panasonic', 'wake', 'whack', 'pinball', 'oppsite', 'retrieves', 'create', 'cafeteria', 'barrels', 'fastens', 'non', 'penzance', 'offroad', 'statue', 'facefirst', 'frilly', 'bullfight', 'calculate', 'drove', 'posh', 'treeless', 'whie', 'spiky', 'faucet', 'bubble', 'heavyset', 'kill', 'wires', 'start', 'carying', 'fowl', 'position', 'pudding', 'weirmeiner', 'ridding', 'airtime', 'backbends', 'transparent', 'swallow', 'softdrinks', 'recently', 'terrain', 'chase', 'perfors', 'blown', 'waterpark', 'advertizing', 'pompoms', 'andy', 'conical', 'object', 'cloaks', 'hairdo', 'heading', 'skier', 'studies', 'carefully', 'modern', 'sound', 'jack', 'specialized', 'focus', 'connected', 'tentatively', 'montana', 'lookout', 'horse', 'pockets', 'ghandi', 'brightly', 'poster', 'longboarder', 'signal', 'chef', 'campsite', 'pumpkins', 'backyard', 'miscellaneous', 'launching', 'playmat', 'giants', 'carring', 'add', 'car', 'swirling', 'leading', 'hearts', 'ump', 'canon', 'tone', 'stroller', 'flowerbed', 'jewelry', 'aids', 'footballs', 'splits', 'roller', 'watches', 'genocide', 'sprawling', 'windsurfs', 'thumbsup', 'dropped', 'evergreen', 'clips', 'fringe', 'looking', 'manicured', 'line', 'twopiece', 'humansize', 'handing', 'flash', 'intended', 'kart', 'cloudy', 'lamppost', 'dreadlocks', 'hailing', 'greeting', 'icicle', 'pavilion', 'darts', 'jumpy', 'tv', 'verdant', 'seen', 'crests', 'aligator', 'weaves', 'shored', 'waterwings', 'apparently', 'railing', 'bars', 'mom', 'laptops', 'toddles', 'footwork', 'flotation', 'informal', 'streaming', 'firehose', 'fluffy', 'funky', 'grandmother', 'blackgreen', 'hissing', 'scantily', 'sentence', 'operators', 'grimmaces', 'yarnlike', 'snowstorm', 'picture', 'styrofoam', 'biplane', 'ballplayer', 'pony', 'descends', 'fries', 'multipiercings', 'wed', 'traveling', 'snow', 'steamboat', 'backgound', 'dappled', 'museum', 'dome', 'corn', 'ruins', 'charged', 'pawed', 'dense', 'diamond', 'midair', 'courtyard', 'slipping', 'pirates', 'headress', 'met', 'landform', 'professional', 'scampers', 'fielder', 'continue', 'mural', 'headscarfs', 'motley', 'ladies', 'snacks', 'photographers', 'our', 'dry', 'stretching', 'customer', 'stocking', 'overcast', 'facility', 'roughhousing', 'greenbay', 'dirtbikers', 'sleeps', 'inground', 'vocabulary', 'aqua', 'claus', 'consulting', 'paraphernalia', 'footage', 'adornment', 'whipping', 'sunrise', 'glowing', 'smirks', 'college', 'steve', 'scarfs', 'violinist', 'licking', 'league', 'spokes', 'cause', 'strainer', 'filled', 'mustard', 'playroom', 'across', 'excited', 'competitive', 'turns', 'cruiser', 'surfing', 'twotone', 'mask', 'ballthrower', 'ready', 'army', 'thrower', 'vinyl', 'puck', 'lenses', 'damp', 'men', 'cement', 'frayed', 'pails', 'snowmobile', 'zippered', 'unknown', 'giving', 'petting', 'tbar', 'israel', 'pole', 'stoop', 'losing', 'congregation', 'teeshirt', 'soaker', 'chasseing', 'amuseument', 'standard', 'admires', 'shining', 'charging', 'stoic', 'together', 'have', 'toyota', 'anthem', 'hacking', 'origin', 'popsicles', 'overlooks', 'exchanges', 'elegant', 'tanned', 'cheeks', 'one', 'woods', 'changes', 'cloud', 'someones', 'calico', 'motion', 'base', 'assemble', 'comfort', 'deserted', 'excersizing', 'handinhand', 'oceanside', 'hurdles', 'bulldog', 'abseiling', 'snowsuit', 'mogul', 'queen', 'may', 'coping', 'desertlike', 'gothically', 'witnesses', 'sexy', 'facepainted', 'arrives', 'expressions', 'participant', 'boarding', 'touches', 'shetland', 'descend', 'michael', 'rapids', 'eastpak', 'hdr', 'sooners', 'grinds', 'plaza', 'dirty', 'allmale', 'lassos', 'cut', 'bushes', 'viewing', 'formation', 'brook', 'bakery', 'novelty', 'coupe', 'portapotties', 'pinscher', 'cbs', 'fencing', 'ditch', 'winking', 'muslim', 'spill', 'coldweather', 'caged', 'pullovers', 'greysuited', 'rising', 'motorcyle', 'clump', 'popscicles', 'darkly', 'school', 'leg', 'spinning', 'netted', 'bullrider', 'majestically', 'swooping', 'sliiding', 'flickr', 'windsurfers', 'railroad', 'beverage', 'wades', 'jean', 'cracked', 'solid', 'setter', 'mosaic', 'skewers', 'dolls', 'senior', 'multicolored', 'leave', 'warning', 'mic', 'dirtbike', 'sipping', 'crashes', 'pursuing', 'holder', 'defense', 'seek', 'than', 'spits', 'skids', 'traditional', 'paraglide', 'darkened', 'congregated', 'camels', 'boods', 'soldier', 'pomeranian', 'skisuit', 'murals', 'offstage', 'stool', 'burrowing', 'gokarts', 'spoted', 'bananas', 'weimaraners', 'cylindrical', 'tussling', 'peddal', 'crazily', 'brow', 'brave', 'statute', 'tricycles', 'ractrack', 'snowscapes', 'campfire', 'skii', 'hugs', 'accompanying', 'pitchers', 'coyotes', 'undone', 'pepco', 'placing', 'slice', 'rover', 'shoeless', 'person', 'slighty', 'hauling', 'polar', 'helped', 'professionally', 'opens', 'rounds', 'floaters', 'legos', 'seater', 'monkeybars', 'panel', 'cleans', 'witches', 'tide', 'chandelier', 'way', 'rotating', 'attempt', 'condominium', 'parklike', 'pnc', 'waitress', 'dust', 'tote', 'upright', 'tries', 'referees', 'pedals', 'whitewater', 'mail', 'redclothed', 'crocs', 'blindfolds', 'oar', 'flexable', 'bluegray', 'saver', 'beaks', 'bedroom', 'assault', 'wide', 'trashcan', 'drivers', 'topples', 'aframe', 'fronmt', 'foil', 'bluestriped', 'tend', 'ribbons', 'responding', 'barb', 'monument', 'walkers', 'welcome', 'perfect', 'natural', 'swine', 'squinting', 'flees', 'schoolgirls', 'lies', 'sock', 'nude', 'traffic', 'sillhouetted', 'enjoyment', 'clack', 'ilks', 'pizzeria', 'ears', 'panties', 'pushed', 'gliders', 'brian', 'shorts', 'striking', 'moped', 'fundraising', 'daylight', 'goatee', 'cam', 'floral', 'checked', 'gust', 'foot', 'bustling', 'highway', 'jagged', 'carriage', 'backtoback', 'celebrating', 'punt', 'peers', 'steps', 'organization', 'drilling', 'weilding', 'wakeboarding', 'fans', 'launches', 'snowbanks', 'skirt', 'lawn', 'vents', 'blood', 'throughwindow', 'nets', 'box', 'iron', 'footballers', 'safely', 'hind', 'violins', 'holing', 'restrain', 'streams', 'cavort', 'stance', 'impress', 'againest', 'extended', 'dressed', 'drips', 'mate', 'competitively', 'shoelaces', 'bikins', 'outfits', 'fiercely', 'rustric', 'buffet', 'aerobatics', 'creates', 'shriner', 'izod', 'dooorway', 'pitched', 'cheering', 'lifeboat', 'walkways', 'rubber', 'impersonator', 'hilly', 'amusement', 'italian', 'holy', 'notices', 'smeared', 'garmet', 'clowns', 'silhouette', 'tonge', 'cutting', 'pulling', 'curls', 'median', 'either', 'beatup', 'paintbrush', 'electronic', 'eyed', 'valley', 'downpour', 'goldfish', 'pamphlets', 'fireworks', 'toilets', 'flamboyantly', 'net', 'sifting', 'yuong', 'barely', 'driver', 'him', 'blondhair', 'sunlight', 'padded', 'bruised', 'froup', 'carolina', 'wiped', 'rag', 'wheelbarrow', 'palace', 'wolflike', 'pitch', 'daughter', 'greyblue', 'geyser', 'wet', 'mountaineers', 'taping', 'rowboat', 'snowbank', 'displayed', 'political', 'mardis', 'beams', 'even', 'scrolled', 'bigger', 'twig', 'incredible', 'scouts', 'strap', 'age', 'fluid', 'public', 'cylinder', 'pilots', 'fly', 'htting', 'lampost', 'language', 'shrine', 'interacts', 'elephants', 'panes', 'casterol', 'somersaults', 'virtual', 'permed', 'poodles', 'competiton', 'grand', 'haystack', 'utility', 'alert', 'sideline', 'beachfront', 'completing', 'room', 'trips', 'hot', 'paint', 'talent', 'martial', 'bikina', 'extremely', 'concentration', 'redwood', 'spiderman', 'purchase', 'collection', 'decorated', 'cigars', 'mountains', 'greyhounds', 'tawny', 'bin', 'overlooked', 'maneuvers', 'batman', 'cookie', 'packages', 'map', 'moment', 'will', 'backbend', 'complex', 'block', 'photographing', 'arm', 'tongue', 'drawings', 'seesaw', 'youths', 'operate', 'boogie', 'wait', 'olympic', 'brownhaired', 'funeral', 'busy', 'sumo', 'winding', 'wrangles', 'grownups', 'cramped', 'stunning', 'downward', 'sillhouttes', 'diners', 'vaulting', 'nose', 'furry', 'gambling', 'threewheeled', 'closeout', 'atm', 'viewpoint', 'possessions', 'guarded', 'and', 'gregoire', 'rescue', 'hood', 'parasails', 'powered', 'steaks', 'desks', 'snapping', 'redbull', 'driven', 'sitting', 'ninja', 'boston', 'lobby', 'earmuffs', 'ques', 'themselves', 'twisted', 'gondoliers', 'sprinting', 'antique', 'bathed', 'jumpropes', 'seventh', 'amphitheater', 'applying', 'towrope', 'stylish', 'cheered', 'chimes', 'youngster', 'sushi', 'gorge', 'mesh', 'transport', 'ribbon', 'poms', 'kept', 'pillow', 'coppery', 'maintained', 'relatively', 'bring', 'homemade', 'cheerleading', 'spell', 'them', 'getting', 'punting', 'flowery', 'pets', 'acroos', 'fourth', 'robot', 'runner', 'action', 'putting', 'fliers', 'sponsored', 'pacman', 'apparatus', 'pure', 'spout', 'class', 'chicken', 'mans', 'development', 'emits', 'homerun', 'cornfield', 'throws', 'pen', 'overalls', 'wristband', 'dads', 'huddles', 'approach', 'darked', 'feeds', 'desserts', 'used', 'wool', 'unexcited', 'film', 'athletics', 'reviewing', 'east', 'personal', 'blownup', 'vast', 'pawing', 'poorly', 'wellgroomed', 'cloth', 'embankment', 'guy', 'knife', 'dumping', 'boundary', 'soaked', 'steap', 'rod', 'spotters', 'colorblock', 'palmtree', 'attaches', 'calf', 'blitz', 'nighttime', 'scenery', 'foal', 'urban', 'nursing', 'union', 'queue', 'cartwheel', 'gazebo', 'excitement', 'peach', 'saris', 'crossed', 'frisbree', 'vans', 'convienience', 'stomach', 'wakeboard', 'waterski', 'challange', 'pedalling', 'york', 'saddle', 'overshirt', 'spays', 'motorboat', 'windboard', 'radio', 'yamaha', 'stickball', 'washes', 'upper', 'seagulls', 'flexibility', 'everywhere', 'earflaps', 'venue', 'draft', 'latte', 'european', 'begs', 'blasted', 'receiving', 'ticket', 'military', 'who', 'speedway', 'quad', 'blazing', 'twome', 'melting', 'cookies', 'sniffed', 'speaking', 'cannons', 'favorite', 'skit', 'owner', 'packaged', 'strawberries', 'tying', 'crossing', 'superhero', 'fending', 'sidecar', 'snowed', 'parasailors', 'breathes', 'pontoon', 'cornstalks', 'bubbles', 'khaki', 'reared', 'glowers', 'stare', 'hung', 'huskies', 'underpass', 'pierced', 'menacingly', 'fists', 'quarterback', 'motorbikes', 'excercise', 'dead', 'dock', 'summer', 'winters', 'cords', 'gallops', 'threeway', 'forwards', 'claps', 'cows', 'adhd', 'black', 'gymnastic', 'paneled', 'forested', 'shimp', 'floors', 'scramble', 'from', 'lion', 'level', 'noticable', 'upsidedown', 'crying', 'cake', 'admiring', 'swordsman', 'single', 'horseshoe', 'squares', 'ascend', 'swarming', 'jukebox', 'rackets', 'wands', 'shooting', 'weiner', 'feathery', 'packer', 'tge', 'aim', 'asleep', 're', 'emerging', 'hiding', 'arrangement', 'lifesavers', 'flowercovered', 'decorate', 'threshold', 'television', 'concrete', 'jeeps', 'tickets', 'heavily', 'skill', 'doghouse', 'reclining', 'lollipops', 'cheer', 'notsocrowded', 'clue', 'trundles', 'strokes', 'chidl', 'romp', 'win', 'greenery', 'mexico', 'pursed', 'arbor', 'groups', 'foam', 'course', 'parallel', 'wood', 'costume', 'laid', 'sunshine', 'fishermen', 'satchel', 'occassion', 'japanese', 'beaver', 'foggy', 'waiting', 'pottypotty', 'antiquated', 'hotrod', 'images', 'blanket', 'dandelions', 'takeing', 'embedded', 'hockey', 'newlywed', 'sky', 'camcorder', 'armful', 'separated', 'tip', 'diveboard', 'aquarium', 'tikes', 'document', 'pocket', 'outs', 'yound', 'stabs', 'rockclimber', 'polkadotted', 'steep', 'wetland', 'kayak', 'fighter', 'grin', 'husk', 'extravagent', 'await', 'turbulent', 'throw', 'regains', 'screaming', 'peeing', 'brindlecolored', 'creepy', 'sabre', 'blankets', 'seaside', 'seaguls', 'pulley', 'landing', 'fellow', 'shadow', 'elaborate', 'kicker', 'typical', 'coaching', 'event', 'tread', 'columns', 'dresser', 'brownspotted', 'tramples', 'clergy', 'ghostbuster', 'dries', 'swatting', 'ten', 'kid', 'moving', 'outfitted', 'escalators', 'beak', 'crevasse', 'playtoy', 'statefarmcom', 'kneeling', 'setting', 'spare', 'piercings', 'plank', 'offensive', 'bounce', 'halter', 'introduces', 'otherwise', 'flexible', 'speed', 'fences', 'anything', 'frowning', 'challenges', 'handkerchiefs', 'ampitheater', 'fabric', 'persian', 'fisher', 'upward', 'beating', 'reaching', 'smokestacks', 'stomachs', 'vintage', 'sportsfield', 'bikers', 'binocular', 'type', 'bathtub', 'riverrafting', 'arranged', 'clings', 'windshield', 'flares', 'ties', 'horseback', 'ripstik', 'backing', 'onlookers', 'rock', 'voice', 'videotaping', 'longsleeved', 'huskey', 'turquiose', 'stairway', 'dyed', 'shirtless', 'terrorizes', 'unoccupied', 'checking', 'decoyanimal', 'bank', 'res', 'speech', 'pullup', 'canes', 'fton', 'equestrian', 'continues', 'shouting', 'extravagantlyhaired', 'interacting', 'rundown', 'jeep', 'jousting', 'manually', 'onto', 'wedding', 'incense', 'farm', 'presents', 'ping', 'turf', 'unhappy', 'smiff', 'flies', 'diry', 'snowgear', 'drab', 'corgie', 'florida', 'streght', 'scrubby', 'revealing', 'wadingpool', 'paying', 'love', 'barnlike', 'overhear', 'associated', 'loofa', 'troll', 'blueish', 'stones', 'brother', 'stars', 'amused', 'litle', 'suv', 'youg', 'bones', 'india', 'reflection', 'waterskiis', 'swerves', 'wheelie', 'blockers', 'horsemen', 'meadow', 'washer', 'sewer', 'locomotives', 'tangled', 'flashing', 'trotted', 'ability', 'sweating', 'tells', 'cover', 'wintery', 'disks', 'explorer', 'king', 'midstride', 'dancefloor', 'needs', 'grate', 'winner', 'rear', 'workers', 'bags', 'confront', 'year', 'paleontologist', 'oriential', 'enthusiastic', 'stepping', 'expanding', 'backstroke', 'digging', 'dogshirt', 'lei', 'carrying', 'hapy', 'silverware', 'buena', 'converse', 'blonde', 'bonnet', 'cowgirls', 'burlap', 'patches', 'aross', 'flowers', 'parasurfs', 'massage', 'interrupts', 'climbes', 'leaped', 'thie', 'tethered', 'leotards', 'sells', 'located', 'bystanders', 'goth', 'stonefilled', 'hapily', 'buy', 'milkbone', 'skinned', 'rooftop', 'butt', 'bedspread', 'cellphones', 'pose', 'indoors', 'joggers', 'refrigerator', 'covering', 'hips', 'rotweiler', 'mommy', 'product', 'madly', 'goldenrod', 'sidewalk', 'acoustic', 'pilot', 'visits', 'reaches', 'anouther', 'carry', 'given', 'pans', 'plows', 'shadowed', 'hungry', 'hypocrites', 'obscures', 'courts', 'gnarly', 'choreographed', 'bicycler', 'admire', 'pinned', 'platform', 'waist', 'hammer', 'gestures', 'fire', 'plaid', 'oriental', 'stunt', 'fierce', 'caution', 'fastened', 'stores', 'snarly', 'fatigue', 'sportman', 'pushing', 'bungeejumping', 'spinart', 'record', 'carpenters', 'heels', 'stopaction', 'sprinklers', 'mutltiple', 'mocks', 'nike', 'enough', 'grilling', 'yawns', 'possessively', 'singer', 'laptop', 'italy', 'upside', 'north', 'skilift', 'tier', 'university', 'cleaned', 'slicker', 'bell', 'dim', 'turbans', 'observed', 'dumps', 'help', 'rural', 'bloom', 'rocking', 'fireplace', 'incoming', 'plane', 'underhang', 'deep', 'common', 'spectators', 'student', 'dupont', 'grotto', 'litter', 'son', 'hitter', 'musher', 'alotment', 'passengers', 'handlers', 'loose', 'insynch', 'rollerskate', 'climbs', 'bubbling', 'oxen', 'hoddie', 'meandering', 'cats', 'kicks', 'juice', 'company', 'crowds', 'jetty', 'photos', 'ledges', 'capped', 'bullhorn', 'leapfrog', 'skates', 'cycling', 'trailer', 'longnecked', 'overshadows', 'venture', 'hall', 'almost', 'lazily', 'drags', 'divers', 'woven', 'barbeque', 'sailboat', 'retreived', 'snowcovered', 'childrens', 'obscured', 'profession', 'oddly', 'cones', 'floored', 'graffiti', 'elbow', 'bohemian', 'snowdrift', 'perused', 'boot', 'america', 'if', 'concentrating', 'juming', 'entwined', 'finished', 'spotlight', 'posts', 'control', 'wrestler', 'conversations', 'miniature', 'figurine', 'bamboo', 'circled', 'alleyway', 'junk', 'tantrum', 'filling', 'sailboarder', 'colorfully', 'does', 'multiple', 'ball', 'gras', 'storm', 'grappling', 'global', 'steering', 'golfing', 'night', 'untangles', 'russel', 'graffitifilled', 'backstrokes', 'opened', 'collecting', 'corral', 'competitor', 'chello', 'browsing', 'mistletoe', 'treated', 'seem', 'numerous', 'baked', 'developed', 'swinsuit', 'guidewire', 'blurry', 'kerry', 'phones', 'frisbee', 'rubs', 'movie', 'photograph', 'apex', 'navel', 'badge', 'seal', 'necked', 'tattoos', 'cascading', 'mosscovered', 'resting', 'spreads', 'types', 'motorcross', 'cleats', 'below', 'attention', 'breath', 'dodgeball', 'tim', 'protecting', 'bitten', 'dogsled', 'teach', 'parlor', 'inflatbale', 'window', 'africanamerican', 'huddle', 'bared', 'wasteland', 'zombies', 'wrecks', 'ypoung', 'swimming', 'newborn', 'creating', 'claws', 'racing', 'backgroud', 'bookstore', 'winces', 'rim', 'defecating', 'winston', 'cob', 'dip', 'bead', 'swimsuits', 'coached', 'perplexed', 'dart', 'enclosed', 'old', 'pathway', 'almostpristine', 'skateboards', 'shite', 'swords', 'do', 'distribute', 'peeks', 'magenta', 'gnawing', 'goldencolored', 'banks', 'firemen', 'shape', 'vuitton', 'labradoodle', 'snowfall', 'beard', 'ripping', 'not', 'cubicle', 'terminal', 'bushy', 'synchronized', 'saucers', 'ringing', 'priest', 'cathedral', 'eat', 'siluettes', 'showgirl', 'trumpet', 'pitcher', 'kennel', 'forcing', 'library', 'caucasian', 'billowing', 'squeals', 'engaging', 'gith', 'liked', 'highflying', 'ski', 'awaits', 'churning', 'od', 'emerged', 'mittens', 'planks', 'sticking', 'jump', 'dozes', 'where', 'receive', 'socializing', 'artistic', 'kissing', 'washing', 'sari', 'cafe', 'skirts', 'tankini', 'marks', 'soldiers', 'flight', 'wets', 'printed', 'alien', 'surfaces', 'bends', 'abarrotes', 'picnickers', 'sinking', 'tissue', 'backward', 'motocycle', 'punctured', 'dealth', 'salt', 'string', 'females', 'vfw', 'rakes', 'mechanisms', 'taxis', 'wharf', 'wrapped', 'scans', 'blasts', 'motorbiker', 'waitresses', 'frown', 'seven', 'broadway', 'wolf', 'fence', 'runs', 'arabian', 'littered', 'sea', 'stretchy', 'glee', 'royal', 'yellowgold', 'identical', 'palestinian', 'ice', 'collaborating', 'granny', 'banners', 'strides', 'hikers', 'heron', 'seeking', 'squated', 'decoration', 'cougar', 'knight', 'take', 'arc', 'lawnmower', 'pong', 'tak', 'dusty', 'roses', 'min', 'fit', 'storefronts', 'got', 'blackboard', 'banjo', 'reeds', 'examine', 'treetops', 'collapsing', 'fireman', 'prevent', 'listening', 'bullseye', 'icicles', 'patrollers', 'embrace', 'chewed', 'pecks', 'snowy', 'ladie', 'live', 'sled', 'played', 'separate', 'lucky', 'quarterpipe', 'shortstop', 'bikinis', 'spar', 'fight', 'squats', 'grass', 'mcdonalds', 'pensive', 'storefront', 'fluorecent', 'wringing', 'little', 'wintry', 'playfully', 'blindfolded', 'goggled', 'suckles', 'shabby', 'firetruck', 'roll', 'atv', 'caravan', 'colourful', 'brownish', 'puma', 'hardhats', 'sparkling', 'gingerbread', 'advertisements', 'bartender', 'stared', 'cashier', 'playfighting', 'waing', 'mean', 'shark', 'thatch', 'lie', 'curlyhaired', 'grayhound', 'seems', 'pilar', 'snowfield', 'mercury', 'trek', 'investigating', 'hats', 'cruising', 'peolple', 'clap', 'obese', 'punch', 'features', 'explosion', 'dupar', 'social', 'flew', 'needle', 'handgun', 'solo', 'falling', 'helment', 'point', 'driftwood', 'angerly', 'hillside', 'vaults', 'apron', 'berets', 'glances', 'grss', 'tune', 'wizard', 'stiped', 'jackolantern', 'by', 'mastif', 'burbur', 'slurps', 'odd', 'totter', 'bungee', 'chris', 'banner', 'tophats', 'oak', 'uphill', 'surrounding', 'rolled', 'enthusiastically', 'cushions', 'halfpipe', 'playes', 'painters', 'sleigh', 'perfoms', 'cube', 'springtime', 'three', 'dinner', 'marches', 'hoodedcoat', 'drinks', 'allowing', 'kickboxing', 'bonnets', 'banana', 'lighted', 'paraglider', 'each', 'temporary', 'teddy', 'hanging', 'hovers', 'iguanas', 'fights', 'sparring', 'icy', 'caramel', 'hooded', 'cartoon', 'kickflip', 'antitax', 'lanyard', 'exchange', 'blooming', 'thumbs', 'planeta', 'white', 'tournament', 'fed', 'vert', 'basketballs', 'solitude', 'pounces', 'surf', 'severe', 'sucker', 'paraskier', 'bouncey', 'outdoor', 'grasp', 'kickboxer', 'starlet', 'fins', 'volkswagen', 'drooping', 'climb', 'piling', 'bathe', 'jockeys', 'struggling', 'bow', 'hardhat', 'experimenter', 'punts', 'masters', 'manequins', 'dot', 'behinds', 'measures', 'texts', 'defended', 'planked', 'skeleton', 'headcover', 'dollar', 'percussionists', 'tile', 'similarly', 'pile', 'back', 'rollskating', 'brunette', 'obligatoire', 'antics', 'marble', 'butterfly', 'talks', 'palm', 'recieve', 'beaded', 'shoppers', 'indoor', 'skydiving', 'chain', 'gin', 'drak', 'meat', 'implements', 'web', 'dressing', 'sightseers', 'mock', 'dhe', 'screeches', 'marshy', 'tower', 'glancing', 'paperback', 'tied', 'romping', 'maids', 'guitarist', 'lush', 'dizzy', 'sight', 'wrinkley', 'rigging', 'propeller', 'firefighter', 'flipflop', 'sparks', 'bowlike', 'catches', 'wildflowers', 'jacket', 'tubing', 'me', 'squat', 'speckled', 'african', 'portfolio', 'candles', 'raincoat', 'walkng', 'critter', 'gutarist', 'unconventional', 'linet', 'touch', 'shotput', 'bale', 'blackhaired', 'soccer', 'holds', 'handkerchief', 'sister', 'coverall', 'clown', 'wetsuite', 'ban', 'jerseys', 'bordering', 'devices', 'pull', 'stony', 'tugging', 'outrun', 'graveyard', 'saroog', 'stall', 'braids', 'recording', 'whizzes', 'county', 'pigs', 'tee', 'phillie', 'poll', 'motorcyclists', 'rowing', 'sprayed', 'playhouse', 'greenpeace', 'goals', 'engulfed', 'spurting', 'pinkbottomed', 'buggys', 'antoher', 'dingo', 'whild', 'groupe', 'lounge', 'main', 'doors', 'dalmation', 'whips', 'garment', 'riverbank', 'ended', 'dancing', 'sniff', 'reeling', 'steers', 'regalia', 'trotting', 'kitchen', 'parents', 'target', 'nurses', 'soap', 'attentively', 'goldenbrown', 'seabird', 'carpeting', 'zipline', 'vest', 'apparel', 'blog', 'amidst', 'tables', 'mouthpiece', 'catcher', 'field', 'saltandpepperhaired', 'waeribng', 'midway', 'brightcolored', 'headwraps', 'waterskis', 'card', 'persues', 'sarongs', 'targeting', 'graduation', 'snub', 'plastic', 'desperate', 'midswing', 'support', 'slates', 'racedog', 'raling', 'carving', 'approached', 'barrior', 'racket', 'blackandwhite', 'goldcolored', 'frosty', 'bib', 'award', 'yougn', 'kilts', 'sheltered', 'artist', 'cosplayers', 'smells', 'beds', 'treats', 'novel', 'hitting', 'batting', 'upfront', 'spelling', 'amazement', 'act', 'lecture', 'filming', 'purchased', 'dangling', 'treelined', 'advertisment', 'spandex', 'marine', 'overhanging', 'country', 'disrupt', 'vegetable', 'jersay', 'sorts', 'showerhead', 'tussle', 'tshirt', 'palying', 'kids', 'woamn', 'puckering', 'grocery', 'flung', 'cooking', 'puzzled', 'bracelets', 'residential', 'food', 'filiming', 'dye', 'font', 'minitrampoline', 'content', 'squatting', 'greenglow', 'sewn', 'scratch', 'beads', 'struggle', 'tripped', 'spread', 'perform', 'rodent', 'react', 'swinger', 'interlocking', 'himself', 'trekkies', 'ollie', 'silohuetted', 'messenger', 'signpost', 'streetpole', 'confronted', 'hospital', 'unzipping', 'beckham', 'attend', 'siting', 'shag', 'computer', 'fiveteen', 'accents', 'bicyclist', 'jetskis', 'supporters', 'gravel', 'showering', 'waterside', 'election', 'hunched', 'tulips', 'wierd', 'offers', 'panting', 'zone', 'spindle', 'preserves', 'treecovered', 'diner', 'griding', 'counry', 'fiels', 'rottweiler', 'twp', 'overflowing', 'buttonup', 'pice', 'preservers', 'overpass', 'judo', 'rockstar', 'lillypads', 'mittened', 'information', 'mets', 'rasing', 'hoof', 'times', 'lingers', 'scowls', 'cadet', 'recked', 'male', 'roughly', 'schoolaged', 'sales', 'brige', 'pumped', 'toe', 'ponytail', 'cabana', 'gathered', 'la', 'pins', 'occasion', 'uneven', 'attacks', 'crowded', 'resort', 'barrel', 'tackle', 'hooping', 'ashtray', 'tossed', 'bodysurfs', 'leatherclad', 'clears', 'wrestling', 'further', 'blues', 'dune', 'tow', 'pumpkin', 'aloft', 'policewoman', 'clemson', 'beetle', 'drawn', 'longeared', 'detector', 'faint', 'stuntleap', 'tightropes', 'signature', 'nestled', 'huge', 'fetches', 'remax', 'stoops', 'minding', 'collegiate', 'hop', 'domed', 'williams', 'cricket', 'miami', 'stair', 'busk', 'hi', 'observes', 'oiled', 'spoke', 'magazines', 'through', 'escorts', 'knocks', 'headfirst', 'archways', 'recorder', 'rowed', 'squirrel', 'films', 'fleece', 'be', 'visitors', 'spirit', 'suspenders', 'sandal', 'engine', 'barista', 'tags', 'wrestlers', 'boxing', 'moter', 'louis', 'suits', 'tired', 'dice', 'eyepatch', 'rack', 'attached', 'market', 'rockclimbing', 'representing', 'pouch', 'chasing', 'parked', 'fronr', 'suprised', 'pitbulls', 'contemplates', 'owners', 'snowpacked', 'horseshoes', 'rungs', 'emty', 'geishas', 'cycles', 'musicians', 'shawls', 'hangglider', 'beauty', 'bullfighting', 'lacross', 'mohawk', 'horizon', 'ropeswinging', 'lobster', 'quarry', 'landfill', 'refugees', 'match', 'vine', 'shake', 'mr', 'village', 'eleven', 'advantage', 'ghostbusters', 'gazing', 'agency', 'overall', 'girl', 'crime', 'hortons', 'swing', 'via', 'leopard', 'to', 'early', 'drooling', 'shook', 'greets', 'crew', 'stripes', 'encircling', 'uniforms', 'motorized', 'costumes', 'bookshelf', 'donations', 'gorgeous', 'slam', 'pride', 'mitsubishi', 'dragon', 'contestent', 'cream', 'fighters', 'elder', 'forms', 'drainpipe', 'ponytails', 'shade', 'bridal', 'footpath', 'tourist', 'verizon', 'calm', 'swingtoy', 'protester', 'leggings', 'castle', 'nears', 'teeing', 'puffs', 'industrial', 'shortsleeved', 'which', 'extravagant', 'panda', 'argues', 'whit', 'fan', 'autumn', 'been', 'low', 'hudge', 'milkweed', 'peaks', 'zigzag', 'degrees', 'slurpees', 'cautious', 'viewer', 'guiutarist', 'pinwheel', 'wounds', 'gelled', 'downhill', 'draping', 'crystal', 'toothpaste', 'oars', 'drive', 'frame', 'prints', 'hippie', 'lakes', 'swaetshirt', 'gauges', 'toddlers', 'pitted', 'hustle', 'balanced', 'sprays', 'scattered', 'trots', 'garner', 'creamy', 'jumpsuit', 'planter', 'tame', 'bar', 'peacoat', 'children', 'brick', 'pain', 'photograhi', 'things', 'newlyweds', 'safe', 'tail', 'gains', 'boa', 'spiking', 'extreme', 'leashed', 'heard', 'obscene', 'pianist', 'adventurer', 'highrise', 'ollies', 'salmon', 'reddishbrown', 'grasses', 'lavendar', 'sends', 'tanktop', 'fetching', 'applebee', 'cyclers', 'harvest', 'bites', 'dressedup', 'bench', 'pants', 'monitors', 'performs', 'when', 'newspaper', 'retrieve', 'santa', 'hurdlejumper', 'outwards', 'investigate', 'tackles', 'mist', 'misty', 'cone', 'glassess', 'beneath', 'artsstyle', 'derby', 'nice', 'bicylist', 'denim', 'sleeved', 'guitar', 'streambed', 'planting', 'wearubg', 'clibing', 'finds', 'half', 'locks', 'shines', 'dachshunds', 'canoers', 'groucho', 'neckdeep', 'around', 'cobblestone', 'bounces', 'waterspout', 'draws', 'angled', 'flood', 'beam', 'juggles', 'cigarettes', 'shirted', 'light', 'rocker', 'ride', 'grouped', 'hoodie', 'atomic', 'among', 'youn', 'government', 'burgundy', 'snowflake', 'horn', 'bmxer', 'bookcase', 'change', 'eroded', 'modifications', 'nothing', 'labrador', 'least', 'practising', 'whitecolored', 'discovers', 'poof', 'frozen', 'woolly', 'climbing', 'aerobics', 'gowns', 'surround', 'patio', 'tugboat', 'ashen', 'dear', 'lightsaber', 'butting', 'towed', 'trucks', 'on', 'landed', 'wipes', 'collage', 'attending', 'flurry', 'pipeline', 'care', 'cordoned', 'trunks', 'only', 'teens', 'substance', 'crazy', 'paralell', 'bases', 'keeper', 'french', 'lawnchair', 'reflections', 'leashes', 'saw', 'tattoed', 'mucky', 'crochet', 'squeezed', 'tell', 'straw', 'halway', 'guarding', 'cheese', 'gocart', 'afternoon', 'stoney', 'persue', 'call', 'propping', 'bangs', 'pattern', 'portrate', 'barber', 'running', 'abdomen', 'blondhaired', 'tubes', 'pring', 'croc', 'prances', 'elementary', 'setup', 'brownstone', 'lady', 'snarling', 'watch', 'instructs', 'blindfold', 'waterboard', 'charges', 'sprinkles', 'saxaphones', 'lagging', 'two', 'alter', 'zipup', 'scalling', 'tattoo', 'ceremony', 'cutout', 'anticipating', 'binky', 'romantic', 'neatly', 'partially', 'miles', 'greyish', 'leaguer', 'jets', 'yellows', 'maneuver', 'piercing', 'trained', 'styled', 'contorts', 'protesters', 'safety', 'tilting', 'hopscotch', 'attractive', 'wild', 'packers', 'looker', 'tumbleweed', 'tools', 'marina', 'grown', 'jaket', 'angels', 'open', 'supports', 'partake', 'horseriders', 'egytianlike', 'listens', 'sees', 'skiiers', 'grafitti', 'patterns', 'deck', 'taped', 'chili', 'steady', 'diplomas', 'classroom', 'turbaned', 'close', 'bloe', 'golfers', 'stained', 'sprints', 'cuts', 'produce', 'environment', 'fort', 'feild', 'dashes', 'backed', 'ringed', 'offered', 'quick', 'down', 'written', 'marsh', 'cardboard', 'rallies', 'competes', 'astroturf', 'waterline', 'wheel', 'retangular', 'raft', 'sundown', 'squirted', 'muscles', 'couples', 'leafs', 'markings', 'carrier', 'lounges', 'rockstrewn', 'scared', 'lump', 'views', 'roddick', 'swiftly', 'collides', 'shaggy', 'kong', 'swim', 'obstacles', 'pyranha', 'encripted', 'oversized', 'emblems', 'umbrellas', 'touts', 'squeak', 'astro', 'ion', 'garter', 'snowboarders', 'executes', 'mike', 'videotapes', 'stuck', 'pump', 'dodges', 'fetched', 'referring', 'pine', 'feathers', 'bigbox', 'twins', 'wiffle', 'enterance', 'pistol', 'sweeping', 'bearers', 'citizens', 'turned', 'fish', 'german', 'blame', 'seed', 'retriever', 'tw', 'formula', 'happening', 'laden', 'vegas', 'objest', 'baby', 'tap', 'entertaining', 'coveralls', 'wrestles', 'donut', 'buying', 'bucking', 'flaps', 'slinky', 'reenactment', 'sips', 'bicyler', 'dunks', 'appearing', 'accordion', 'sprinkling', 'aisle', 'potao', 'longhaired', 'jetskiing', 'belongings', 'attaching', 'manuals', 'dimlight', 'clean', 'agility', 'those', 'exited', 'girder', 'splattered', 'farmer', 'frosting', 'tufts', 'challenge', 'cower', 'dominant', 'cot', 'burgers', 'shrowded', 'higher', 'instrument', 'fedex', 'turn', 'basement', 'keeps', 'crampons', 'log', 'sneakers', 'commercial', 'underneath', 'replaces', 'coast', 'arrow', 'shady', 'rubble', 'bulldozer', 'organizing', 'lecturing', 'skips', 'including', 'teeter', 'busters', 'hides', 'phrase', 'cello', 'diagram', 'kneepads', 'headgear', 'varying', 'sledding', 'between', 'garage', 'facepaint', 'adorn', 'organized', 'lying', 'nat', 'hovered', 'winter', 'laying', 'prepares', 'eachothers', 'minivan', 'bundle', 'snowball', 'hp', 'because', 'moonwalk', 'mountaintops', 'thumb', 'arizona', 'nation', 'inverted', 'trade', 'curvy', 'river', 'mountaintop', 'fashionably', 'writes', 'pincer', 'couch', 'scarves', 'sniffs', 'exotic', 'mambo', 'loading', 'suns', 'nervous', 'spelunkers', 'redclad', 'nugent', 'skaters', 'impact', 'dummy', 'dinghy', 'brighly', 'crotch', 'grins', 'late', 'fathers', 'snorkeling', 'lounging', 'husks', 'athletic', 'kelp', 'chopsticks', 'samsung', 'toes', 'signing', 'mortar', 'weimeraners', 'tropical', 'overturn', 'featuring', 'sightseeing', 'netting', 'stork', 'americans', 'posign', 'chews', 'end', 'crocks', 'flinging', 'engaged', 'snapshot', 'accident', 'barettes', 'fat', 'rust', 'junction', 'tidal', 'assist', 'sign', 'reduniformed', 'banister', 'tosses', 'parent', 'cockpit', 'idea', 'pooh', 'soda', 'placemats', 'behind', 'sidelines', 'internet', 'windsurf', 'necks', 'breakdancer', 'offcamera', 'blocks', 'panelling', 'feel', 'jaywalk', 'scientist', 'dog', 'suds', 'vehicle', 'excites', 'biker', 'sundappled', 'presses', 'forest', 'balloon', 'include', 'snowsuits', 'ant', 'reception', 'hard', 'troupe', 'cases', 'obedience', 'coming', 'openmouthed', 'order', 'rehearsing', 'headlight', 'vending', 'shovels', 'sheep', 'few', 'poems', 'sisters', 'stump', 'soles', 'clothes', 'strips', 'sprinkers', 'bread', 'gym', 'porch', 'parody', 'equiment', 'restroom', 'sync', 'begging', 'mission', 'vapour', 'admired', 'mysterious', 'champ', 'semicloudy', 'judgement', 'midflight', 'science', 'advance', 'shore', 'padding', 'patrick', 'protects', 'preoccupied', 'pinkish', 'chinatown', 'tutu', 'fruit', 'cellos', 'ashy', 'rather', 'backset', 'turkeys', 'rental', 'sole', 'wanting', 'sparkler', 'defending', 'subway', 'skateboarders', 'footballer', 'recreational', 'laceup', 'tears', 'bunny', 'gazed', 'mart', 'ad', 'civil', 'hoses', 'africanamericans', 'speedo', 'fishes', 'shaped', 'freddy', 'zoo', 'utensils', 'shovel', 'containing', 'man', 'kidsized', 'athelete', 'walking', 'bottles', 'south', 'axe', 'nipples', 'rowers', 'tree', 'rocky', 'carousel', 'einstein', 'dumpsters', 'breaking', 'goers', 'camps', 'yellowgrassed', 'greencolored', 'coach', 'dusted', 'bathes', 'harness', 'bears', 'equipments', 'headdress', 'vat', 'sprint', 'frightened', 'gotten', 'somersault', 'walls', 'overshadowed', 'retriving', 'special', 'wisconsin', 'jumping', 'jacuzzi', 'possible', 'paddled', 'breed', 'deeps', 'gateway', 'weird', 'garbage', 'lollipop', 'repels', 'vision', 'carves', 'square', 'plains', 'hook', 'dining', 'receiver', 'breeze', 'frolicks', 'panhandler', 'wintergear', 'suntan', 'lilies', 'respectively', 'column', 'orthodox', 'desolate', 'fast', 'rivers', 'height', 'foldable', 'background', 'slanted', 'powerwashing', 'flea', 'sponsors', 'sprinking', 'encounters', 'headdresses', 'passed', 'slumped', 'freestyle', 'containig', 'worn', 'wearing', 'rockclimb', 'diverse', 'hello', 'includes', 'gallery', 'grey', 'bundledup', 'hump', 'container', 'tucked', 'color', 'congregate', 'stock', 'crowd', 'superman', 'jersy', 'juggle', 'kimono', 'mounted', 'lost', 'aveda', 'defaced', 'wig', 'flop', 'geological', 'gleefully', 'dane', 'shrubs', 'flatscreen', 'name', 'bridges', 'cracker', 'kites', 'chains', 'kneedeep', 'exposing', 'congratulate', 'scrimmage', 'wants', 'ornate', 'approaching', 'piggy', 'crowns', 'headscarf', 'brawl', 'mediumsized', 'at', 'reenactors', 'graffitistrewn', 'firends', 'odeon', 'barricade', 'pelicans', 'fighting', 'darkness', 'battling', 'shocked', 'sparse', 'frizzy', 'smile', 'booklets', 'ceremonial', 'railling', 'doberman', 'engulf', 'poles', 'mitt', 'wax', 'operated', 'pane', 'groceries', 'passers', 'harnessed', 'submerges', 'faithful', 'pieces', 'herding', 'masks', 'zooms', 'ornamental', 'pursued', 'headed', 'skyscrapers', 'loaded', 'six', 'moniter', 'bales', 'ships', 'suggestive', 'repair', 'colored', 'hotpink', 'frames', 'rotary', 'towards', 'electrical', 'makeup', 'arcade', 'nordic', 'pebbles', 'ethnic', 'greens', 'jostles', 'sprinkled', 'blazer', 'rests', 'cycler', 'grassy', 'dachshund', 'acrouss', 'donning', 'framed', 'mouthing', 'symbol', 'married', 'passage', 'thrashed', 'saturated', 'experiences', 'stadning', 'gifts', 'flaring', 'whiffle', 'trailing', 'twirling', 'picking', 'longdistance', 'flute', 'belongs', 'competing', 'ipods', 'chilly', 'canoes', 'feels', 'bright', 'campaign', 'posters', 'becomes', 'sponsorship', 'backless', 'allwhite', 'snowmobiles', 'tagged', 'bmw', 'launcher', 'wear', 'underbrush', 'pinches', 'paper', 'drenched', 'pay', 'sharp', 'demonstrates', 'crumb', 'doorbell', 'defend', 'ridge', 'backsides', 'disguises', 'cots', 'sandcastles', 'sweatshirts', 'waits', 'unusual', 'sunflower', 'communications', 'puppet', 'hooker', 'backview', 'spiked', 'comforter', 'bmx', 'zombie', 'rafael', 'eyeing', 'leotard', 'comfortable', 'character', 'sticker', 'impeach', 'examines', 'fireside', 'squeezing', 'bloody', 'ac', 'muffler', 'doe', 'joined', 'cowgirl', 'accepting', 'limegreen', 'shell', 'promotional', 'tinkerbell', 'icey', 'knotted', 'blower', 'brightlylit', 'adjustments', 'trams', 'soup', 'four', 'desert', 'wheelchair', 'bump', 'piggyback', 'floor', 'shields', 'wrinkled', 'gated', 'posing', 'farmland', 'crustacean', 'athlete', 'get', 'streches', 'swimcap', 'meet', 'violently', 'bro', 'barechested', 'register', 'dirtracing', 'celebrate', 'tilts', 'scrubbing', 'coyote', 'has', 'mannequin', 'patterned', 'chained', 'ballerinas', 'breaching', 'ladle', 'explosions', 'wrists', 'pylon', 'seashore', 'exposure', 'hopes', 'established', 'ruined', 'snowboard', 'characters', 'sites', 'waiter', 'entering', 'makes', 'eating', 'doggy', 'pass', 'nametags', 'prize', 'peace', 'pound', 'bellbottoms', 'grove', 'smell', 'signed', 'corgi', 'baring', 'stringless', 'quickly', 'curtain', 'retrives', 'butter', 'pigeons', 'automobiles', 'caucasion', 'glasses', 'sour', 'carabiner', 'trials', 'cape', 'defying', 'lilypads', 'away', 'gettnig', 'boots', 'patiently', 'seahorse', 'blacktop', 'constructed', 'pregnant', 'winds', 'lunchbox', 'digital', 'though', 'flipflops', 'coarse', 'hoodies', 'weave', 'face', 'winks', 'drink', 'really', 'grows', 'nutcracker', 'hurrying', 'retrieved', 'pastry', 'pointing', 'handrailing', 'sit', 'archeologist', 'bathrobe', 'we', 'siren', 'djs', 'earrings', 'sportswear', 'gates', 'worships', 'hurricanes', 'participates', 'eyebrow', 'furious', 'closeby', 'smaller', 'blurred', 'torsodeep', 'nitro', 'circular', 'crossbones', 'cross', 'melted', 'suffering', 'leather', 'marching', 'hummingbird', 'section', 'pressing', 'crawls', 'overnight', 'doorway', 'great', 'thirty', 'states', 'bting', 'glacial', 'chaperone', 'interesting', 'grainy', 'cheerleaders', 'backround', 'flakes', 'notice', 'suit', 'khakicolored', 'opponent', 'broadly', 'inspects', 'dong', 'tball', 'whitesuited', 'clothing', 'picks', 'dandylions', 'pleople', 'shoeshine', 'shine', 'hike', 'fuzzy', 'bodyless', 'videocameras', 'ups', 'boogieboard', 'trousers', 'mussels', 'itself', 'same', 'sum', 'bride', 'crewmen', 'peirced', 'boas', 'score', 'gigantic', 'camp', 'glovedhand', 'floated', 'basketball', 'catwalk', 'hopper', 'stopped', 'blackblue', 'dunked', 'slab', 'crawl', 'calmer', 'holey', 'rustic', 'inline', 'tiger', 'camera', 'involving', 'see', 'material', 'steered', 'tablet', 'scored', 'potato', 'protruding', 'driveway', 'audience', 'nash', 'longish', 'hardwood', 'cheerful', 'somthing', 'just', 'drifting', 'nadal', 'track', 'bodies', 'asphalt', 'healthy', 'coated', 'joyfully', 'makeshift', 'cable', 'ramps', 'gnome', 'raise', 'sleeves', 'outfir', 'come', 'shorline', 'shipping', 'powerboats', 'confused', 'harvested', 'thatched', 'inflatable', 'iceskate', 'sidewalks', 'entertainer', 'built', 'oncoming', 'day', 'wielding', 'consoling', 'flippers', 'twelve', 'burnt', 'democrat', 'mexican', 'thin', 'lkievely', 'strapped', 'forests', 'grayhaired', 'pinata', 'parasurfer', 'bicycle', 'barack', 'drap', 'balding', 'springs', 'mattress', 'threatening', 'cin', 'singing', 'travelling', 'marvel', 'fangs', 'rimmed', 'anticipates', 'adolescents', 'wheat', 'conversing', 'davison', 'daytime', 'backdrop', 'muddy', 'similar', 'slowly', 'boredom', 'jacked', 'dragster', 'spouts', 'mudfight', 'reached', 'fill', 'hoist', 'bulky', 'bicycles', 'starting', 'pitches', 'earring', 'minirace', 'festive', 'slips', 'roundabout', 'littering', 'nylon', 'withering', 'picure', 'make', 'thw', 'rollerskater', 'growling', 'neat', 'camel', 'fraternal', 'protect', 'bent', 'flowering', 'beers', 'fishemen', 'protective', 'bill', 'gray', 'joke', 'uplifted', 'shoulderbag', 'shallow', 'passenger', 'thick', 'dale', 'misses', 'friends', 'seawall', 'handed', 'prom', 'sunglasses', 'bald', 'fell', 'cameraphone', 'comforting', 'bark', 'headset', 'strawberry', 'tatooed', 'protectors', 'donkeys', 'tiny', 'goaltender', 'reflects', 'launched', 'full', 'busstop', 'sleeping', 'almostdried', 'wakeboards', 'array', 'pointy', 'possession', 'lunch', 'beanches', 'widelegged', 'rockets', 'craft', 'ritz', 'uno', 'mostly', 'hugging', 'coasterlike', 'demonstration', 'ranger', 'villages', 'custom', 'tatoo', 'ocean', 'popping', 'swirls', 'archway', 'propels', 'flag', 'haircut', 'roosters', 'duel', 'hippies', 'slipper', 'amid', 'wakeboarders', 'suburban', 'there', 'mule', 'mardi', 'cavorts', 'bonfire', 'bog', 'center', 'expose', 'kiddie', 'swatted', 'infants', 'snuggles', 'cds', 'spool', 'session', 'outdoors', 'pigtails', 'tutus', 'eccentric', 'fantasy', 'sheet', 'practicing', 'animal', 'carpet', 'camping', 'bra', 'activity', 'collarless', 'photographic', 'belts', 'prancing', 'exciting', 'structures', 'blackclad', 'skipped', 'fallen', 'chicago', 'waves', 'sweatsuit', 'themed', 'nfl', 'mown', 'exiting', 'slalom', 'signage', 'programs', 'harpsichord', 'extends', 'wildebeast', 'interestingly', 'sucks', 'headbands', 'confronts', 'seller', 'identically', 'tackler', 'beat', 'downwards', 'clothed', 'stretcher', 'show', 'spanish', 'ceramic', 'krueger', 'blurs', 'operating', 'bursting', 'soccor', 'surrounds', 'uncut', 'screams', 'pinkhooded', 'coaster', 'recliner', 'toll', 'dunk', 'pours', 'splashes', 'cloudcovered', 'medatative', 'covers', 'frolics', 'grab', 'bus', 'shack', 'oldfashioned', 'unmanned', 'innertube', 'beack', 'lower', 'interested', 'ref', 'minor', 'bolts', 'headwrap', 'soggy', 'artwork', 'several', 'prayer', 'cloths', 'accented', 'hole', 'you', 'stretches', 'ipod', 'they', 'lead', 'bite', 'thrust', 'scooters', 'matching', 'colourfully', 'underwear', 'twirl', 'mole', 'overhangs', 'dodging', 'muzzled', 'made', 'forehead', 'trapped', 'slaloms', 'fixtures', 'quarters', 'ax', 'observer', 'worker', 'silhouettes', 'exhibt', 'churns', 'middleaged', 'debri', 'slideshow', 'dinosaur', 'tinted', 'crafted', 'beijing', 'puddle', 'pall', 'tent', 'lambs', 'burst', 'gallop', 'pop', 'rectangle', 'eye', 'soaks', 'ads', 'aims', 'hoolahoops', 'bash', 'windmill', 'sashes', 'dobbermen', 'cliffside', 'golden', 'other', 'shephard', 'march', 'dealing', 'crosswalks', 'dances', 'covered', 'spangles', 'spewing', 'hunt', 'handrail', 'passes', 'stirred', 'hound', 'signer', 'espana', 'an', 'cliffs', 'directing', 'driftrood', 'dive', 'waring', 'piles', 'hawaiian', 'progressively', 'mesa', 'fourwheel', 'muti', 'enforcement', 'waterfalls', 'middle', 'telegraph', 'adventures', 'sheilding', 'steamy', 'scarily', 'balconies', 'stove', 'shallows', 'backlit', 'moves', 'silly', 'droplets', 'vinecovered', 'stretch', 'caches', 'dribbling', 'horned', 'redhaired', 'bespectacled', 'rebound', 'automobile', 'seaweed', 'capture', 'rail', 'determination', 'advertisement', 'moutains', 'leans', 'euro', 'dimond', 'sleve', 'ace', 'crescent', 'prefabricated', 'accent', 'cautiously', 'sewing', 'fleeces', 'peering', 'hoodoos', 'junglegym', 'flowing', 'nursed', 'road', 'of', 'race', 'boats', 'peoplw', 'dimlylit', 'classicstyle', 'skimming', 'scoring', 'guns', 'throwing', 'elevated', 'colander', 'tigger', 'dont', 'powerlines', 'loaves', 'defensive', 'lame', 'are', 'butterflycatcher', 'doorag', 'luggage', 'pugs', 'mobility', 'charm', 'layered', 'teal', 'alon', 'produces', 'gathers', 'shown', 'fist', 'suspended', 'chip', 'halfway', 'partition', 'serious', 'halfdressed', 'amnesty', 'stirs', 'shepherds', 'curling', 'aboveground', 'lease', 'sits', 'attempting', 'grazes', 'speeds', 'branding', 'disney', 'flattened', 'part', 'self', 'schoolchildren', 'real', 'pictures', 'worm', 'paintings', 'third', 'out', 'scores', 'note', 'measuring', 'primping', 'led', 'reindeer', 'takedown', 'war', 'magic', 'hardly', 'district', 'spike', 'bridesmaid', 'delivery', 'judea', 'law', 'leaned', 'piste', 'payphone', 'plants', 'frisbeen', 'tumble', 'smoke', 'post', 'it', 'department', 'offwhite', 'shadows', 'nipping', 'crane', 'shiny', 'what', 'battle', 'slides', 'towel', 'obama', 'raises', 'feeding', 'outside', 'thong', 'safron', 'kildare', 'walk', 'followed', 'aggresively', 'outfut', 'bystander', 'garland', 'dge', 'prison', 'suggestively', 'endorsementcovered', 'shoulder', 'lav', 'move', 'domino', 'gold', 'campground', 'aerodynamically', 'brandishes', 'provocative', 'pressure', 'hurridly', 'period', 'buggies', 'squints', 'addressing', 'religious', 'microphones', 'coffin', 'dramatically', 'number', 'bluejean', 'guardsman', 'dish', 'peaking', 'playgym', 'paisley', 'snowbound', 'bridge', 'talk', 'crumbling', 'shading', 'swept', 'crocodile', 'own', 'fairgrounds', 'strength', 'iove', 'footbridge', 'fisherman', 'garden', 'coutryside', 'speakers', 'campus', 'tundra', 'goods', 'laborador', 'welldressed', 'springer', 'carreis', 'backstage', 'balls', 'talking', 'crab', 'says', 'chested', 'reflected', 'croquet', 'surprised', 'band', 'cop', 'boulder', 'roof', 'kicked', 'nd', 'pom', 'toy', 'retaining', 'blossom', 'shrubbery', 'lipstick', 'before', 'soaring', 'accross', 'cork', 'rugs', 'stamds', 'alligator', 'orchestra', 'winnie', 'lighterskinned', 'livestock', 'onearmed', 'weaving', 'subdivsion', 'community', 'strolling', 'broom', 'redhead', 'chaps', 'competitors', 'players', 'ballerina', 'hers', 'splatter', 'stubby', 'powdery', 'raingear', 'spikes', 'ont', 'hooding', 'militarystyle', 'fiery', 'bland', 'boardwalk', 'he', 'ruin', 'badminton', 'newspapers', 'sprawls', 'mandolin', 'enjoys', 'neckless', 'resaurant', 'demonstarting', 'bowler', 'huts', 'stiffing', 'cushion', 'limousine', 'shredded', 'numbered', 'overhang', 'peak', 'terrior', 'notes', 'ragged', 'barrier', 'handheld', 'recital', 'veil', 'pyramid', 'comforts', 'barking', 'edge', 'blocked', 'lap', 'tanskinned', 'visitor', 'size', 'sweat', 'balloons', 'silk', 'antenna', 'magizine', 'scope', 'pebble', 'aquatic', 'pausing', 'dancers', 'discs', 'scanner', 'rockclimbs', 'headwear', 'graffitti', 'lecturer', 'cuddle', 'lowering', 'dominance', 'reviews', 'tourists', 'biting', 'rings', 'seperate', 'eight', 'vampires', 'cute', 'freefall', 'hoop', 'compete', 'dalmatians', 'shows', 'carries', 'knee', 'signals', 'establishment', 'peoples', 'compact', 'playpen', 'bearing', 'skateboarding', 'breasts', 'beef', 'needlepoint', 'lot', 'fix', 'train', 'glass', 'place', 'moutain', 'bronze', 'supervising', 'adopted', 'longbeaked', 'bellysurfing', 'protest', 'backflips', 'products', 'readying', 'killer', 'starbucks', 'mullet', 'life', 'shire', 'tackled', 'contracption', 'waters', 'once', 'polkadot', 'telephot', 'robust', 'kitty', 'fencers', 'demonstrating', 'parrot', 'blackstriped', 'stools', 'passing', 'steeple', 'stack', 'opposite', 'sailor', 'meanders', 'rummaging', 'missing', 'ourdoors', 'loooking', 'areas', 'brownandwhite', 'medium', 'spray', 'police', 'belt', 'equipment', 'standind', 'assistance', 'glider', 'florist', 'yoga', 'fixer', 'spectate', 'scales', 'else', 'drinking', 'go', 'limo', 'figure', 'docked', 'push', 'sports', 'halo', 'stops', 'beige', 'smartly', 'chunky', 'mother', 'graffitiheavy', 'hods', 'genetic', 'vampire', 'vegetables', 'startled', 'beer', 'outcroping', 'beached', 'incline', 'rollerblade', 'terrace', 'swingtype', 'powerful', 'cannot', 'client', 'whitemetal', 'pail', 'grid', 'milk', 'arab', 'skies', 'album', 'dons', 'scrubland', 'popped', 'candy', 'playground', 'henna', 'dresswear', 'identifier', 'flips', 'protesting', 'wintertime', 'boarders', 'headlights', 'floats', 'discussion', 'kick', 'sleds', 'escape', 'related', 'aig', 'overgrown', 'boatload', 'bannister', 'swimmies', 'uptop', 'hill', 'annoyed', 'sand', 'paraglides', 'medieval', 'cements', 'populated', 'pushup', 'foraging', 'trooper', 'dance', 'softball', 'closes', 'rounding', 'piano', 'redheaded', 'depicts', 'gigolo', 'australian', 'finish', 'invention', 'artificial', 'trimmed', 'accelerates', 'painted', 'heads', 'monster', 'prarie', 'moss', 'grabs', 'build', 'challenging', 'say', 'utilities', 'chocolate', 'pelican', 'gover', 'tupperware', 'pensively', 'fuchsia', 'snoring', 'crawling', 'working', 'spring', 'sleeve', 'plats', 'snowing', 'orange', 'brunettes', 'comprised', 'jazz', 'atmosphere', 'assorted', 'musical', 'tugs', 'uniquelyshaped', 'minimal', 'cub', 'coaches', 'floatlys', 'nibbles', 'dried', 'explosive', 'brindle', 'anciet', 'midspeach', 'evident', 'reach', 'hell', 'towheaded', 'trees', 'biden', 'firefighters', 'pinkcoated', 'blades', 'goggles', 'sect', 'straddle', 'diapers', 'earpiece', 'spot', 'childing', 'pearls', 'moon', 'larger', 'dark', 'energizer', 'tentlike', 'pf', 'razer', 'baton', 'enviorment', 'teammates', 'rubbing', 'confrontation', 'display', 'chief', 'smock', 'reclines', 'rollerblader', 'propped', 'teammate', 'fig', 'lined', 'seyeview', 'outlines', 'shit', 'lionist', 'slopes', 'parachuting', 'magazine', 'messy', 'tabby', 'board', 'pees', 'bike', 'necklaces', 'homes', 'caribbean', 'subject', 'less', 'secondstory', 'slush', 'toetouch', 'prairie', 'tambourines', 'meal', 'silhouetted', 'manuever', 'purina', 'cyclist', 'locker', 'route', 'twists', 'tribal', 'seats', 'pleadingly', 'eyes', 'railings', 'more', 'shamrocks', 'hidden', 'creeping', 'twho', 'easter', 'checkstand', 'prepared', 'burned', 'prepare', 'traveler', 'duffel', 'ducking', 'tortoise', 'semiformal', 'sparklers', 'muzzle', 'design', 'angrily', 'windbreaker', 'icing', 'stereo', 'station', 'recyclable', 'focuses', 'sponges', 'depicting', 'cannon', 'entire', 'firecracker', 'buddha', 'smear', 'messily', 'overweight', 'cooling', 'huddled', 'tyedyed', 'snap', 'sweatband', 'photography', 'bodyboarder', 'looms', 'blackrobed', 'firework', 'tax', 'emblazoned', 'pavillion', 'yellowsuited', 'snake', 'quinta', 'ripped', 'van', 'lemons', 'hobby', 'longhandled', 'skateboarder', 'machinery', 'removes', 'grimacing', 'markers', 'pulled', 'pumps', 'deflated', 'skimpy', 'cardigan', 'decorative', 'wiht', 'mouths', 'touchline', 'captured', 'countertop', 'dirtcovered', 'weeping', 'motors', 'goucho', 'fisheye', 'occured', 'ballet', 'barefoot', 'afro', 'heights', 'terrier', 'distnat', 'whom', 'canadian', 'muffs', 'glittery', 'dj', 'ramp', 'crate', 'dips', 'spitting', 'gra', 'club', 'emerges', 'allowed', 'colonial', 'staircase', 'christmas', 'strains', 'gyro', 'outline', 'conversation', 'signs', 'corkscrew', 'overturned', 'attack', 'parachute', 'corridor', 'flags', 'auto', 'older', 'cheers', 'opinion', 'handling', 'mermaid', 'vie', 'cord', 'meter', 'croquette', 'buff', 'properly', 'brightlycolred', 'marker', 'pecking', 'playing', 'leafcovered', 'canoeing', 'circles', 'teams', 'backlegs', 'personnel', 'warehouse', 'edges', 'eyese', 'confronting', 'lets', 'whacking', 'body', 'fortune', 'rollerskates', 'someplace', 'kiss', 'scruffy', 'notepad', 'negotiates', 'somersaulting', 'mall', 'outward', 'stoplight', 'avrovulcancom', 'convoy', 'mirrored', 'sucking', 'lip', 'maple', 'money', 'widespread', 'cleavage', 'disabled', 'legs', 'brushes', 'nudges', 'awnings', 'treed', 'litttle', 'howls', 'studio', 'destination', 'no', 'rappels', 'snowmobiling', 'chairswing', 'saffron', 'still', 'broad', 'orangesunset', 'obscuring', 'paperwork', 'fastfood', 'biek', 'jars', 'pots', 'sculptures', 'god', 'noy', 'leaps', 'force', 'underfoot', 'reflective', 'midrun', 'thank', 'teenage', 'liquid', 'split', 'buttondown', 'bone', 'aggressive', 'laughing', 'hallways', 'models', 'manner', 'drainage', 'smokes', 'sweatpants', 'pro', 'placid', 'hoists', 'vandalized', 'striped', 'seattle', 'contemplating', 'direction', 'propelling', 'tips', 'paved', 'joust', 'samoyads', 'gentle', 'lightup', 'candle', 'outstreached', 'dumped', 'cringes', 'replaced', 'fend', 'yachts', 'proudly', 'casts', 'rocket', 'ignore', 'plays', 'bluejeans', 'rafts', 'labs', 'tumbles', 'celebratory', 'elephant', 'snout', 'brazilian', 'story', 'snowmobiler', 'settings', 'collected', 'chat', 'bird', 'watermelon', 'technical', 'earphones', 'moms', 'traverses', 'eyeglasses', 'orca', 'top', 'werewolf', 'stumbling', 'parasail', 'multistory', 'anklehigh', 'ultimate', 'wuth', 'wraps', 'pagent', 'landscaped', 'athletes', 'aimed', 'cigarette', 'hiviz', 'tan', 'acrobatic', 'bug', 'fair', 'baggage', 'mountainous', 'plantains', 'tones', 'circling', 'rolling', 'tabloid', 'barren', 'born', 'battons', 'stifflyposed', 'news', 'instructing', 'tipped', 'tights', 'parachuter', 'building', 'soled', 'curb', 'seperated', 'whoa', 'tooth', 'turkey', 'posed', 'foreround', 'city', 'strapless', 'jr', 'struggles', 'abandon', 'twilight', 'spills', 'skeptically', 'choice', 'creams', 'cycle', 'pasts', 'ohio', 'expressway', 'mani', 'bands', 'chickens', 'widows', 'fishscales', 'sidebyside', 'freeclimbing', 'mosquelike', 'headresses', 'ravine', 'nearby', 'wildebeest', 'awards', 'apple', 'gal', 'embraces', 'learn', 'easily', 'rears', 'nations', 'ran', 'chiseling', 'smashed', 'geese', 'passageway', 'visiting', 'sniffing', 'noce', 'boxer', 'wallride', 'cleaning', 'gown', 'lapse', 'cruise', 'broen', 'unfurling', 'over', 'barriers', 'unifrom', 'swung', 'matador', 'codpiece', 'stoll', 'bust', 'aboriginal', 'port', 'aggitates', 'snoopy', 'hugged', 'facepaintings', 'feature', 'need', 'herd', 'glove', 'slices', 'shreds', 'strange', 'happen', 'last', 'appear', 'green', 'debris', 'oval', 'hula', 'jug', 'peddled', 'vendor', 'zepra', 'armbands', 'perhaps', 'logos', 'mustached', 'bernard', 'stange', 'twenties', 'proped', 'halfnaked', 'casque', 'overflow', 'israeli', 'grapple', 'humping', 'zip', 'billboards', 'plenty', 'short', 'watersports', 'parade', 'goalie', 'minerature', 'spigot', 'tractorlike', 'laugh', 'felled', 'stucco', 'game', 'jello', 'wavy', 'boatful', 'tandem', 'antennae', 'activities', 'companions', 'arriving', 'beverages', 'blue', 'unique', 'egyptian', 'exit', 'entry', 'paw', 'anime', 'chainsaw', 'surfers', 'universal', 'actors', 'kangaroo', 'lioness', 'ejected', 'rafter', 'without', 'mountian', 'vw', 'tongee', 'overfilled', 'sunbathe', 'shots', 'whistle', 'sooner', 'somone', 'colorings', 'worshippers', 'windsailing', 'multicolor', 'dreary', 'his', 'topped', 'uw', 'cattails', 'craw', 'pitbull', 'sale', 'vacant', 'mountaineer', 'shaving', 'snakeskin', 'twos', 'arrows', 'gauzey', 'wears', 'entertains', 'hatchback', 'stripe', 'buddhists', 'amazed', 'wife', 'sedan', 'washington', 'chi', 'wizards', 'shoveling', 'how', 'right', 'diving', 'twigs', 'waterful', 'vendors', 'vibrant', 'avoiding', 'cellphone', 'belted', 'monitoring', 'amplifier', 'robes', 'twist', 'happily', 'yerba', 'turquoise', 'swetashirts', 'skydiver', 'footrace', 'tires', 'otuside', 'frowns', 'combat', 'armenian', 'grips', 'warm', 'gentlemen', 'puff', 'knitted', 'skyscraper', 'speaks', 'strike', 'daschunds', 'gren', 'faded', 'coliding', 'whispering', 'tale', 'partly', 'sword', 'figures', 'dress', 'spanishstyle', 'prisoner', 'coverings', 'flooded', 'brownishorange', 'skating', 'laughed', 'bulletproof', 'drops', 'flannel', 'differentcolored', 'knit', 'crash', 'child', 'women', 'mouth', 'entertainment', 'hiker', 'projector', 'sort', 'columned', 'piggybacking', 'calming', 'batsman', 'peer', 'cliff', 'football', 'camo', 'brush', 'mountaindew', 'catered', 'soil', 'flat', 'armour', 'father', 'yankees', 'david', 'loops', 'joy', 'downriver', 'puddles', 'helping', 'excercises', 'jumpos', 'reading', 'baseball', 'decide', 'mine', 'egde', 'interracial', 'hand', 'petals', 'bean', 'scratching', 'treks', 'secluded', 'meetinghall', 'good', 'kayaks', 'leaping', 'onstage', 'peacefully', 'shoulders', 'glide', 'presidential', 'brought', 'choir', 'gators', 'thre', 'litlle', 'versus', 'thorugh', 'melts', 'convert', 'tireshaped', 'easel', 'protection', 'pet', 'cobbled', 'raising', 'navy', 'viz', 'skis', 'unpainted', 'checkered', 'strong', 'island', 'restaraunt', 'shorter', 'shadowy', 'broach', 'view', 'converging', 'outstreched', 'reveals', 'san', 'pressed', 'save', 'clasped', 'motorcycle', 'citizen', 'revel', 'concealed', 'wetsuits', 'leafy', 'steadies', 'monkey', 'paintball', 'cans', 'mechanical', 'button', 'rides', 'skills', 'motorbike', 'wiener', 'romantically', 'checks', 'loader', 'adorned', 'so', 'videogame', 'tasting', 'pylons', 'peeping', 'megaphone', 'braces', 'confetti', 'noses', 'erupts', 'attacked', 'looked', 'midsections', 'catching', 'struck', 'fingerpaints', 'fields', 'angle', 'rollercoaster', 'float', 'spokesmodels', 'concert', 'shelf', 'hulk', 'adults', 'meditational', 'bumps', 'chairlift', 'fruits', 'harly', 'sill', 'hummer', 'preparing', 'emerald', 'guard', 'burn', 'pizza', 'ways', 'foamy', 'urge', 'amoung', 'midriff', 'nature', 'traversing', 'headband', 'graffiticovered', 'work', 'gatorade', 'brownishred', 'kinds', 'held', 'unicycle', 'neptuno', 'glassy', 'knocked', 'branded', 'wildly', 'handcrank', 'wrangle', 'index', 'gothic', 'drills', 'loser', 'effort', 'presenting', 'cosplay', 'sheppard', 'toss', 'rounded', 'uniformed', 'kneeled', 'cue', 'uniform', 'closecropped', 'reds', 'slip', 'portable', 'braided', 'flanked', 'collapsed', 'baskers', 'house', 'receives', 'candidate', 'ciff', 'parasailing', 'freesbies', 'behing', 'ceiling', 'skateboard', 'sailing', 'using', 'pasture', 'bounding', 'trekking', 'donuts', 'sporting', 'miasto', 'ally', 'shapes', 'crank', 'everybody', 'highschoolers', 'standing', 'well', 'china', 'flings', 'monkeys', 'gate', 'memorial', 'her', 'intervening', 'alone', 'tatoos', 'squad', 'fours', 'scantilyclad', 'rippled', 'pokes', 'flyer', 'along', 'atop', 'wedgie', 'barefooted', 'earphone', 'paints', 'store', 'bound', 'helmeted', 'punk', 'neon', 'removing', 'multiprint', 'widow', 'pulleys', 'watching', 'drummer', 'battles', 'baptized', 'scene', 'encouraged', 'had', 'sprinkler', 'did', 'opening', 'hauled', 'momma', 'bracelet', 'curly', 'pool', 'skydivers', 'accepts', 'poling', 'welllit', 'hatted', 'air', 'clearing', 'facedown', 'prizes', 'rusty', 'showroom', 'swam', 'spaghetti', 'buildings', 'fear', 'motor', 'hr', 'dolly', 'racquet', 'expansive', 'housing', 'coopers', 'curve', 'redseated', 'smacks', 'text', 'articles', 'tripods', 'meeting', 'pencil', 'fails', 'woodstacked', 'presentation', 'contemporary', 'coral', 'furtrimmed', 'hide', 'skims', 'wishing', 'kisses', 'puppies', 'whitehaired', 'browm', 'try', 'leaves', 'horses', 'turning', 'would', 'numeral', 'speaker', 'wilderness', 'pedal', 'maps', 'empty', 'sack', 'lifevest', 'shin', 'ropes', 'dryed', 'parking', 'conoe', 'lake', 'proud', 'masquerade', 'simpsons', 'honest', 'stuff', 'medow', 'penske', 'indicating', 'korean', 'freak', 'buildabear', 'bucket', 'members', 'neoncolored', 'weathered', 'wand', 'perched', 'olympics', 'remaining', 'carved', 'nipple', 'family', 'serena', 'foreheads', 'grasping', 'chased', 'trot', 'lighting', 'tulip', 'patroling', 'freefalling', 'share', 'surfs', 'flautist', 'tea', 'progress', 'eyebrows', 'flops', 'forearm', 'poolside', 'twowheeled', 'rainy', 'twin', 'ovals', 'next', 'barge', 'oppenents', 'jewlery', 'directions', 'cruisship', 'santas', 'hooking', 'slouching', 'windowed', 'loan', 'video', 'canyon', 'maroon', 'machines', 'defenders', 'greyhound', 'bundles', 'afghan', 'creek', 'bordered', 'sunshaped', 'outfield', 'edged', 'relax', 'trays', 'ferns', 'kayacker', 'developing', 'armstand', 'objects', 'mainly', 'swishing', 'stick', 'albert', 'rights', 'stares', 'tether', 'peek', 'khakis', 'lips', 'tram', 'nip', 'forceful', 'tube', 'slalomlike', 'encouraging', 'for', 'attrative', 'abandoned', 'hits', 'roadway', 'breaststroke', 'blueeyed', 'volleyball', 'smilely', 'court', 'perfomed', 'outstretched', 'finley', 'wheeler', 'moutainside', 'everything', 'looks', 'suntanning', 'labelled', 'guide', 'frog', 'deposited', 'cresting', 'dresses', 'eluding', 'fluorescent', 'architectural', 'taller', 'tough', 'stage', 'waterway', 'obsured', 'tape', 'mustache', 'apparantly', 'snowpile', 'stopping', 'moutnain', 'dirtbed', 'drumming', 'dunking', 'mixed', 'backstand', 'gauntlet', 'chutes', 'contest', 'checkerboard', 'bay', 'helicopter', 'muscle', 'imagery', 'tests', 'basset', 'looming', 'soars', 'narrow', 'sloped', 'navigates', 'mishap', 'waists', 'observing', 'construction', 'scale', 'students', 'that', 'ruggers', 'blows', 'released', 'fiddles', 'series', 'having', 'cheek', 'lay', 'double', 'region', 'leads', 'retrive', 'device', 'aided', 'liking', 'bouncer', 'largeboned', 'john', 'aerial', 'sunny', 'left', 'crates', 'thck', 'catholic', 'finger', 'town', 'worried', 'helemt', 'texas', 'earnhardt', 'straps', 'supermarket', 'climbers', 'cold', 'joins', 'poncho', 'hug', 'guitarists', 'overhead', 'gymnasium', 'homebase', 'licks', 'bareback', 'supported', 'everyone', 'smoky', 'rappelling', 'plushie', 'bending', 'onesie', 'toilet', 'schoolboy', 'ascends', 'busines', 'autos', 'rises', 'fashion', 'towing', 'anticipation', 'patriotic', 'guessing', 'upset', 'poured', 'indians', 'punching', 'multilple', 'baseman', 'kayakers', 'lockers', 'teaches', 'porcelain', 'upturned', 'folding', 'visor', 'oppsing', 'ducks', 'pickup', 'gokart', 'hangs', 'rollerbladers', 'damaged', 'officials', 'rise', 'swimmer', 'offering', 'woody', 'trackside', 'dragging', 'wristwatch', 'underside', 'ill', 'designed', 'attentive', 'judge', 'model', 'texting', 'theater', 'vegetation', 'books', 'dad', 'armor', 'beanie', 'toddler', 'tapped', 'browse', 'branch', 'streaks', 'meditating', 'cappedhills', 'explores', 'feather', 'crystalclear', 'telescopes', 'sling', 'bigwheels', 'handle', 'supervise', 'sings', 'surfboarding', 'hallway', 'table', 'collar', 'bang', 'round', 'fake', 'gound', 'viewfinder', 'parachutist', 'coasts', 'upperclass', 'truck', 'walked', 'canopy', 'handrails', 'loses', 'pursing', 'attraction', 'consumed', 'jaw', 'sveral', 'pouting', 'peoople', 'brings', 'portrait', 'gets', 'pops', 'dojo', 'yard', 'polaris', 'root', 'cathcer', 'process', 'pastor', 'rapidly', 'flaggers', 'frolic', 'being', 'necklace', 'extending', 'celebration', 'supervision', 'beats', 'roadside', 'foosball', 'cloverfilled', 'nightlife', 'excess', 'taught', 'navigating', 'lots', 'vigorous', 'ignores', 'unison', 'flock', 'highschool', 'cup', 'pretending', 'decorations', 'bearded', 'rangler', 'cutouts', 'sun', 'lick', 'marked', 'victory', 'torch', 'chow', 'mulch', 'sombody', 'breakdances', 'childern', 'sleddog', 'buggy', 'youngle', 'repelling', 'multiracial', 'surveying', 'cattle', 'accompanies', 'carton', 'shades', 'cameraman', 'rottweiller', 'profusely', 'lavender', 'midclimb', 'boxy', 'curious', 'motorscooter', 'compound', 'stays', 'swordfighting', 'manmade', 'sprawled', 'discuss', 'straining', 'pairs', 'while', 'coloring', 'formations', 'cowlike', 'exhibit', 'playful', 'formed', 'poses', 'crucifixion', 'alley', 'aluminum', 'drain', 'sheer', 'victorian', 'bullbranded', 'chair', 'front', 'chewedup', 'bleak', 'crust', 'cutoff', 'pot', 'celtics', 'orangehooded', 'seidwalk', 'coats', 'crosscountry', 'armoire', 'guys', 'travels', 'windsurfing', 'dolphin', 'seas', 'crow', 'canal', 'divided', 'stood', 'mirror', 'shepherd', 'sunsets', 'umpire', 'jacks', 'stacked', 'gear', 'serve', 'since', 'turtle', 'patch', 'linked', 'contact', 'fingers', 'packs', 'wrecked', 'fingertips', 'direct', 'belaying', 'under', 'western', 'guardrail', 'head', 'skater', 'some', 'corgis', 'distressed', 'impersonators', 'umbrella', 'emitting', 'reptiles', 'staue', 'leaning', 'average', 'determined', 'beside', 'theme', 'milkshake', 'vacation', 'budweiser', 'ralley', 'read', 'smiles', 'waterfall', 'cheery', 'swims', 'colliding', 'jaws', 'endzone', 'applies', 'cricketer', 'cameras', 'intercept', 'bongo', 'completes', 'logo', 'bumble', 'tubular', 'egret', 'acts', 'napping', 'centipede', 'contorted', 'stingray', 'goal', 'grimaces', 'minnie', 'tackling', 'scenic', 'perfom', 'scrambling', 'about', 'asian', 'ledge', 'native', 'following', 'sandy', 'mama', 'merchant', 'opportunity', 'digs', 'clover', 'employees', 'frolicking', 'casuallydressed', 'too', 'showgirls', 'aerobatic', 'drumset', 'popsicle', 'lit', 'learns', 'shoots', 'performance', 'fitness', 'throat', 'crevice', 'insect', 'readied', 'seagull', 'harbor', 'cascades', 'highfiving', 'mallard', 'near', 'ensemble', 'regularly', 'stacking', 'couches', 'shoulderlength', 'alertly', 'procession', 'lights', 'screening', 'horns', 'set', 'pushes', 'teen', 'shredding', 'doge', 'rode', 'chins', 'rally', 'grating', 'interviewed', 'furnace', 'mannequins', 'hands', 'hanglider', 'names', 'recreation', 'limb', 'workshop', 'let', 'filed', 'instructor', 'masked', 'designs', 'bullrun', 'tub', 'pack', 'seedoo', 'quilt', 'crocheted', 'merchandise', 'beaten', 'secret', 'orders', 'flyfishing', 'case', 'ornaments', 'teeth', 'unner', 'chunk', 'dancer', 'opponents', 'trendy', 'balances', 'responders', 'sledge', 'as', 'unsual', 'follows', 'facing', 'clapping', 'downsteps', 'tho', 'guiding', 'yorkshire', 'motorcycling', 'swampy', 'secured', 'trains', 'mouthed', 'fronds', 'bedroll', 'pillows', 'studded', 'gradual', 'ladder', 'any', 'windy', 'legged', 'pinestraw', 'ladys', 'pirate', 'heart', 'pajama', 'lilly', 'sick', 'cacti', 'scratches', 'historic', 'inlineskates', 'metallic', 'rapid', 'london', 'officiallooking', 'file', 'flipped', 'snaps', 'won', 'tool', 'widely', 'paneling', 'punkish', 'flailing', 'snowpatched', 'bathing', 'tie', 'pristine', 'suited', 'roiling', 'soaking', 'dotted', 'heating', 'solicits', 'tightly', 'ganilla', 'lock', 'against', 'counter', 'starts', 'whil', 'segway', 'vault', 'pamphlet', 'wetsuit', 'pits', 'divind', 'measured', 'intertube', 'traveller', 'idyllic', 'dew', 'milling', 'squirts', 'sink', 'but', 'aside', 'spiritual', 'wrapping', 'messanger', 'hsirt', 'overlooking', 'doorstep', 'surronded', 'lifted', 'containers', 'wade', 'hold', 'russell', 'skijoring', 'throught', 'crosses', 'toward', 'kickbox', 'controls', 'bobbed', 'captures', 'feed', 'past', 'know', 'saxophone', 'sinks', 'booths', 'hillock', 'raced', 'weight', 'socks', 'aged', 'border', 'downstream', 'handstands', 'sunshade', 'matchin', 'accompanied', 'stalks', 'sing', 'shelves', 'stripped', 'home', 'midst', 'papers', 'bowling', 'remote', 'pads', 'butchers', 'spots', 'fleecy', 'trick', 'driverside', 'surounded', 'pharmacy', 'snowboarding', 'syrup', 'lopes', 'peterson', 'waterskier', 'nicely', 'spraying', 'press', 'disk', 'touching', 'hankerchief', 'friend', 'package', 'airplane', 'nussle', 'decked', 'am', 'warming', 'actor', 'exercise', 'rushed', 'opposition', 'chinese', 'wine', 'leap', 'foreground', 'laughs', 'ivars', 'kisscostumed', 'weating', 'games', 'handstand', 'chalk', 'driving', 'nowhere', 'visible', 'officer', 'handbags', 'graying', 'fourwheeled', 'tanandwhite', 'rainling', 'west', 'look', 'routine', 'boxes', 'classes', 'finishes', 'risen', 'scoop', 'enter', 'forelegs', 'graze', 'location', 'mansion', 'both', 'sash', 'ou', 'lean', 'lunches', 'bridesmaids', 'wisks', 'wearfing', 'jersey', 'lens', 'nongrassy', 'took', 'surroundings', 'streched', 'sticks', 'mold', 'herbs', 'pep', 'crafts', 'hawk', 'fedora', 'indescript', 'dribbles', 'fame', 'bills', 'polka', 'tilted', 'shower', 'worshipping', 'gloves', 'sweater', 'strip', 'helmets', 'test', 'better', 'maker', 'dangerous', 'tugowar', 'yorkie', 'wanders', 'eldery', 'artifacts', 'dragged', 'gandhi', 'fork', 'fenced', 'forehand', 'side', 'clutches', 'fribee', 'scary', 'frisbees', 'ee', 'dobermans', 'pompadour', 'backseat', 'alcove', 'nips', 'buoy', 'ballons', 'archer', 'striding', 'rickety', 'arched', 'screened', 'snowcapped', 'zig', 'girlfriends', 'rips', 'collide', 'newly', 'keep', 'tunic', 'straddles', 'usual', 'shirtness', 'stirring', 'bowls', 'rush', 'halfsmile', 'lemonade', 'bras', 'brake', 'sibling', 'stuffed', 'scrap', 'agents', 'pencils', 'skiers', 'freshly', 'letters', 'flapping', 'disgusted', 'controller', 'emphatically', 'bathingsuit', 'soocerball', 'disturbed', 'wheelers', 'steel', 'jar', 'tartan', 'woodland', 'sideways', 'hanna', 'whist', 'formally', 'pink', 'withered', 'sailboard', 'approachs', 'trampoline', 'cobblestones', 'happiness', 'pedestrians', 'popcycles', 'flocking', 'started', 'constructions', 'fishers', 'lettuce', 'vase', 'lab', 'breastfeeding', 'oh', 'overcoat', 'disc', 'expression', 'source', 'involved', 'wigs', 'jeans', 'shouts', 'cupcake', 'tight', 'labeled', 'excersise', 'dine', 'angles', 'rainstorm', 'sizes', 'coffee', 'dipping', 'heavymetal', 'all', 'skinny', 'distant', 'motioning', 'railway', 'perm', 'controlling', 'ship', 'ballplayers', 'trackandfield', 'cannonball', 'fanny', 'accends', 'strikes', 'diego', 'attire', 'rummages', 'backwards', 'potty', 'affectionately', 'ridable', 'identification', 'shorthair', 'effects', 'licked', 'writing', 'balancing', 'fawkes', 'curled', 'slender', 'mosque', 'beyond', 'stadium', 'super', 'anatomy', 'pedigree', 'fairground', 'slouched', 'saying', 'latter', 'speak', 'ahead', 'quilted', 'keffiyahs', 'blondeheaded', 'vaulated', 'marx', 'retrievers', 'my', 'daschund', 'unshaven', 'pour', 'glides', 'sport', 'backpacking', 'speedskater', 'numbers', 'pedaling', 'water', 'plate', 'rippling', 'thriller', 'stages', 'drums', 'asking', 'plling', 'announcer', 'bend', 'sacks', 'dumpster', 'cloak', 'taken', 'crushed', 'purchasing', 'saddled', 'crashing', 'glacier', 'slippery', 'jogging', 'ground', 'rug', 'saxophones', 'subaru', 'spiderpatterned', 'vessel', 'toppless', 'windowsill', 'walmart', 'affixed', 'twenty', 'false', 'cigar', 'bigs', 'abs', 'bowtie', 'weights', 'rollerskating', 'overtop', 'depth', 'smiling', 'priests', 'curl', 'antelope', 'swarmed', 'gallopsing', 'stepped', 'dismounts', 'begin', 'mantle', 'swarm', 'ti', 'was', 'hovering', 'handles', 'disheveled', 'office', 'conifers', 'squabble', 'rest', 'brooms', 'buries', 'aerodynamic', 'cleared', 'naval', 'kayaking', 'photo', 'cemetery', 'helplessly', 'decortive', 'cocker', 'headline', 'tiles', 'wakeboarder', 'tarp', 'vacationing', 'floatation', 'cargo', 'spouse', 'willow', 'nerf', 'world', 'hilltops', 'muscular', 'garb', 'tunnel', 'folded', 'farward', 'racer', 'bended', 'starbuck', 'hit', 'flower', 'kite', 'snorkel', 'arena', 'style', 'farmers', 'easels', 'helmet', 'swoops', 'plungles', 'high', 'swimwear', 'asia', 'fur', 'drawing', 'birthday', 'pasta', 'cradling', 'sunning', 'multicoloured', 'lakefront', 'lone', 'groomed', 'lamp', 'thrown', 'patricks', 'paddlers', 'daisies', 'dilapidated', 'atvs', 'id', 'adjusting', 'motorcycles', 'eagle', 'pokemon', 'zagging', 'pajamas', 'canooers', 'shop', 'bluegreen', 'dandelion', 'cheap', 'capes', 'barks', 'lines', 'weimaraner', 'buzzes', 'watering', 'cherry', 'tanktops', 'maintain', 'paragliding', 'stringed', 'dolphins', 'untouched', 'literature', 'streetshot', 'brwon', 'motivation', 'headphone', 'crag', 'ok', 'policeman', 'chihuahua', 'colecting', 'budweisersponsored', 'girls', 'competition', 'sofa', 'shaved', 'innertubes', 'houses', 'based', 'brochure', 'lightly', 'fingerhold', 'recoils', 'potted', 'males', 'buffalo', 'goes', 'chrismas', 'involves', 'spotting', 'couple', 'grasps', 'mobile', 'wispy', 'belly', 'recline', 'crooswalk', 'looling', 'smiled', 'twirls', 'bungeetype', 'behinf', 'morning', 'veteran', 'agile', 'collars', 'electronics', 'kaki', 'flown', 'burrows', 'offroading', 'moustache', 'grassland', 'waterfilled', 'steer', 'colapsable', 'neclace', 'clouds', 'amount', 'tuxedos', 'bushels', 'attempted', 'five', 'splash', 'lamb', 'clay', 'sheepdogs', 'boulders', 'load', 'soapy', 'anchored', 'perked', 'clause', 'investigates', 'caught', 'fireplug', 'local', 'tricolored', 'closely', 'wiping', 'dig', 'osme', 'floating', 'trash', 'horro', 'buckled', 'backs', 'image', 'kicking', 'corner', 'islamic', 'hardscape', 'bleachers', 'auditorium', 'hotel', 'dalmatian', 'chute', 'egg', 'unified', 'sunbathing', 'autumnal', 'computers', 'waaves', 'bull', 'participating', 'fashioned', 'feathered', 'shot', 'inertia', 'torn', 'concerned', 'panoramic', 'trows', 'door', 'canvasses', 'giant', 'lodge', 'awe', 'reson', 'rice', 'alongside', 'mouse', 'gorup', 'tilling', 'dragons', 'jesus', 'performer', 'sparsely', 'buckets', 'gentleman', 'faux', 'pulls', 'thing', 'jackson', 'sleeding', 'joyful', 'basett', 'like', 'chess', 'closed', 'buddy', 'wharfs', 'cartwheels', 'upstream', 'yacht', 'pigeon', 'marquee', 'gain', 'snuggling', 'lays', 'notre', 'dirtyblonde', 'boy', 'put', 'ate', 'vike', 'in', 'sledders', 'cage', 'rockface', 'streamers', 'restaurant', 'eggs', 'waling', 'temple', 'cook', 'bullfighter', 'muzzles', 'stroke', 'ropey', 'corporate', 'mossy', 'gravity', 'another', 'shops', 'graphic', 'additional', 'bares', 'choppy', 'directed', 'ghost', 'sharing', 'rider', 'fiddle', 'parachutes', 'badly', 'attemping', 'haired', 'circumvents', 'pug', 'orangestained', 'skewed', 'lighthouse', 'waded', 'strings', 'signaling', 'ring', 'cyclists', 'lesh', 'unspooled', 'tends', 'musicans', 'enters', 'arabic', 'lavish', 'flaming', 'shoulderdeep', 'japanesesponsored', 'knees', 'buddist', 'periods', 'walkman', 'lifting', 'stocky', 'perforced', 'puffy', 'tinsel', 'current', 'mingling', 'adjust', 'mascot', 'smelled', 'roped', 'selling', 'exercises', 'shutters', 'skins', 'trudge', 'redvested', 'bohemians', 'lotion', 'orangeclad', 'castles', 'roasted', 'forth', 'flowered', 'tobaggons', 'surges', 'crudely', 'propelled', 'gazes', 'poppies', 'conoes', 'producing', 'hazmat', 'javelin', 'various', 'bumpers', 'mini', 'copper', 'squeamish', 'apples', 'tray', 'communal', 'fellows', 'graham', 'clowds', 'backgrounds', 'exibit', 'clinging', 'elevator', 'teases', 'shawled', 'gesture', 'joker', 'relaxes', 'bed', 'thread', 'ever', 'letter', 'causing', 'slinging', 'spin', 'helments', 'attach', 'lands', 'sleeveless', 'pauses'}\n",
            "Vocabulary Size: 8763\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfK7GkWA4KD1",
        "colab_type": "text"
      },
      "source": [
        "Finally, we can save the dictionary of image identifiers and descriptions to a new file named descriptions.txt, with one image identifier and description per line.\n",
        "\n",
        "Below defines the save_descriptions() function that, given a dictionary containing the mapping of identifiers to descriptions and a filename, saves the mapping to file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DwELCjB3lBv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save descriptions to file, one per line\n",
        "def save_descriptions(descriptions, filename):\n",
        "  lines = list()\n",
        "  \n",
        "  for key, desc_list in descriptions.items():\n",
        "    for desc in desc_list:\n",
        "      lines.append(key + ' ' + desc)\n",
        "  \n",
        "  data = '\\n'.join(lines)\n",
        "  file = open(file=filename, mode='w')\n",
        "  file.write(data)\n",
        "  file.close()\n",
        "  \n",
        "  \n",
        "save_descriptions(descriptions, 'descriptions.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cE9Wo2lH65md",
        "colab_type": "text"
      },
      "source": [
        "### Develop Deep Learning Model\n",
        "\n",
        "In this section, we will define the deep learning model and fit it on the training dataset.\n",
        "\n",
        "1. Loading Data.\n",
        "2. Defining the Model.\n",
        "3. Fitting the Model.\n",
        "\n",
        "#### Loading Data\n",
        "\n",
        "First, we must load the prepared photo and text data so that we can use it to fit the model.\n",
        "\n",
        "We are going to train the data on all of the photos and captions in the training dataset. While training, we are going to monitor the performance of the model on the development dataset and use that performance to decide when to save models to file.\n",
        "\n",
        "The train and development dataset have been predefined in the Flickr_8k.trainImages.txt and Flickr_8k.devImages.txt files respectively, that both contain lists of photo file names. From these file names, we can extract the photo identifiers and use these identifiers to filter photos and descriptions for each set.\n",
        "\n",
        "The function load_set() below will load a pre-defined set of identifiers given the train or development sets filename.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58VokVq4dZ-C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load the doc into memory\n",
        "def load_doc(filename):\n",
        "  # open the file as read only\n",
        "  file = open(file=filename, mode='r')\n",
        "  # read all text\n",
        "  text = file.read()\n",
        "  # close the file\n",
        "  file.close()\n",
        "  return text\n",
        "\n",
        "filename = './Flickr8k_text/Flickr8k.token.txt'\n",
        "\n",
        "doc = load_doc(filename)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzR01uxrE8tC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def load_set(filename):\n",
        "  \"\"\"\n",
        "  load a pre-defined list of photo identifiers\n",
        "  \"\"\"\n",
        "  #get text contents of the file\n",
        "  doc = load_doc(filename)\n",
        "  \n",
        "  # initialize an empty list\n",
        "  dataset = list()\n",
        "  \n",
        "  # read line by line\n",
        "  for line in doc.split('\\n'):\n",
        "    # skip empty lines\n",
        "    if len(line)<1:\n",
        "      continue\n",
        "    # get image identifier\n",
        "    identifier = line.split('.')[0]\n",
        "    dataset.append(identifier)\n",
        "    \n",
        "  return set(dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZPyBjQcFqqC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_clean_descriptions(filename, dataset):\n",
        "  \"\"\"\n",
        "  load clean descriptions into memory\n",
        "  filename: file to load the descriptions from\n",
        "  dataset: only extract descriptions for image_ids in dataset\n",
        "  \"\"\"\n",
        "  # load doc\n",
        "  doc = load_doc(filename)\n",
        "  descriptions = dict()\n",
        "  for line in doc.split('\\n'):\n",
        "    # split line by white space\n",
        "    tokens = line.split()\n",
        "    # split id from description\n",
        "    image_id, image_desc = tokens[0], tokens[1:]\n",
        "    # only take image_ids which are present in dataset\n",
        "    if image_id in dataset:\n",
        "      # create list\n",
        "      if image_id not in descriptions:\n",
        "        descriptions[image_id] = list()\n",
        "      # wrap description in tokens\n",
        "      desc = 'startseq ' + ' '.join(image_desc) + ' endseq'\n",
        "      # store\n",
        "      descriptions[image_id].append(desc)\n",
        "      \n",
        "  return descriptions\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GoqSOW1rgHBz",
        "colab_type": "code",
        "outputId": "797fea42-d289-419e-c00f-38bbf2d421f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from pickle import load\n",
        "\n",
        "features_data = load(open(file='./features.pkl', mode='rb'))\n",
        "\n",
        "print (features_data['221973402_ecb1cd51f1'].shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 4096)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwGes6_Odctu",
        "colab_type": "code",
        "outputId": "e8b3821b-b935-411c-bb98-17d07dd92652",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "from pickle import load\n",
        "\n",
        "def load_photo_features(filename, dataset):\n",
        "  \"\"\"\n",
        "  load all features\n",
        "  filename: file to load the features from (expects a pickle file)\n",
        "  dataset: only extract features for image_ids in dataset\n",
        "  \"\"\"\n",
        "  all_features = load(open(file=filename, mode='rb'))\n",
        "  \n",
        "  # filter features\n",
        "  features = {k:all_features[k] for k in dataset}\n",
        "  return features\n",
        "\n",
        "# load training dataset (6K)\n",
        "filename = './Flickr8k_text/Flickr_8k.trainImages.txt'\n",
        "train = load_set(filename)\n",
        "\n",
        "print (\"Length of train set: %d\" %len(train))\n",
        "\n",
        "# load descriptions for the train set\n",
        "\n",
        "train_descriptions = load_clean_descriptions(filename='./descriptions.txt', dataset=train)\n",
        "\n",
        "print('Train Descriptions: len=%d' % len(train_descriptions))\n",
        "\n",
        "# load features for the train set\n",
        "\n",
        "train_features = load_photo_features(filename='./features.pkl', dataset=train)\n",
        "print('Train Features: len=%d' % len(train_features))\n",
        "   "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of train set: 6000\n",
            "Train Descriptions: len=6000\n",
            "Train Features: len=6000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thfprDyhqNSa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print (train_descriptions['1000268201_693b08cb0e'])\n",
        "\n",
        "print (train_features['1000268201_693b08cb0e'].shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IcIFXVuDspKd",
        "colab_type": "text"
      },
      "source": [
        "The description text will need to be encoded to numbers before it can be presented to the model as in input or compared to the model’s predictions.\n",
        "\n",
        "The first step in encoding the data is to create a consistent mapping from words to unique integer values. Keras provides the Tokenizer class that can learn this mapping from the loaded description data.\n",
        "\n",
        "Below defines the to_lines() to convert the dictionary of descriptions into a list of strings and the create_tokenizer() function that will fit a Tokenizer given the loaded photo description text.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OliVk08ptFMV",
        "colab_type": "code",
        "outputId": "833e0b15-4915-41eb-cac6-6399d3525d4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "def to_lines(descriptions):\n",
        "  \"\"\"\n",
        "  convert a dictionary of clean descriptions to a list of descriptions\n",
        "  \"\"\"\n",
        "  \n",
        "  all_desc = list()\n",
        "  # for each descrription\n",
        "  for key in descriptions.keys():\n",
        "    # append each word in the list\n",
        "    [all_desc.append(d) for d in descriptions[key]]\n",
        "  return all_desc\n",
        "\n",
        "def create_tokenizer(descriptions):\n",
        "  \"\"\"\n",
        "  fits a tokenizer to caption descriptions\n",
        "  \"\"\"\n",
        "  # get list of all descriptions\n",
        "  lines = to_lines(descriptions)\n",
        "  tokenizer = Tokenizer()\n",
        "  # Updates internal vocabulary based on a list of texts.\n",
        "  tokenizer.fit_on_texts(lines)\n",
        "  return tokenizer\n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "tokenizer=create_tokenizer(descriptions)\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print('Vocabulary Size: %d' % vocab_size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary Size: 8764\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ync4HZQg-JPB",
        "colab_type": "text"
      },
      "source": [
        "We can now encode the text.\n",
        "\n",
        "Each description will be split into words. The model will be provided one word and the photo and generate the next word. Then the first two words of the description will be provided to the model as input with the image to generate the next word. This is how the model will be trained.\n",
        "\n",
        "For example, the input sequence “little girl running in field” would be split into 6 input-output pairs to train the model:\n",
        "\n",
        "```\n",
        "X1,\t\tX2 (text sequence), \t\t\t\t\t\ty (word)\n",
        "\n",
        "photo\tstartseq, \t\t\t\t\t\t\t\t\tlittle\n",
        "\n",
        "photo\tstartseq, little,\t\t\t\t\t\t\tgirl\n",
        "\n",
        "photo\tstartseq, little, girl, \t\t\t\t\trunning\n",
        "\n",
        "photo\tstartseq, little, girl, running, \t\t\tin\n",
        "\n",
        "photo\tstartseq, little, girl, running, in, \t\tfield\n",
        "\n",
        "photo\tstartseq, little, girl, running, in, field, endseq\n",
        "\n",
        "```\n",
        "\n",
        "Later, when the model is used to generate descriptions, the generated words will be concatenated and recursively provided as input to generate a caption for an image.\n",
        "\n",
        "The function below named create_sequences(), given the tokenizer, a maximum sequence length, and the dictionary of all descriptions and photos, will transform the data into input-output pairs of data for training the model. There are two input arrays to the model: one for photo features and one for the encoded text. There is one output for the model which is the encoded next word in the text sequence.\n",
        "\n",
        "The input text is encoded as integers, which will be fed to a word embedding layer. The photo features will be fed directly to another part of the model. The model will output a prediction, which will be a probability distribution over all words in the vocabulary.\n",
        "\n",
        "The output data will therefore be a one-hot encoded version of each word, representing an idealized probability distribution with 0 values at all word positions except the actual word position, which has a value of 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvSWeS9IFuY2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_descriptions['1000268201_693b08cb0e']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEKhkWvCGNj4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwZu7ZPw-V6T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from numpy import array\n",
        "\n",
        "def create_sequences(tokenizer, max_length, descriptions, photos, vocab_size):\n",
        "\tX1, X2, y = list(), list(), list()\n",
        "\t# walk through each image identifier\n",
        "\tfor key, desc_list in descriptions.items():\n",
        "\t\t# walk through each description for the image\n",
        "\t\tfor desc in desc_list:\n",
        "\t\t\t# encode the sequence\n",
        "\t\t\tseq = tokenizer.texts_to_sequences([desc])[0]\n",
        "\t\t\t# split one sequence into multiple X,y pairs\n",
        "\t\t\tfor i in range(1, len(seq)):\n",
        "\t\t\t\t# split into input and output pair\n",
        "\t\t\t\tin_seq, out_seq = seq[:i], seq[i]\n",
        "\t\t\t\t# pad input sequence\n",
        "\t\t\t\tin_seq = pad_sequences([in_seq], maxlen=max_length)[0]\n",
        "\t\t\t\t# encode output sequence\n",
        "\t\t\t\tout_seq = to_categorical([out_seq], num_classes=vocab_size)[0]\n",
        "\t\t\t\t# store\n",
        "\t\t\t\tX1.append(photos[key][0])\n",
        "\t\t\t\tX2.append(in_seq)\n",
        "\t\t\t\ty.append(out_seq)\n",
        "\treturn array(X1), array(X2), array(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skkw84nAy6eB",
        "colab_type": "text"
      },
      "source": [
        "We will need to calculate the maximum number of words in the longest description. A short helper function named max_length() is defined below.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTIKSpSvy66e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_max_length(description):\n",
        "  \"\"\"\n",
        "  calculate the length of the description with the most words\n",
        "  \"\"\"\n",
        "  lines = to_lines(description)\n",
        "  return max(len(d.split()) for d in lines)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xU7p64o7ScL",
        "colab_type": "code",
        "outputId": "14249782-756b-4e74-a9f3-d89d3d6b3a9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        }
      },
      "source": [
        "compute_max_length(train_descriptions)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-30c9cf78cefa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcompute_max_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_descriptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'compute_max_length' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJB7hn-r6fEe",
        "colab_type": "text"
      },
      "source": [
        "### Defining the Model\n",
        "\n",
        "We will define a deep learning based on the “merge-model” described by Marc Tanti, et al. in their 2017 papers:\n",
        "\n",
        "The authors provide a nice schematic of the model, reproduced below.\n",
        "\n",
        "![](https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2017/09/Schematic-of-the-Merge-Model-For-Image-Captioning.png)\n",
        "\n",
        "We will describe the model in three parts:\n",
        "\n",
        "1. **Photo Feature Extractor**: This is a 16-layer VGG model pre-trained on the ImageNet dataset. We have pre-processed the photos with the VGG model (without the output layer) and will use the extracted features predicted by this model as input.\n",
        "\n",
        "2. **Sequence Processor**: This is a word embedding layer for handling the text input, followed by a Long Short-Term Memory (LSTM) recurrent neural network layer.\n",
        "\n",
        "3. **Decoder (for lack of a better name)**: Both the feature extractor and sequence processor output a fixed-length vector. These are merged together and processed by a Dense layer to make a final prediction.\n",
        "\n",
        "The Photo Feature Extractor model expects input photo features to be a vector of 4,096 elements. These are processed by a Dense layer to produce a 256 element representation of the photo.\n",
        "\n",
        "The Sequence Processor model expects input sequences with a pre-defined length (34 words) which are fed into an Embedding layer that uses a mask to ignore padded values. This is followed by an LSTM layer with 256 memory units. The longest description for an image has 34 words\n",
        "\n",
        "Both the input models produce a 256 element vector. Further, both input models use regularization in the form of 50% dropout. This is to reduce overfitting the training dataset, as this model configuration learns very fast.\n",
        "\n",
        "The Decoder model merges the vectors from both input models using an addition operation. This is then fed to a Dense 256 neuron layer and then to a final output Dense layer that makes a softmax prediction over the entire output vocabulary for the next word in the sequence.\n",
        "\n",
        "The function below named define_model() defines and returns the model ready to be fit.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jq9AU8l76yta",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import plot_model\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import Dropout\n",
        "from keras.layers.merge import add\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "def define_model(vocab_size, max_length):\n",
        "  \"\"\"\n",
        "  define the architecture of the captioning model\n",
        "  \"\"\"\n",
        "  \n",
        "  # feature extractor model\n",
        "  \n",
        "  inputs1 = Input(shape=(4096,))\n",
        "  fe1 = Dropout(rate=0.5)(inputs1)\n",
        "  fe2 = Dense(units=256, activation='relu')(fe1)\n",
        "  \n",
        "  # sequence model\n",
        "  # Sequence Processor model expects input sequences with a pre-defined length (34 words) \n",
        "  inputs2 = Input(shape=(max_length,))\n",
        "  se1 = Embedding(input_dim=vocab_size, output_dim=256, mask_zero=True)(inputs2)\n",
        "  se2 = Dropout(rate=0.5)(se1)\n",
        "  se3 = LSTM(units=256)(se2)\n",
        "  \n",
        "  # decoder model\n",
        "  decoder1 = add([fe2, se3])\n",
        "  decoder2 = Dense(units=256, activation='relu')(decoder1)\n",
        "  # softmax prediction over the entire output vocabulary for the next word in the sequence\n",
        "  outputs = Dense(units=vocab_size, activation='softmax')(decoder2)\n",
        "  \n",
        "  # tie it together [image, seq] [word]\n",
        "  model = Model(inputs=[inputs1, inputs2], outputs=outputs)\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "  \n",
        "  # summarize model\n",
        "  print(model.summary())\n",
        "\n",
        "  # save model plot\n",
        "  plot_model(model, to_file='./model.png', show_shapes=True)\n",
        "\n",
        "  return model\n",
        "  \n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-qhro7YUIQa",
        "colab_type": "code",
        "outputId": "af89d698-84c6-4f69-bc93-8135cc5dd679",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "# train dataset\n",
        "\n",
        "# load training dataset (6K)\n",
        "\n",
        "filename = './Flickr8k_text/Flickr_8k.trainImages.txt'\n",
        "\n",
        "train = load_set(filename)\n",
        "\n",
        "print (\"Length of train set:\", len(train))\n",
        "\n",
        "# load desc\n",
        "\n",
        "train_descriptions = load_clean_descriptions('./descriptions.txt', train)\n",
        "\n",
        "print (\"Train desc length:\", len(train_descriptions))\n",
        "\n",
        "\n",
        "# photo features\n",
        "\n",
        "train_features = load_photo_features('./features.pkl', train)\n",
        "\n",
        "print (\"Train features length:\", len(train_features))\n",
        "\n",
        "# prepare tokenizer\n",
        "\n",
        "tokenizer = create_tokenizer(train_descriptions)\n",
        "\n",
        "# 1 as tokenizer is 0 indexed\n",
        "\n",
        "vocab_size = len(tokenizer.word_index)+1\n",
        "\n",
        "print (\"Vocab size:\", vocab_size)\n",
        "\n",
        "# determine the maximum sequence length\n",
        "\n",
        "max_length = compute_max_length(train_descriptions)\n",
        "\n",
        "print (\"Max length of caption:\", max_length)\n",
        "\n",
        "# prepare seq for training\n",
        "\n",
        "X1train, X2train, ytrain = create_sequences(tokenizer, max_length, train_descriptions, train_features, vocab_size)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of train set: 6000\n",
            "Train desc length: 6000\n",
            "Train features length: 6000\n",
            "Vocab size: 7579\n",
            "Max length of caption: 34\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxfGVEAOlBCG",
        "colab_type": "code",
        "outputId": "0bc03b98-51ce-4fa0-e4bd-bafdd83c4dea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "source": [
        "from numpy import array\n",
        "from pickle import load\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from keras.utils import plot_model\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import Dropout\n",
        "from keras.layers.merge import add\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# load doc into memory\n",
        "def load_doc(filename):\n",
        "\t# open the file as read only\n",
        "\tfile = open(filename, 'r')\n",
        "\t# read all text\n",
        "\ttext = file.read()\n",
        "\t# close the file\n",
        "\tfile.close()\n",
        "\treturn text\n",
        "\n",
        "# load a pre-defined list of photo identifiers\n",
        "def load_set(filename):\n",
        "\tdoc = load_doc(filename)\n",
        "\tdataset = list()\n",
        "\t# process line by line\n",
        "\tfor line in doc.split('\\n'):\n",
        "\t\t# skip empty lines\n",
        "\t\tif len(line) < 1:\n",
        "\t\t\tcontinue\n",
        "\t\t# get the image identifier\n",
        "\t\tidentifier = line.split('.')[0]\n",
        "\t\tdataset.append(identifier)\n",
        "\treturn set(dataset)\n",
        "\n",
        "# load clean descriptions into memory\n",
        "def load_clean_descriptions(filename, dataset):\n",
        "\t# load document\n",
        "\tdoc = load_doc(filename)\n",
        "\tdescriptions = dict()\n",
        "\tfor line in doc.split('\\n'):\n",
        "\t\t# split line by white space\n",
        "\t\ttokens = line.split()\n",
        "\t\t# split id from description\n",
        "\t\timage_id, image_desc = tokens[0], tokens[1:]\n",
        "\t\t# skip images not in the set\n",
        "\t\tif image_id in dataset:\n",
        "\t\t\t# create list\n",
        "\t\t\tif image_id not in descriptions:\n",
        "\t\t\t\tdescriptions[image_id] = list()\n",
        "\t\t\t# wrap description in tokens\n",
        "\t\t\tdesc = 'startseq ' + ' '.join(image_desc) + ' endseq'\n",
        "\t\t\t# store\n",
        "\t\t\tdescriptions[image_id].append(desc)\n",
        "\treturn descriptions\n",
        "\n",
        "# load photo features\n",
        "def load_photo_features(filename, dataset):\n",
        "\t# load all features\n",
        "\tall_features = load(open(filename, 'rb'))\n",
        "\t# filter features\n",
        "\tfeatures = {k: all_features[k] for k in dataset}\n",
        "\treturn features\n",
        "\n",
        "# covert a dictionary of clean descriptions to a list of descriptions\n",
        "def to_lines(descriptions):\n",
        "\tall_desc = list()\n",
        "\tfor key in descriptions.keys():\n",
        "\t\t[all_desc.append(d) for d in descriptions[key]]\n",
        "\treturn all_desc\n",
        "\n",
        "# fit a tokenizer given caption descriptions\n",
        "def create_tokenizer(descriptions):\n",
        "\tlines = to_lines(descriptions)\n",
        "\ttokenizer = Tokenizer()\n",
        "\ttokenizer.fit_on_texts(lines)\n",
        "\treturn tokenizer\n",
        "\n",
        "# calculate the length of the description with the most words\n",
        "def max_length(descriptions):\n",
        "\tlines = to_lines(descriptions)\n",
        "\treturn max(len(d.split()) for d in lines)\n",
        "\n",
        "# create sequences of images, input sequences and output words for an image\n",
        "def create_sequences(tokenizer, max_length, descriptions, photos, vocab_size):\n",
        "\tX1, X2, y = list(), list(), list()\n",
        "\t# walk through each image identifier\n",
        "\tfor key, desc_list in descriptions.items():\n",
        "\t\t# walk through each description for the image\n",
        "\t\tfor desc in desc_list:\n",
        "\t\t\t# encode the sequence\n",
        "\t\t\tseq = tokenizer.texts_to_sequences([desc])[0]\n",
        "\t\t\t# split one sequence into multiple X,y pairs\n",
        "\t\t\tfor i in range(1, len(seq)):\n",
        "\t\t\t\t# split into input and output pair\n",
        "\t\t\t\tin_seq, out_seq = seq[:i], seq[i]\n",
        "\t\t\t\t# pad input sequence\n",
        "\t\t\t\tin_seq = pad_sequences([in_seq], maxlen=max_length)[0]\n",
        "\t\t\t\t# encode output sequence\n",
        "\t\t\t\tout_seq = to_categorical([out_seq], num_classes=vocab_size)[0]\n",
        "\t\t\t\t# store\n",
        "\t\t\t\tX1.append(photos[key][0])\n",
        "\t\t\t\tX2.append(in_seq)\n",
        "\t\t\t\ty.append(out_seq)\n",
        "\treturn array(X1), array(X2), array(y)\n",
        "\n",
        "# define the captioning model\n",
        "def define_model(vocab_size, max_length):\n",
        "\t# feature extractor model\n",
        "\tinputs1 = Input(shape=(4096,))\n",
        "\tfe1 = Dropout(0.5)(inputs1)\n",
        "\tfe2 = Dense(256, activation='relu')(fe1)\n",
        "\t# sequence model\n",
        "\tinputs2 = Input(shape=(max_length,))\n",
        "\tse1 = Embedding(vocab_size, 256, mask_zero=True)(inputs2)\n",
        "\tse2 = Dropout(0.5)(se1)\n",
        "\tse3 = LSTM(256)(se2)\n",
        "\t# decoder model\n",
        "\tdecoder1 = add([fe2, se3])\n",
        "\tdecoder2 = Dense(256, activation='relu')(decoder1)\n",
        "\toutputs = Dense(vocab_size, activation='softmax')(decoder2)\n",
        "\t# tie it together [image, seq] [word]\n",
        "\tmodel = Model(inputs=[inputs1, inputs2], outputs=outputs)\n",
        "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\t# summarize model\n",
        "\tprint(model.summary())\n",
        "\tplot_model(model, to_file='model.png', show_shapes=True)\n",
        "\treturn model\n",
        "\n",
        "# train dataset\n",
        "\n",
        "# load training dataset (6K)\n",
        "filename = 'Flickr8k_text/Flickr_8k.trainImages.txt'\n",
        "train = load_set(filename)\n",
        "print('Dataset: %d' % len(train))\n",
        "# descriptions\n",
        "train_descriptions = load_clean_descriptions('descriptions.txt', train)\n",
        "print('Descriptions: train=%d' % len(train_descriptions))\n",
        "# photo features\n",
        "train_features = load_photo_features('features.pkl', train)\n",
        "print('Photos: train=%d' % len(train_features))\n",
        "# prepare tokenizer\n",
        "tokenizer = create_tokenizer(train_descriptions)\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print('Vocabulary Size: %d' % vocab_size)\n",
        "# determine the maximum sequence length\n",
        "max_length = max_length(train_descriptions)\n",
        "print('Description Length: %d' % max_length)\n",
        "# prepare sequences\n",
        "X1train, X2train, ytrain = create_sequences(tokenizer, max_length, train_descriptions, train_features, vocab_size)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Dataset: 6000\n",
            "Descriptions: train=6000\n",
            "Photos: train=6000\n",
            "Vocabulary Size: 7579\n",
            "Description Length: 34\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaRzN1VZtoo6",
        "colab_type": "code",
        "outputId": "4f45ee05-8868-4bf9-8a48-c60dfdd9d609",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X1train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(306404, 4096)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1N3VFsNvtJtm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pickle import dump\n",
        "\n",
        "dump(X1train, open('X1train.pkl', 'wb'), protocol=4)\n",
        "dump(X2train, open('X2train.pkl', 'wb'), protocol=4)\n",
        "dump(ytrain, open('ytrain.pkl', 'wb'), protocol=4)\n",
        "\n",
        "print (\"Done...\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2otMlPpOq8to",
        "colab_type": "code",
        "outputId": "f47079bd-0695-4f99-8224-6825b99f7096",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "# dev dataset\n",
        "\n",
        "# load test set\n",
        "filename = 'Flickr8k_text/Flickr_8k.devImages.txt'\n",
        "test = load_set(filename)\n",
        "print('Dataset: %d' % len(test))\n",
        "# descriptions\n",
        "test_descriptions = load_clean_descriptions('descriptions.txt', test)\n",
        "print('Descriptions: test=%d' % len(test_descriptions))\n",
        "# photo features\n",
        "test_features = load_photo_features('features.pkl', test)\n",
        "print('Photos: test=%d' % len(test_features))\n",
        "# prepare sequences\n",
        "X1test, X2test, ytest = create_sequences(tokenizer, max_length, test_descriptions, test_features, vocab_size)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset: 1000\n",
            "Descriptions: test=1000\n",
            "Photos: test=1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtDtboT1qjK6",
        "colab_type": "code",
        "outputId": "8febcd3e-c160-4bce-cefd-0fa49dbe3dca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# fit model\n",
        "# define the model\n",
        "model = define_model(vocab_size, max_length)\n",
        "# define checkpoint callback\n",
        "filepath = 'model-ep{epoch:03d}-loss{loss:.3f}-val_loss{val_loss:.3f}.h5'\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "# fit model\n",
        "model.fit([X1train, X2train], ytrain, epochs=6, verbose=2, callbacks=[checkpoint], validation_data=([X1test, X2test], ytest))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0725 14:29:34.201067 140515973060480 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0725 14:29:34.242206 140515973060480 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0725 14:29:34.249349 140515973060480 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0725 14:29:34.258840 140515973060480 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0725 14:29:34.275749 140515973060480 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0725 14:29:34.744791 140515973060480 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2974: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0725 14:29:34.800782 140515973060480 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0725 14:29:34.822907 140515973060480 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            (None, 34)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_1 (InputLayer)            (None, 4096)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 34, 256)      1940224     input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 4096)         0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 34, 256)      0           embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 256)          1048832     dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   (None, 256)          525312      dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 256)          0           dense_1[0][0]                    \n",
            "                                                                 lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 256)          65792       add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 7579)         1947803     dense_2[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 5,527,963\n",
            "Trainable params: 5,527,963\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Train on 306404 samples, validate on 50903 samples\n",
            "Epoch 1/6\n",
            " - 623s - loss: 4.5126 - val_loss: 4.0616\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 4.06164, saving model to model-ep001-loss4.513-val_loss4.062.h5\n",
            "Epoch 2/6\n",
            " - 622s - loss: 3.8758 - val_loss: 3.8917\n",
            "\n",
            "Epoch 00002: val_loss improved from 4.06164 to 3.89169, saving model to model-ep002-loss3.876-val_loss3.892.h5\n",
            "Epoch 3/6\n",
            " - 622s - loss: 3.6801 - val_loss: 3.8375\n",
            "\n",
            "Epoch 00003: val_loss improved from 3.89169 to 3.83751, saving model to model-ep003-loss3.680-val_loss3.838.h5\n",
            "Epoch 4/6\n",
            " - 621s - loss: 3.5840 - val_loss: 3.8424\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 3.83751\n",
            "Epoch 5/6\n",
            " - 616s - loss: 3.5333 - val_loss: 3.8436\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 3.83751\n",
            "Epoch 6/6\n",
            " - 613s - loss: 3.4963 - val_loss: 3.8575\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 3.83751\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fcc1dbf7438>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "So4rrL8DxWZc",
        "colab_type": "text"
      },
      "source": [
        "### Evaluate Model\n",
        "\n",
        "Once the model is fit, we can evaluate the skill of its predictions on the holdout test dataset.\n",
        "\n",
        "We will evaluate a model by generating descriptions for all photos in the test dataset and evaluating those predictions with a standard cost function.\n",
        "\n",
        "First, we need to be able to generate a description for a photo using a trained model.\n",
        "\n",
        "This involves passing in the start description token ‘startseq‘, generating one word, then calling the model recursively with generated words as input until the end of sequence token is reached ‘endseq‘ or the maximum description length is reached.\n",
        "\n",
        "The function below named generate_desc() implements this behavior and generates a textual description given a trained model, and a given prepared photo as input. It calls the function word_for_id() in order to map an integer prediction back to a word.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_n7Z4lO2dHA",
        "colab_type": "code",
        "outputId": "88cc0fff-5ba3-4b16-ae3b-91a972521107",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tokenizer.texts_to_sequences(['hi', 'dog'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[2982], [8]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FtyrC42yDrA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def word_for_id(integer, tokenizer):\n",
        "  \"\"\"\n",
        "  map an integer to a word\n",
        "  \"\"\"\n",
        "  return tokenizer.index_word.get(integer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2wd_uzv3MbT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_desc(model, tokenizer, photo, max_length):\n",
        "  \"\"\"\n",
        "  generate a description for an image\n",
        "  \"\"\"\n",
        "  \n",
        "  # seed the generation process\n",
        "  in_text = 'startseq'\n",
        "\n",
        "  # iterate over the whole length of the sequence\n",
        "  for i in range(max_length):\n",
        "    # integer encode input sequence\n",
        "    sequence = tokenizer.texts_to_sequences([in_text])[0]\n",
        "    # pad input\n",
        "    sequence = pad_sequences([sequence], maxlen=max_length)\n",
        "\n",
        "    # predict next word\n",
        "    yhat = model.predict([photo,sequence], verbose=0)\n",
        "    # convert probability to integer\n",
        "    yhat = argmax(yhat)\n",
        "    # map integer to word\n",
        "    word = word_for_id(yhat, tokenizer)\n",
        "    # stop if we cannot map the word\n",
        "    if word is None:\n",
        "      break\n",
        "    # append as input for generating the next word\n",
        "    in_text += ' ' + word\n",
        "    # stop if we predict the end of the sequence\n",
        "    if word == 'endseq':\n",
        "      break\n",
        "  return in_text\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yu7U_LDS45M6",
        "colab_type": "text"
      },
      "source": [
        "We will generate predictions for all photos in the test dataset and in the train dataset.\n",
        "\n",
        "The function below named evaluate_model() will evaluate a trained model against a given dataset of photo descriptions and photo features. The actual and predicted descriptions are collected and evaluated collectively using the corpus BLEU score that summarizes how close the generated text is to the expected text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2FT_aCq456-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "\n",
        "def evaluate_model(model, descriptions, photos, tokenizer, max_length):\n",
        "\tactual, predicted = list(), list()\n",
        "\t# step over the whole set\n",
        "\tfor key, desc_list in descriptions.items():\n",
        "\t\t# generate description\n",
        "\t\tyhat = generate_desc(model, tokenizer, photos[key], max_length)\n",
        "\t\t# store actual and predicted\n",
        "\t\treferences = [d.split() for d in desc_list]\n",
        "\t\tactual.append(references)\n",
        "\t\tpredicted.append(yhat.split())\n",
        "\t# calculate BLEU score\n",
        "\tprint('BLEU-1: %f' % corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0)))\n",
        "\tprint('BLEU-2: %f' % corpus_bleu(actual, predicted, weights=(0.5, 0.5, 0, 0)))\n",
        "\tprint('BLEU-3: %f' % corpus_bleu(actual, predicted, weights=(0.3, 0.3, 0.3, 0)))\n",
        "\tprint('BLEU-4: %f' % corpus_bleu(actual, predicted, weights=(0.25, 0.25, 0.25, 0.25)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CiiJguv75lGd",
        "colab_type": "text"
      },
      "source": [
        "BLEU scores are used in text translation for evaluating translated text against one or more reference translations.\n",
        "\n",
        "Here, we compare each generated description against all of the reference descriptions for the photograph. We then calculate BLEU scores for 1, 2, 3 and 4 cumulative n-grams.\n",
        "\n",
        "You can learn more about the BLEU score here:\n",
        "\n",
        "A Gentle Introduction to Calculating the BLEU Score for Text in Python\n",
        "The NLTK Python library implements the BLEU score calculation in the corpus_bleu() function. A higher score close to 1.0 is better, a score closer to zero is worse.\n",
        "\n",
        "We can put all of this together with the functions from the previous section for loading the data. We first need to load the training dataset in order to prepare a Tokenizer so that we can encode generated words as input sequences for the model. It is critical that we encode the generated words using exactly the same encoding scheme as was used when training the model.\n",
        "\n",
        "We then use these functions for loading the test dataset.\n",
        "\n",
        "The complete example is listed below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7uR4sHL5hyW",
        "colab_type": "code",
        "outputId": "dee90e8d-5daf-494f-d438-b4f9c0744eda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "from numpy import argmax\n",
        "from pickle import load\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import load_model\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "# prepare tokenizer on train set\n",
        "\n",
        "# load training dataset (6K)\n",
        "filename = 'Flickr8k_text/Flickr_8k.trainImages.txt'\n",
        "train = load_set(filename)\n",
        "print('Dataset: %d' % len(train))\n",
        "# descriptions\n",
        "train_descriptions = load_clean_descriptions('descriptions.txt', train)\n",
        "print('Descriptions: train=%d' % len(train_descriptions))\n",
        "# prepare tokenizer\n",
        "tokenizer = create_tokenizer(train_descriptions)\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print('Vocabulary Size: %d' % vocab_size)\n",
        "# determine the maximum sequence length\n",
        "max_length = compute_max_length(train_descriptions)\n",
        "print('Description Length: %d' % max_length)\n",
        "\n",
        "# prepare test set\n",
        "\n",
        "# load test set\n",
        "filename = 'Flickr8k_text/Flickr_8k.testImages.txt'\n",
        "test = load_set(filename)\n",
        "print('Dataset: %d' % len(test))\n",
        "# descriptions\n",
        "test_descriptions = load_clean_descriptions('descriptions.txt', test)\n",
        "print('Descriptions: test=%d' % len(test_descriptions))\n",
        "# photo features\n",
        "test_features = load_photo_features('features.pkl', test)\n",
        "print('Photos: test=%d' % len(test_features))\n",
        "\n",
        "# load the model\n",
        "filename = 'model-ep003-loss3.680-val_loss3.838.h5'\n",
        "model = load_model(filename)\n",
        "# evaluate model\n",
        "evaluate_model(model, test_descriptions, test_features, tokenizer, max_length)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset: 6000\n",
            "Descriptions: train=6000\n",
            "Vocabulary Size: 7579\n",
            "Description Length: 34\n",
            "Dataset: 1000\n",
            "Descriptions: test=1000\n",
            "Photos: test=1000\n",
            "BLEU-1: 0.516892\n",
            "BLEU-2: 0.268575\n",
            "BLEU-3: 0.181900\n",
            "BLEU-4: 0.082526\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}