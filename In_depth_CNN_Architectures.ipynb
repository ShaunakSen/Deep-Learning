{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "In-depth CNN Architectures.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM7G8ChE040lf2LU0kmizRf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShaunakSen/Deep-Learning/blob/master/In_depth_CNN_Architectures.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xC5EYFwcxgE0"
      },
      "source": [
        "## CNN Architectures - Advanced \r\n",
        "\r\n",
        "> Based on the lecture by Dr. Ahlad Kumar: https://www.youtube.com/watch?v=CNNnzl8HIIU\r\n",
        "\r\n",
        "### CNN achieves Translation Equi-Variance\r\n",
        "\r\n",
        "Say we have a filter below which is very good at detecting edges.\r\n",
        "Now, it does not matter where the '9' image is present, as long as we have the same filter, it will detect the edges as features\r\n",
        "\r\n",
        "Thus CNNs achieve __translation equi-varaince__\r\n",
        "\r\n",
        "This is the first advantage of convolutions\r\n",
        "\r\n",
        "![](https://i.imgur.com/wOL1syi.png)\r\n",
        "\r\n",
        "In the below image we see this in more details:\r\n",
        "\r\n",
        "![](https://i.imgur.com/7TFTGbL.png)\r\n",
        "\r\n",
        "As we can see that the pixel values for 9 are shifted and as the result the feature values also get shifted but the values remain same\r\n",
        "\r\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFGHbUXkN44T"
      },
      "source": [
        "### Advantage of Pooling\r\n",
        "\r\n",
        "Imagine we have an image of a '9' and we translate it. Can pooling still capture the information?\r\n",
        "\r\n",
        "- Yes it can procided the translation distance is small\r\n",
        "\r\n",
        "In the image of '9' in LHS we have the pixel values outlined in green as 100->40->80->20\r\n",
        "\r\n",
        "In RHS we have translated the pixels by 1 pixel to the right\r\n",
        "\r\n",
        "We do MaxPool with 2x2 receptive field with stride 2 and ops are shown\r\n",
        "\r\n",
        "We can see that 100->80 combination is getting detected in both cases\r\n",
        "\r\n",
        "![](https://i.imgur.com/g6VGkJR.png)\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8a0A5Q0EQKWL"
      },
      "source": [
        "### AlexNet Architecture Details\r\n",
        "\r\n",
        "![](https://i.imgur.com/9IqgwZD.png)\r\n",
        "\r\n",
        "The ip image shape: 224x224x3\r\n",
        "\r\n",
        "After the first conv layer we use a Maxpool of stride=2\r\n",
        "The receptive field is 3x3\r\n",
        "\r\n",
        "In general we often find that the field size == stride in max pool.\r\n",
        "Here it is not so\r\n",
        "\r\n",
        "This is called __Overlapping Max Pooling__\r\n",
        "\r\n",
        "`Conv Same` means we pad the image to preserve the dimensionality\r\n",
        "\r\n",
        "Lets check calculation:\r\n",
        "\r\n",
        "Acc to: https://d2l.ai/chapter_convolutional-neural-networks/padding-and-strides.html\r\n",
        "\r\n",
        "In general, when the stride for the height is  s_h  and the stride for the width is  s_w , the output shape is\r\n",
        "\r\n",
        "$\\lfloor(n_h-k_h+p_h+s_h)/s_h\\rfloor \\times \\lfloor(n_w-k_w+p_w+s_w)/s_w\\rfloor.$\r\n",
        "\r\n",
        "Here we can assume for the first conv layer padding == stride == 4\r\n",
        "\r\n",
        "Plugging the values in the below function we can verify that we get op shape as 56x56x96 (as we have used 96 filters)\r\n",
        "\r\n",
        "#### Features in ALexNet\r\n",
        "\r\n",
        "1. Use of ReLU\r\n",
        "2. Use of Dropout\r\n",
        "3. Use of multiple GPUs\r\n",
        "4. Overlapping pooling\r\n",
        "5. Local Response Normalization (nowadays this evolved into Batch Normalization)\r\n",
        "6. Data augmentation\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qiu0IP76wbNw",
        "outputId": "ee8f462e-0ba1-482e-d5ac-52cc89f47e6d"
      },
      "source": [
        "import numpy as np\r\n",
        "def calculate_op_shape(n, k, p, s):\r\n",
        "    return np.floor((n-k+p+s)/s)\r\n",
        "\r\n",
        "calculate_op_shape(224, 11, 4, 4)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "55.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxxncxK4RMaY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}